<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Diana Villasana Ocampo">

<title>Ordinary Least Squares Regression (OLSR)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="01_01_OLSR_py_files/libs/clipboard/clipboard.min.js"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/popper.min.js"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/anchor.min.js"></script>
<link href="01_01_OLSR_py_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="01_01_OLSR_py_files/libs/quarto-html/quarto-syntax-highlighting-af5ec82acda093b5ee751184164e9432.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="01_01_OLSR_py_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="01_01_OLSR_py_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="01_01_OLSR_py_files/libs/bootstrap/bootstrap-7714f832e6fc2622986168d4fba84f88.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#objetivo" id="toc-objetivo" class="nav-link active" data-scroll-target="#objetivo">Objetivo</a></li>
  <li><a href="#metodolog√≠a" id="toc-metodolog√≠a" class="nav-link" data-scroll-target="#metodolog√≠a">Metodolog√≠a</a></li>
  <li><a href="#pasos-generales-del-machine-learning-supervisado" id="toc-pasos-generales-del-machine-learning-supervisado" class="nav-link" data-scroll-target="#pasos-generales-del-machine-learning-supervisado"><strong>Pasos generales del Machine Learning supervisado</strong></a></li>
  <li><a href="#base-de-datos" id="toc-base-de-datos" class="nav-link" data-scroll-target="#base-de-datos">Base de datos</a></li>
  <li><a href="#entrenamiento-de-los-datos-traintest" id="toc-entrenamiento-de-los-datos-traintest" class="nav-link" data-scroll-target="#entrenamiento-de-los-datos-traintest">Entrenamiento de los datos (train/test)</a></li>
  <li><a href="#entrenamiento-del-modelo" id="toc-entrenamiento-del-modelo" class="nav-link" data-scroll-target="#entrenamiento-del-modelo">Entrenamiento del modelo</a></li>
  <li><a href="#selecci√≥n-de-variables" id="toc-selecci√≥n-de-variables" class="nav-link" data-scroll-target="#selecci√≥n-de-variables">Selecci√≥n de variables</a>
  <ul class="collapse">
  <li><a href="#criterio-de-informaci√≥n-de-akaike" id="toc-criterio-de-informaci√≥n-de-akaike" class="nav-link" data-scroll-target="#criterio-de-informaci√≥n-de-akaike">Criterio de Informaci√≥n de Akaike</a></li>
  <li><a href="#interpretaci√≥n-final" id="toc-interpretaci√≥n-final" class="nav-link" data-scroll-target="#interpretaci√≥n-final">Interpretaci√≥n Final</a></li>
  <li><a href="#forward-or-backward-stepwise" id="toc-forward-or-backward-stepwise" class="nav-link" data-scroll-target="#forward-or-backward-stepwise">Forward or backward stepwise</a></li>
  <li><a href="#variance-inflation-factor-vif" id="toc-variance-inflation-factor-vif" class="nav-link" data-scroll-target="#variance-inflation-factor-vif">Variance Inflation Factor (<code>VIF</code>)</a></li>
  </ul></li>
  <li><a href="#evaluaci√≥n-del-modelo" id="toc-evaluaci√≥n-del-modelo" class="nav-link" data-scroll-target="#evaluaci√≥n-del-modelo">Evaluaci√≥n del modelo</a>
  <ul class="collapse">
  <li><a href="#modelo-predictivo" id="toc-modelo-predictivo" class="nav-link" data-scroll-target="#modelo-predictivo">Modelo predictivo</a></li>
  <li><a href="#evaluar-el-desempe√±o-predictivo" id="toc-evaluar-el-desempe√±o-predictivo" class="nav-link" data-scroll-target="#evaluar-el-desempe√±o-predictivo">Evaluar el desempe√±o predictivo</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Ordinary Least Squares Regression (OLSR)</h1>
<p class="subtitle lead">Apuntes y anotaciones personales</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Diana Villasana Ocampo </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<style type="text/css">
body {
text-align: justify;
font-style: normal;
font-family: "Montserrat";
font-size: 12px
}
h1.title {
  font-size: 40px;
  color: #000D3B;
}
h1 {
  font-size: 35px;
  color: #B6854D;
}
h2 {
  font-size: 30px;
  color: #172984;
}
h3 {
  font-size: 25px;
  color: #172984;
}
h4 {
  font-size: 22px;
  color: #172984;
}
h5 {
  ont-size: 20px;
  color: #172984;
}
h6{
  ont-size: 18px;
  color: #1864cb;
}
</style>
<style>
.nav>li>a {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #1C3BA4
}
.nav-pills>li.active>a, .nav-pills>li.active>a:hover, .nav-pills>li>a:focus {
    color: #ffffff;
    background-color: #09C2BC
}
</style>
<style>
.tile1-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6A87;
    list-style: none;
}
.top1-tiles a:nth-of-type(1):hover, .top-tiles1 a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6A87
}
</style>
<style>
.tile2-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6CC8;
    list-style: none;
}
.top2-tiles a:nth-of-type(1):hover, .top2-tiles a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6CC8
}
</style>
<style>
.math {
  font-size: 15px;
  color: #1e42ab;
}

.callout {
  border: 1px solid red; /* Yellow border */
  background-color: lightgrey; /* Light yellow background */
  padding: 15px;
  margin-bottom: 15px;
  border-left: 5px solid #ffcc00; /* Stronger left border */
}

</style>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Este material es reproducible en c√≥digo Python utilizando Quarto
</div>
</div>
<div class="callout-body-container callout-body">

</div>
</div>
<p>La Regresi√≥n por M√≠nimos Cuadrados Ordinarios (Ordinary Least Squares Regression, <strong>OLSR</strong> u <strong>OLS</strong>) representa una metodolog√≠a estad√≠stica esencial que permite analizar la correlaci√≥n entre una <strong>variable dependiente</strong> (tambi√©n conocida como variable de respuesta) y una o m√°s <strong>variables independientes</strong> (o predictoras). Este m√©todo constituye una herramienta fundamental en el campo del an√°lisis de regresi√≥n lineal.</p>
<p align="center">
</p><p><img src="../../img/Regression/01_image_OLSR.png" alt="Machine Learning Steps" width="40%"></p>
<p></p>
<p><strong>Librer√≠as que se usaron en el documento</strong></p>
<div id="load-py-pckgs" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#conda install -c conda-forge numpy</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#conda install -c conda-forge pandas</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#conda install -c conda-forge scikit-learn</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os <span class="co"># Necesario para la funci√≥n os.makedirs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c8eccfd4" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display" data-execution_count="3">
<style type="text/css">
#T_0721e td {
  padding: 1px;
}
#T_0721e_row0_col0, #T_0721e_row0_col1, #T_0721e_row1_col0, #T_0721e_row1_col1, #T_0721e_row2_col0, #T_0721e_row2_col1, #T_0721e_row3_col0, #T_0721e_row3_col1, #T_0721e_row4_col0, #T_0721e_row4_col1, #T_0721e_row5_col0, #T_0721e_row5_col1, #T_0721e_row6_col0, #T_0721e_row6_col1, #T_0721e_row7_col0, #T_0721e_row7_col1, #T_0721e_row8_col0, #T_0721e_row8_col1, #T_0721e_row9_col0, #T_0721e_row9_col1, #T_0721e_row10_col0, #T_0721e_row10_col1, #T_0721e_row11_col0, #T_0721e_row11_col1, #T_0721e_row12_col0, #T_0721e_row12_col1 {
  width: 200px;
  text-align: left;
}
#T_0721e_row0_col2, #T_0721e_row1_col2, #T_0721e_row2_col2, #T_0721e_row3_col2, #T_0721e_row4_col2, #T_0721e_row5_col2, #T_0721e_row6_col2, #T_0721e_row7_col2, #T_0721e_row8_col2, #T_0721e_row9_col2, #T_0721e_row10_col2, #T_0721e_row11_col2, #T_0721e_row12_col2 {
  width: 500px;
  text-align: left;
}
</style>

<div id="T_0721e" class="quarto-float quarto-figure quarto-figure-center anchored" style="font-family: Century Gothic; font-size: 10pt;" data-quarto-postprocess="true">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="T_0721e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Fuente: Elaboraci√≥n propia
</figcaption>
<div aria-describedby="T_0721e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table id="T_0721e" class="caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_0721e_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Criterio</th>
<th id="T_0721e_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Aplica</th>
<th id="T_0721e_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Detalles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_0721e_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_0721e_row0_col0" class="data row0 col0">üîç Tipo de modelo</td>
<td id="T_0721e_row0_col1" class="data row0 col1">Supervisado</td>
<td id="T_0721e_row0_col2" class="data row0 col2">Se entrena con datos X ‚Üí y</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_0721e_row1_col0" class="data row1 col0">üéØ Variable respuesta</td>
<td id="T_0721e_row1_col1" class="data row1 col1">Num√©rica continua</td>
<td id="T_0721e_row1_col2" class="data row1 col2">Ej. mpg, precio, ingresos</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_0721e_row2_col0" class="data row2 col0">üî¢ Variables predictoras</td>
<td id="T_0721e_row2_col1" class="data row2 col1">Num√©ricas y/o categ√≥ricas</td>
<td id="T_0721e_row2_col2" class="data row2 col2">Categor√≠as convertidas a dummies</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_0721e_row3_col0" class="data row3 col0">üìà Relaci√≥n entre variables</td>
<td id="T_0721e_row3_col1" class="data row3 col1">Lineal (supuesto clave)</td>
<td id="T_0721e_row3_col2" class="data row3 col2">Se asume una relaci√≥n lineal entre X e Y</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_0721e_row4_col0" class="data row4 col0">üß™ Normalidad de residuos</td>
<td id="T_0721e_row4_col1" class="data row4 col1">Deseable</td>
<td id="T_0721e_row4_col2" class="data row4 col2">Importante para intervalos de confianza v√°lidos</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_0721e_row5_col0" class="data row5 col0">üîÅ Independencia de errores</td>
<td id="T_0721e_row5_col1" class="data row5 col1">Necesaria</td>
<td id="T_0721e_row5_col2" class="data row5 col2">Errores deben ser independientes</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_0721e_row6_col0" class="data row6 col0">‚öñÔ∏è Homoscedasticidad</td>
<td id="T_0721e_row6_col1" class="data row6 col1">Necesaria</td>
<td id="T_0721e_row6_col2" class="data row6 col2">Varianza de errores debe ser constante</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_0721e_row7_col0" class="data row7 col0">‚ùó Sensible a outliers</td>
<td id="T_0721e_row7_col1" class="data row7 col1">S√≠</td>
<td id="T_0721e_row7_col2" class="data row7 col2">Outliers pueden influir mucho en el modelo</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_0721e_row8_col0" class="data row8 col0">üîó Multicolinealidad entre predictores</td>
<td id="T_0721e_row8_col1" class="data row8 col1">Problema com√∫n</td>
<td id="T_0721e_row8_col2" class="data row8 col2">Usar VIF para detectar problemas</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_0721e_row9_col0" class="data row9 col0">üß† Interpretabilidad</td>
<td id="T_0721e_row9_col1" class="data row9 col1">Alta</td>
<td id="T_0721e_row9_col2" class="data row9 col2">Modelo f√°cil de explicar</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">10</td>
<td id="T_0721e_row10_col0" class="data row10 col0">üöÄ Velocidad y eficiencia</td>
<td id="T_0721e_row10_col1" class="data row10 col1">Muy alta</td>
<td id="T_0721e_row10_col2" class="data row10 col2">R√°pido incluso con datos grandes</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">11</td>
<td id="T_0721e_row11_col0" class="data row11 col0">üß™ Validaci√≥n cruzada</td>
<td id="T_0721e_row11_col1" class="data row11 col1">Compatible</td>
<td id="T_0721e_row11_col2" class="data row11 col2">Ayuda a prevenir overfitting</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row12" class="row_heading level0 row12" data-quarto-table-cell-role="th">12</td>
<td id="T_0721e_row12_col0" class="data row12 col0">‚ùå No funciona bien si...</td>
<td id="T_0721e_row12_col1" class="data row12 col1">Relaciones no lineales, outliers severos, colinealidad</td>
<td id="T_0721e_row12_col2" class="data row12 col2">Evitar si no hay linealidad o hay muchos outliers</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
<section id="objetivo" class="level2">
<h2 class="anchored" data-anchor-id="objetivo">Objetivo</h2>
<p>La Regresi√≥n por M√≠nimos Cuadrados Ordinarios (<code>OLSR</code>) busca la l√≠nea que mejor se ajusta a los datos. Para lograrlo, reduce al m√≠nimo la suma de los cuadrados de las diferencias entre los valores reales y los valores que predice el modelo. Estas diferencias son los <strong>residuos</strong> o <strong>errores</strong>. Al trabajar con los cuadrados de los errores, este m√©todo evita que los errores positivos y negativos se anulen entre s√≠, y da m√°s peso a los errores grandes durante el proceso de minimizaci√≥n.</p>
</section>
<section id="metodolog√≠a" class="level2">
<h2 class="anchored" data-anchor-id="metodolog√≠a">Metodolog√≠a</h2>
<p>La metodolog√≠a de OLSR se basa en los siguientes pasos y principios:</p>
<ol type="1">
<li><p><strong>Modelo Lineal:</strong> OLSR asume una relaci√≥n lineal entre las variables. Para una regresi√≥n lineal simple (una variable independiente), la ecuaci√≥n es:<br>
<span class="math display">\[Y = \beta_0 + \beta_1X + \epsilon\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(Y\)</span> es la variable dependiente.</li>
</ul></li>
</ol>
<ul>
<li><span class="math inline">\(X\)</span> es la variable independiente.</li>
<li><span class="math inline">\(\beta_0\)</span> es el intercepto (el valor de <span class="math inline">\(Y\)</span> cuando <span class="math inline">\(X\)</span> es 0).</li>
<li><span class="math inline">\(\beta_1\)</span> es la pendiente (el cambio en <span class="math inline">\(Y\)</span> por cada unidad de cambio en <span class="math inline">\(X\)</span>).</li>
<li><span class="math inline">\(\epsilon\)</span> es el t√©rmino de error o residual, que representa la parte de <span class="math inline">\(Y\)</span> que no puede ser explicada por <span class="math inline">\(X\)</span>.</li>
</ul>
<p>Para una regresi√≥n lineal m√∫ltiple (varias variables independientes), la ecuaci√≥n se expande a:<br>
<span class="math display">\[Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k + \epsilon\]</span></p>
<ol start="2" type="1">
<li><strong>Minimizaci√≥n de la Suma de Cuadrados de Residuos (SSR):</strong> El coraz√≥n de OLS es encontrar los valores de los coeficientes (<span class="math inline">\(\beta_0, \beta_1\)</span>, etc.) que minimicen la siguiente funci√≥n:<br>
<span class="math display">\[\text{Minimizar } \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span><br>
Donde:
<ul>
<li><span class="math inline">\(y_i\)</span> es el valor observado de la variable dependiente para la observaci√≥n <span class="math inline">\(i\)</span>.</li>
</ul></li>
</ol>
<ul>
<li><span class="math inline">\(\hat{y}_i\)</span> es el valor predicho de la variable dependiente por el modelo para la observaci√≥n <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\((y_i - \hat{y}_i)\)</span> es el residual para la observaci√≥n <span class="math inline">\(i\)</span>.</li>
</ul>
<p>Para lograr esta minimizaci√≥n, se utilizan t√©cnicas de c√°lculo (derivadas parciales) para encontrar los valores de los coeficientes que hacen que la pendiente de la funci√≥n de suma de cuadrados sea cero.</p>
<ol start="3" type="1">
<li><p><strong>Estimaci√≥n de Coeficientes:</strong> Los valores estimados de los coeficientes, denotados como <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span>, etc., son aquellos que resultan de la minimizaci√≥n. Estos coeficientes son los que definen la ‚Äúl√≠nea de mejor ajuste‚Äù.</p></li>
<li><p><strong>Supuestos del OLS:</strong> Para que los estimadores de OLS sean los ‚Äúmejores estimadores lineales insesgados‚Äù (seg√∫n el Teorema de Gauss-Markov), se deben cumplir ciertas suposiciones:</p>
<ul>
<li><p><strong>Linealidad:</strong> La relaci√≥n entre las variables es lineal.</p></li>
<li><p><strong>Independencia de los errores:</strong> Los errores de una observaci√≥n no est√°n correlacionados con los errores de otra.</p></li>
<li><p><strong>Homocedasticidad:</strong> La varianza de los errores es constante en todos los niveles de las variables independientes.</p></li>
<li><p><strong>Normalidad de los errores:</strong> Los errores se distribuyen normalmente (aunque no es estrictamente necesario para la estimaci√≥n, s√≠ lo es para la inferencia estad√≠stica).</p></li>
<li><p><strong>No multicolinealidad perfecta:</strong> Las variables independientes no est√°n perfectamente correlacionadas entre s√≠.</p></li>
</ul></li>
</ol>
</section>
<section id="pasos-generales-del-machine-learning-supervisado" class="level2">
<h2 class="anchored" data-anchor-id="pasos-generales-del-machine-learning-supervisado"><strong>Pasos generales del Machine Learning supervisado</strong></h2>
<ol type="1">
<li><strong>Importar y explorar los datos</strong></li>
<li><strong>Preprocesamiento</strong></li>
<li><strong>Divisi√≥n de los datos (train/test)</strong></li>
<li><strong>Entrenamiento del modelo</strong></li>
<li><strong>Evaluaci√≥n del modelo</strong></li>
<li><strong>Ajustes o validaci√≥n cruzada (si aplica)</strong></li>
<li><strong>Predicci√≥n con nuevos datos</strong></li>
<li><strong>Interpretaci√≥n de resultados</strong></li>
</ol>
<p align="center">
<img src="../../img/ML_Steps.png" alt="Machine Learning Steps" width="100%">
</p>
<hr>
</section>
<section id="base-de-datos" class="level2">
<h2 class="anchored" data-anchor-id="base-de-datos">Base de datos</h2>
<p>La base de datos <code>mtcars</code> es un conjunto de datos cl√°sico en R que contiene informaci√≥n sobre <strong>32 autom√≥viles</strong> (modelos de 1973‚Äì74), y fue extra√≠do de la revista <em>Motor Trend US</em>. Incluye <strong>variables t√©cnicas</strong> del desempe√±o de los autos.</p>
<p>Aqu√≠ est√° una descripci√≥n de cada columna:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 47%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Significado</th>
<th>Tipo de dato</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>mpg</code></td>
<td>Miles per gallon (millas por gal√≥n)</td>
<td>Num√©rica</td>
</tr>
<tr class="even">
<td><code>cyl</code></td>
<td>N√∫mero de cilindros</td>
<td>Entero</td>
</tr>
<tr class="odd">
<td><code>disp</code></td>
<td>Desplazamiento del motor (en pulgadas c√∫bicas)</td>
<td>Num√©rica</td>
</tr>
<tr class="even">
<td><code>hp</code></td>
<td>Caballos de fuerza</td>
<td>Entero</td>
</tr>
<tr class="odd">
<td><code>drat</code></td>
<td>Relaci√≥n del eje trasero (rear axle ratio)</td>
<td>Num√©rica</td>
</tr>
<tr class="even">
<td><code>wt</code></td>
<td>Peso del auto (en miles de libras)</td>
<td>Num√©rica</td>
</tr>
<tr class="odd">
<td><code>qsec</code></td>
<td>Tiempo en 1/4 de milla (segundos)</td>
<td>Num√©rica</td>
</tr>
<tr class="even">
<td><code>vs</code></td>
<td>Tipo de motor: 0 = V-shaped, 1 = straight (en l√≠nea)</td>
<td>Binaria (factor)</td>
</tr>
<tr class="odd">
<td><code>am</code></td>
<td>Tipo de transmisi√≥n: 0 = autom√°tica, 1 = manual</td>
<td>Binaria (factor)</td>
</tr>
<tr class="even">
<td><code>gear</code></td>
<td>N√∫mero de velocidades (marchas) adelante</td>
<td>Entero</td>
</tr>
<tr class="odd">
<td><code>carb</code></td>
<td>N√∫mero de carburadores</td>
<td>Entero</td>
</tr>
</tbody>
</table>
<div id="3657a813" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>require(reticulate)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>reticulate::repl_python() <span class="co">#can be used to interactively run Python code</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Cargar y se exploran los datos</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>data(<span class="st">"mtcars"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b4367e8d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#pip install openpyxl </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os <span class="co"># Necesario para la funci√≥n os.makedirs</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar la base de datos mtcars directamente desde el entorno de R</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># r.mtcars accede al objeto 'mtcars' que R ha puesto a disposici√≥n</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Reticulate autom√°ticamente lo convierte a un DataFrame de Pandas.</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> r.mtcars</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">## Se guarda la base de datos en un archivo Excel  </span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">file</span> <span class="op">=</span> Path.cwd().parent.parent <span class="op">/</span> <span class="st">"Data"</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>mtcars_df.to_excel(<span class="bu">file</span> <span class="op">/</span><span class="st">"mtcars_data.xlsx"</span>, index<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="50bfc000" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> pd.read_excel(Path.cwd().parent.parent <span class="op">/</span> <span class="st">"Data"</span> <span class="op">/</span> <span class="st">"mtcars_data.xlsx"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3e42bd2e" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">cyl</th>
<th data-quarto-table-cell-role="th">disp</th>
<th data-quarto-table-cell-role="th">hp</th>
<th data-quarto-table-cell-role="th">drat</th>
<th data-quarto-table-cell-role="th">wt</th>
<th data-quarto-table-cell-role="th">qsec</th>
<th data-quarto-table-cell-role="th">vs</th>
<th data-quarto-table-cell-role="th">am</th>
<th data-quarto-table-cell-role="th">gear</th>
<th data-quarto-table-cell-role="th">carb</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Mazda RX4</td>
<td>21.0</td>
<td>6</td>
<td>160.0</td>
<td>110</td>
<td>3.90</td>
<td>2.620</td>
<td>16.46</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Mazda RX4 Wag</td>
<td>21.0</td>
<td>6</td>
<td>160.0</td>
<td>110</td>
<td>3.90</td>
<td>2.875</td>
<td>17.02</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Datsun 710</td>
<td>22.8</td>
<td>4</td>
<td>108.0</td>
<td>93</td>
<td>3.85</td>
<td>2.320</td>
<td>18.61</td>
<td>1</td>
<td>1</td>
<td>4</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Hornet 4 Drive</td>
<td>21.4</td>
<td>6</td>
<td>258.0</td>
<td>110</td>
<td>3.08</td>
<td>3.215</td>
<td>19.44</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Hornet Sportabout</td>
<td>18.7</td>
<td>8</td>
<td>360.0</td>
<td>175</td>
<td>3.15</td>
<td>3.440</td>
<td>17.02</td>
<td>0</td>
<td>0</td>
<td>3</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>Valiant</td>
<td>18.1</td>
<td>6</td>
<td>225.0</td>
<td>105</td>
<td>2.76</td>
<td>3.460</td>
<td>20.22</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>Duster 360</td>
<td>14.3</td>
<td>8</td>
<td>360.0</td>
<td>245</td>
<td>3.21</td>
<td>3.570</td>
<td>15.84</td>
<td>0</td>
<td>0</td>
<td>3</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>Merc 240D</td>
<td>24.4</td>
<td>4</td>
<td>146.7</td>
<td>62</td>
<td>3.69</td>
<td>3.190</td>
<td>20.00</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>Merc 230</td>
<td>22.8</td>
<td>4</td>
<td>140.8</td>
<td>95</td>
<td>3.92</td>
<td>3.150</td>
<td>22.90</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>Merc 280</td>
<td>19.2</td>
<td>6</td>
<td>167.6</td>
<td>123</td>
<td>3.92</td>
<td>3.440</td>
<td>18.30</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><strong>Convertir todas las columnas a tipo num√©rico</strong></p>
<div id="f8e3e877" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- IMPORTANTE: Convertir todas las columnas a tipo num√©rico ---</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es crucial para evitar el TypeError</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 'errors='coerce'' convertir√° cualquier valor no num√©rico a NaN</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># y luego se pueden manejar los NaNs (por ejemplo, rellenar o eliminar)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> mtcars_df.<span class="bu">apply</span>(pd.to_numeric, errors<span class="op">=</span><span class="st">'coerce'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="entrenamiento-de-los-datos-traintest" class="level2">
<h2 class="anchored" data-anchor-id="entrenamiento-de-los-datos-traintest">Entrenamiento de los datos (train/test)</h2>
<p>La divisi√≥n de datos en conjuntos de <strong>entrenamiento (train)</strong> y <strong>prueba (test)</strong> es una pr√°ctica fundamental en el aprendizaje autom√°tico y la modelizaci√≥n predictiva. Su importancia radica en la necesidad de obtener una evaluaci√≥n <strong>realista y no sesgada</strong> del rendimiento de un modelo, y de asegurar que el modelo sea capaz de <strong>generalizar</strong> a datos nuevos y no vistos.</p>
<ul>
<li>En Python, <code>train_test_split()</code> devuelve directamente los cuatro conjuntos de datos:
<ul>
<li><code>X_train</code>: Predictoras para entrenamiento.</li>
</ul></li>
<li><code>X_test</code>: Predictoras para prueba.</li>
<li><code>y_train</code>: Variable objetivo para entrenamiento.</li>
<li><code>y_test</code>: Variable objetivo para prueba.</li>
</ul>
<div id="split-data" class="cell" data-message="false" data-execution_count="11">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np <span class="co"># Necesario si necesitas setear una semilla para numpy/pandas</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir la variable objetivo (dependiente)</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>target_variable <span class="op">=</span> <span class="st">'mpg'</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># X contendr√° todas las variables predictoras (features)</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Y contendr√° la variable objetivo</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> mtcars_df.drop(columns<span class="op">=</span>[target_variable])</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> mtcars_df[target_variable]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Dividir los datos en entrenamiento y prueba</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># random_state es el equivalente a set.seed() para reproducibilidad</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># test_size=0.2 significa que el 20% de los datos ir√°n al conjunto de prueba (80% para entrenamiento)</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es importante para asegurar que las proporciones de 'mpg' sean similares en ambos conjuntos,</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># especialmente √∫til para variables categ√≥ricas o si la distribuci√≥n de 'mpg' es importante.</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tama√±o del conjunto de entrenamiento (X_train): </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tama√±o del conjunto de prueba (X_test): </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tama√±o del conjunto de entrenamiento (y_train): </span><span class="sc">{</span>y_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tama√±o del conjunto de prueba (y_test): </span><span class="sc">{</span>y_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tama√±o del conjunto de entrenamiento (X_train): (25, 11)
Tama√±o del conjunto de prueba (X_test): (7, 11)
Tama√±o del conjunto de entrenamiento (y_train): (25,)
Tama√±o del conjunto de prueba (y_test): (7,)</code></pre>
</div>
</div>
<ul>
<li>Particionar los datos, evita el <strong>overfitting</strong> (cuando el modelo memoriza los datos de entrenamiento).</li>
<li>Permite una <strong>evaluaci√≥n honesta</strong> del modelo al probarlo en datos que no vio durante el entrenamiento.</li>
<li>Es una pr√°ctica est√°ndar en cualquier pipeline de aprendizaje autom√°tico.</li>
</ul>
</section>
<section id="entrenamiento-del-modelo" class="level2">
<h2 class="anchored" data-anchor-id="entrenamiento-del-modelo">Entrenamiento del modelo</h2>
<p>El <strong>entrenamiento de un modelo</strong> es el paso m√°s importante en el aprendizaje autom√°tico. Usando un conjunto de datos de entrenamiento (<code>train_data</code>), el modelo aprende a reconocer patrones para hacer predicciones confiables con datos nuevos. Este proceso es esencial por estas razones:</p>
<ul>
<li>Durante el entrenamiento, el modelo <strong>identifica patrones espec√≠ficos</strong> en los datos.</li>
<li>Separamos los datos en grupos de entrenamiento y prueba para asegurar que el modelo funcione bien no solo con datos conocidos, sino tambi√©n con <strong>datos nuevos y no vistos</strong>.</li>
<li>Despu√©s del entrenamiento con <code>train_data</code>, usamos el <strong>conjunto de prueba (<code>test_data</code>)</strong> para medir el rendimiento. Las m√©tricas (MAE, RMSE, <span class="math inline">\(R^2\)</span>) nos muestran qu√© tan bien el modelo <strong>maneja datos nuevos</strong>.</li>
<li>Un rendimiento peor en <code>test_data</code> que en <code>train_data</code> indica que el modelo est√° sobreajustado.</li>
<li>Con estos resultados, podemos decidir si el modelo est√° listo para usar o necesita ajustes.</li>
</ul>
<p><strong>Funci√≥n de entrenamiento</strong></p>
<ul>
<li><code>modelo_ols_py = smf.ols(formula=formula, data=train_data_combined).fit()</code>:</li>
<li><code>smf.ols()</code>: Es la funci√≥n para ajustar un modelo de M√≠nimos Cuadrados Ordinarios (Ordinary Least Squares - OLS).</li>
<li><code>formula=formula</code>: Le pasamos la cadena de f√≥rmula que definimos.</li>
<li><code>data=train_data_combined</code>: Le indicamos de qu√© DataFrame debe tomar las variables.</li>
<li><code>.fit()</code>: Este m√©todo entrena el modelo sobre los datos.</li>
</ul>
<div id="train-ols-model" class="cell" data-message="false" data-results="as-is" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf <span class="co"># Para la sintaxis tipo R de f√≥rmulas</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Asumiendo que X_train, X_test, y_train, y_test ya est√°n definidos</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># por el chunk de divisi√≥n de datos anterior.</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Para asegurar que X_train y y_train se combinen correctamente para statsmodels</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># statsmodels prefiere un solo DataFrame que contenga todas las variables</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es similar a c√≥mo `lm` en R usa `data = train_data`</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Combinar X_train y y_train en un solo DataFrame para statsmodels</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>train_data_combined <span class="op">=</span> pd.concat([X_train, y_train], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir la f√≥rmula del modelo (similar a R)</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># mpg ~ . significa "mpg en funci√≥n de todas las dem√°s variables en el DataFrame"</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Para statsmodels, es mejor listar expl√≠citamente las columnas si X_train tiene muchas</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># O si quieres un subconjunto espec√≠fico, lo especificas aqu√≠.</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Aqu√≠ construimos la f√≥rmula din√°micamente para incluir todas las variables de X_train</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>y_train<span class="sc">.</span>name<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(X_train.columns)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Entrenar el modelo de regresi√≥n lineal (OLS)</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># statsmodels.formula.api permite usar la sintaxis de f√≥rmula similar a R</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>modelo_ols_py <span class="op">=</span> smf.ols(formula <span class="op">=</span> formula, data <span class="op">=</span> train_data_combined).fit()</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Revisar resumen del modelo (similar a summary() en R)</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Resumen del Modelo OLS en Python:"</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(modelo_ols_py.summary()) <span class="co"># .as_html() para una salida bonita en Quarto</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Resumen del Modelo OLS en Python:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.896
Model:                            OLS   Adj. R-squared:                  0.821
Method:                 Least Squares   F-statistic:                     12.00
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           3.06e-05
Time:                        15:17:58   Log-Likelihood:                -52.439
No. Observations:                  25   AIC:                             126.9
Df Residuals:                      14   BIC:                             140.3
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept    -19.2700     31.016     -0.621      0.544     -85.792      47.252
cyl            1.0972      1.593      0.689      0.502      -2.319       4.513
disp           0.0062      0.020      0.307      0.764      -0.037       0.049
hp            -0.0053      0.025     -0.212      0.835      -0.059       0.048
drat           1.8203      2.101      0.866      0.401      -2.687       6.327
wt            -3.6682      2.289     -1.603      0.131      -8.577       1.241
qsec           2.1398      1.379      1.552      0.143      -0.817       5.097
vs             0.8514      4.586      0.186      0.855      -8.985      10.688
am             5.8806      3.918      1.501      0.156      -2.523      14.285
gear          -1.0928      2.698     -0.405      0.692      -6.879       4.694
carb           0.0325      0.975      0.033      0.974      -2.060       2.125
==============================================================================
Omnibus:                        2.342   Durbin-Watson:                   1.335
Prob(Omnibus):                  0.310   Jarque-Bera (JB):                1.544
Skew:                           0.374   Prob(JB):                        0.462
Kurtosis:                       2.040   Cond. No.                     1.94e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.94e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<p>Como resultado se da una visi√≥n general de qu√© tan bien el modelo se ajusta a los datos:</p>
<ul>
<li><strong><code>R-squared: 0.896</code></strong>: Tambi√©n conocido como <strong>coeficiente de determinaci√≥n</strong>. Esto significa que el 89.6% de la variabilidad en <code>mpg</code> puede ser explicada por las variables predictoras en tu modelo. ¬°Este es un valor bastante alto, lo que sugiere que tu modelo explica una gran parte de la variaci√≥n en <code>mpg</code>!
<ul>
<li><strong><code>Adj. R-squared: 0.821</code></strong>: El <strong>R-cuadrado ajustado</strong> es una versi√≥n del R-cuadrado que penaliza el modelo por cada variable predictora adicional. Es m√°s √∫til cuando comparas modelos con diferentes n√∫meros de predictores. Un valor de 0.821 sigue siendo muy bueno y sugiere que el alto R-cuadrado no es solo por a√±adir muchas variables sin valor.</li>
</ul></li>
<li><strong><code>F-statistic: 12.00</code></strong>: La <strong>Estad√≠stica F</strong> eval√∫a la significancia global del modelo. Prueba la hip√≥tesis nula de que todos los coeficientes de las variables predictoras son cero (es decir, que ninguna de tus variables predictoras tiene un efecto significativo sobre <code>mpg</code>).</li>
<li><strong><code>Prob (F-statistic): 3.06e-05</code></strong>: Este es el <strong>p-valor asociado a la Estad√≠stica F</strong>. Un valor tan peque√±o (3.06e-05, que es 0.0000306) es mucho menor que el nivel de significancia com√∫n (0.05). Esto significa que <strong>el modelo en su conjunto es estad√≠sticamente significativo</strong>, y al menos una de tus variables predictoras tiene un efecto significativo sobre <code>mpg</code>.</li>
</ul>
<p><strong>Estad√≠sticos</strong></p>
<p>Estas m√©tricas ayudan a evaluar si el modelo cumple con los supuestos de la regresi√≥n lineal:</p>
<ul>
<li><strong><code>Omnibus</code>, <code>Prob(Omnibus)</code>, <code>Jarque-Bera (JB)</code>, <code>Prob(JB)</code>, <code>Skew</code>, <code>Kurtosis</code></strong>: Estas son pruebas de <strong>normalidad de los residuos</strong>.</li>
<li><code>Prob(Omnibus): 0.310</code> y <code>Prob(JB): 0.462</code> (ambos &gt; 0.05) sugieren que <strong>los residuos son aproximadamente normales</strong>, lo cual es bueno.</li>
<li><code>Skew</code> (Asimetr√≠a) y <code>Kurtosis</code> (Curtosis) describen la forma de la distribuci√≥n de los residuos. Valores cercanos a 0 para <code>Skew</code> y cercanos a 3 para <code>Kurtosis</code> (o 0 para <code>Excess Kurtosis</code>, que es lo que se interpreta a menudo) indican normalidad. Tus valores son razonables.</li>
<li><strong><code>Durbin-Watson: 1.335</code></strong>: Esta prueba detecta la <strong>autocorrelaci√≥n en los residuos</strong>.
<ul>
<li>Un valor cercano a 2 indica poca o ninguna autocorrelaci√≥n.</li>
<li>Valores muy por debajo de 2 (como 1.335) pueden sugerir cierta autocorrelaci√≥n positiva (residuos adyacentes est√°n correlacionados), lo cual es una violaci√≥n de los supuestos y podr√≠a afectar la validez de tus errores est√°ndar y p-valores.</li>
</ul></li>
<li><strong>`<code>Cond. No.: 1.94e+04</code></strong>: El <strong>N√∫mero de Condici√≥n</strong>.
<ul>
<li>Este valor es una medida de <strong>multicolinealidad</strong>.</li>
<li>Un valor alto (generalmente &gt; 1000, y este es de 19400) <strong>indica una fuerte multicolinealidad</strong> entre las variables predictoras. Esto confirma la sospecha de la tabla de coeficientes: tus variables est√°n altamente correlacionadas entre s√≠, lo que dificulta al modelo discernir el efecto √∫nico de cada una. Esta es la raz√≥n m√°s probable por la que el modelo es significativo en general, pero los predictores individuales no lo son.</li>
</ul></li>
</ul>
<p><strong>¬øPor qu√© los resultados de R y Python son diferentes a pesar de usar la misma l√≥gica?</strong></p>
<p>La raz√≥n principal por la que obtienes resultados ligeramente diferentes en R y Python para los coeficientes, errores est√°ndar y p-valores (aunque las m√©tricas generales como R-cuadrado y F-estad√≠stico son muy similares) es debido a la <strong>naturaleza aleatoria de la divisi√≥n de los datos en entrenamiento y prueba</strong>.</p>
<section id="observaciones-generales" class="level4">
<h4 class="anchored" data-anchor-id="observaciones-generales">üìå <strong>Observaciones generales</strong></h4>
<ul>
<li><p>El modelo tiene un <strong>muy buen R¬≤</strong> (89.6%) ‚áí explica bien la variabilidad en <code>mpg</code>.</p></li>
<li><p><strong>El modelo completo es estad√≠sticamente significativo</strong>, pero <strong>ninguna variable individual lo es</strong>, lo que probablemente se deba a <strong>multicolinealidad</strong>.</p></li>
<li><p>Considera usar:</p>
<ul>
<li><strong>An√°lisis de VIF</strong> (Variance Inflation Factor) para detectar multicolinealidad.</li>
<li><strong>Reducci√≥n de dimensionalidad</strong> (PCA, selecci√≥n de variables).</li>
<li><strong>Regularizaci√≥n</strong> (Ridge/Lasso) para mejorar la estabilidad del modelo.</li>
</ul></li>
</ul>
<div id="cell-scatter-plots-faceted" class="cell" data-fig-height="8" data-fig-width="10" data-message="false" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine <span class="im">import</span> (</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    ggplot, aes, geom_point, geom_smooth, facet_wrap,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    theme_bw, theme, element_text, labs</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar datos de ejemplo si no tienes mtcars_df</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine.data <span class="im">import</span> mtcars</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> mtcars.copy()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Preparaci√≥n de los datos</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>tabla_py <span class="op">=</span> (</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>            mtcars_df</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>           .drop(columns <span class="op">=</span> [<span class="st">'name'</span>], errors <span class="op">=</span> <span class="st">'ignore'</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>           .melt(id_vars <span class="op">=</span> [<span class="st">"mpg"</span>], var_name <span class="op">=</span> <span class="st">"variable"</span>, value_name <span class="op">=</span> <span class="st">"value"</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Crear el gr√°fico con plotnine</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> (</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    ggplot(tabla_py, aes(y <span class="op">=</span> <span class="st">"mpg"</span>, x <span class="op">=</span> <span class="st">"value"</span>, color <span class="op">=</span> <span class="st">"variable"</span>))</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> geom_point()</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> geom_smooth(method<span class="op">=</span><span class="st">"lm"</span>, se<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> theme_bw()</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> theme(</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        plot_title<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">22</span>),</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        plot_subtitle<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">18</span>),</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>        plot_caption<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">11</span>),</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>        axis_text<span class="op">=</span>element_text(),</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        axis_text_x <span class="op">=</span> element_text(angle <span class="op">=</span> <span class="dv">45</span>),</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        axis_title<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">15</span>),</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        legend_position<span class="op">=</span><span class="st">"none"</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> facet_wrap(<span class="st">"~variable"</span>, scales<span class="op">=</span><span class="st">"free"</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> labs(</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>        title<span class="op">=</span><span class="st">"Diagramas de dispersi√≥n"</span>,</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">""</span>,</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">""</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar el gr√°fico</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_01_OLSR_py_files/figure-html/scatter-plots-faceted-output-1.png" id="scatter-plots-faceted" width="672" height="480" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="selecci√≥n-de-variables" class="level2">
<h2 class="anchored" data-anchor-id="selecci√≥n-de-variables">Selecci√≥n de variables</h2>
<section id="criterio-de-informaci√≥n-de-akaike" class="level3">
<h3 class="anchored" data-anchor-id="criterio-de-informaci√≥n-de-akaike">Criterio de Informaci√≥n de Akaike</h3>
<p>El Criterio de Informaci√≥n de Akaike (AIC, por sus siglas en ingl√©s, Akaike Information Criterion) es una medida de la bondad de ajuste de un modelo estad√≠stico que penaliza la complejidad del modelo. Su objetivo es seleccionar el modelo que mejor se ajusta a los datos con la menor cantidad de par√°metros, evitando as√≠ el sobreajuste (overfitting).</p>
<p>La f√≥rmula general para calcular el AIC es:</p>
<p><span class="math display">\[AIC = 2k - 2\ln(L)\]</span></p>
<p>Donde:<br>
* <span class="math inline">\(k\)</span> es el n√∫mero de par√°metros del modelo. En un modelo de regresi√≥n, esto incluye el intercepto y los coeficientes de las variables predictoras, m√°s la varianza del error si se estima (en modelos de m√≠nimos cuadrados ordinarios, esto es a menudo el caso, por lo que <span class="math inline">\(k\)</span> a veces se cuenta como el n√∫mero de coeficientes + 1 para la varianza del error, o simplemente el n√∫mero de coeficientes si la varianza del error se considera impl√≠cita en la funci√≥n de verosimilitud).<br>
* <span class="math inline">\(\ln(L)\)</span> es el logaritmo natural del valor m√°ximo de la funci√≥n de verosimilitud (log-likelihood) del modelo. La funci√≥n de verosimilitud mide qu√© tan bien el modelo reproduce los datos observados.</p>
<section id="c√≥mo-se-interpreta" class="level4">
<h4 class="anchored" data-anchor-id="c√≥mo-se-interpreta">C√≥mo se interpreta:</h4>
<ul>
<li><strong>Valores m√°s bajos de AIC indican un mejor modelo.</strong> El AIC busca un equilibrio entre la bondad de ajuste del modelo a los datos (representada por <span class="math inline">\(\ln(L)\)</span>) y la complejidad del modelo (representada por <span class="math inline">\(2k\)</span>).<br>
</li>
<li>El t√©rmino <span class="math inline">\(2k\)</span> es una <strong>penalizaci√≥n por la complejidad</strong>. Cada par√°metro adicional en el modelo aumenta el valor de AIC, lo que desincentiva la inclusi√≥n de variables innecesarias que podr√≠an sobreajustar los datos.</li>
</ul>
</section>
<section id="para-modelos-de-regresi√≥n-por-m√≠nimos-cuadrados-ordinarios-ols" class="level4">
<h4 class="anchored" data-anchor-id="para-modelos-de-regresi√≥n-por-m√≠nimos-cuadrados-ordinarios-ols">Para modelos de Regresi√≥n por M√≠nimos Cuadrados Ordinarios (OLS):</h4>
<p>Aunque la f√≥rmula general del AIC es la que se mencion√≥, para modelos de OLS con residuos normalmente distribuidos, la funci√≥n de log-verosimilitud tiene una forma espec√≠fica, lo que permite reescribir el AIC de una manera m√°s pr√°ctica.</p>
<p>Para un modelo de regresi√≥n lineal con <span class="math inline">\(n\)</span> observaciones y <span class="math inline">\(k\)</span> par√°metros (incluyendo el intercepto), y asumiendo errores normales con varianza constante, el AIC se puede calcular como:</p>
<p><span class="math display">\[AIC = n \cdot \ln\left(\frac{RSS}{n}\right) + 2k\]</span></p>
<p>Donde:<br>
* <span class="math inline">\(n\)</span> es el n√∫mero de observaciones (tama√±o de la muestra).<br>
* <span class="math inline">\(RSS\)</span> es la Suma de Cuadrados de los Residuos (Residual Sum of Squares), que es la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo.<br>
* <span class="math inline">\(k\)</span> es el n√∫mero de par√°metros del modelo (coeficientes de las variables independientes + intercepto).</p>
<p><strong>Es importante recordar:</strong></p>
<ul>
<li>El AIC no es una prueba de hip√≥tesis en el sentido tradicional; no te dice si un modelo es ‚Äúbueno‚Äù o ‚Äúmalo‚Äù en un sentido absoluto.<br>
</li>
<li>Es una herramienta para la <strong>selecci√≥n de modelos entre un conjunto de modelos candidatos</strong>. Siempre se compara el AIC de diferentes modelos ajustados a los <strong>mismos datos</strong>. El modelo con el AIC m√°s bajo es el preferido.<br>
</li>
<li>Cuando la muestra es peque√±a, a veces se prefiere el <strong>AIC corregido (AICc)</strong>, que a√±ade una penalizaci√≥n adicional por el tama√±o de la muestra:<br>
<span class="math display">\[AICc = AIC + \frac{2k(k+1)}{n-k-1}\]</span></li>
</ul>
<p>A medida que <span class="math inline">\(n\)</span> (tama√±o de la muestra) es grande, el t√©rmino de correcci√≥n se vuelve insignificante y el AICc converge al AIC.</p>
<p>Se realiza una selecci√≥n autom√°tica de variables para un modelo de regresi√≥n lineal, utilizando el <strong>criterio AIC (Criterio de Informaci√≥n de Akaike</strong>)</p>
<p><strong>Implementaci√≥n de Selecci√≥n por Pasos (Stepwise) con AIC en Python</strong></p>
<p>Dado que <code>statsmodels</code> no tiene un <code>stepAIC</code> incorporado que funcione exactamente como en R con <code>direction="both"</code>, una forma com√∫n de lograr esto en Python es implementar la l√≥gica de forma manual o usar una funci√≥n auxiliar que la simule.</p>
<div id="stepwise-aic" class="cell" data-message="false" data-results="as-is" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Aunque no lo vamos a importar directamente aqu√≠, el concepto de AIC</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># est√° impl√≠cito en los resultados de summary() de statsmodels</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Asumiendo que X_train, y_train y train_data_combined</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># (el DataFrame combinado para statsmodels) ya est√°n definidos</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># desde los chunks anteriores.</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Y que modelo_ols_py ya fue ajustado.</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stepwise_selection_aic(data, target_variable, initial_features<span class="op">=</span><span class="va">None</span>, verbose<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Realiza una selecci√≥n de caracter√≠sticas por pasos (forward y backward)</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">    basada en el Criterio de Informaci√≥n de Akaike (AIC).</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">        data (pd.DataFrame): El DataFrame de entrenamiento combinado (X y y).</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">        target_variable (str): El nombre de la columna de la variable dependiente.</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">        initial_features (list): Lista opcional de caracter√≠sticas para empezar.</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">                                 Si es None, empieza con un modelo nulo o con todas.</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose (bool): Si es True, imprime los pasos del proceso.</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co">        statsmodels.regression.linear_model.RegressionResultsWrapper: El modelo OLS final.</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    remaining_features <span class="op">=</span> <span class="bu">list</span>(data.drop(columns<span class="op">=</span>[target_variable]).columns)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    selected_features <span class="op">=</span> [] <span class="cf">if</span> initial_features <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> initial_features</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    current_score, best_new_score <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>), <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    best_model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    iteration <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Iniciando selecci√≥n de modelo por pasos con AIC (direcci√≥n 'both')..."</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        iteration <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        model_changed <span class="op">=</span> <span class="va">False</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Iteraci√≥n </span><span class="sc">{</span>iteration<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Caracter√≠sticas seleccionadas actualmente: </span><span class="sc">{</span>selected_features<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Paso hacia adelante (Forward Selection) ---</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        aic_candidates_forward <span class="op">=</span> {}</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> remaining_features: <span class="co"># Solo si hay caracter√≠sticas restantes para a√±adir</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="st">"Considerando a√±adir caracter√≠sticas:"</span>)</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> feature <span class="kw">in</span> remaining_features:</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>                temp_features <span class="op">=</span> selected_features <span class="op">+</span> [feature]</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="kw">not</span> temp_features: <span class="co"># Asegura que al menos haya un Intercept si no hay features</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ 1"</span> <span class="co"># Modelo solo con intercept</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(temp_features)</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>                    model <span class="op">=</span> smf.ols(formula<span class="op">=</span>formula, data<span class="op">=</span>data).fit()</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>                    aic_candidates_forward[feature] <span class="op">=</span> model.aic</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  A√±adiendo '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': AIC = </span><span class="sc">{</span>model<span class="sc">.</span>aic<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  Error al probar '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Paso hacia atr√°s (Backward Elimination) ---</span></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>        aic_candidates_backward <span class="op">=</span> {}</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(selected_features) <span class="op">&gt;</span> <span class="dv">0</span>: <span class="co"># Solo si hay caracter√≠sticas para eliminar</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="st">"Considerando eliminar caracter√≠sticas:"</span>)</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> feature <span class="kw">in</span> selected_features:</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>                temp_features <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> selected_features <span class="cf">if</span> f <span class="op">!=</span> feature]</span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="kw">not</span> temp_features: <span class="co"># Si eliminamos todo y solo queda el intercept</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ 1"</span></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(temp_features)</span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>                    model <span class="op">=</span> smf.ols(formula<span class="op">=</span>formula, data<span class="op">=</span>data).fit()</span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a>                    aic_candidates_backward[feature] <span class="op">=</span> model.aic</span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  Eliminando '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': AIC = </span><span class="sc">{</span>model<span class="sc">.</span>aic<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  Error al probar quitar '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>        best_aic_this_step <span class="op">=</span> current_score</span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>        feature_to_add <span class="op">=</span> <span class="va">None</span></span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>        feature_to_remove <span class="op">=</span> <span class="va">None</span></span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>        action <span class="op">=</span> <span class="va">None</span> <span class="co"># 'add' o 'remove'</span></span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluar mejor movimiento: a√±adir o eliminar</span></span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mejor a√±adir</span></span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> aic_candidates_forward:</span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>            min_aic_add_feature <span class="op">=</span> <span class="bu">min</span>(aic_candidates_forward, key<span class="op">=</span>aic_candidates_forward.get)</span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a>            min_aic_add_value <span class="op">=</span> aic_candidates_forward[min_aic_add_feature]</span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> min_aic_add_value <span class="op">&lt;</span> best_aic_this_step:</span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>                best_aic_this_step <span class="op">=</span> min_aic_add_value</span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a>                feature_to_add <span class="op">=</span> min_aic_add_feature</span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a>                action <span class="op">=</span> <span class="st">'add'</span></span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mejor eliminar</span></span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> aic_candidates_backward:</span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>            min_aic_remove_feature <span class="op">=</span> <span class="bu">min</span>(aic_candidates_backward, key<span class="op">=</span>aic_candidates_backward.get)</span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a>            min_aic_remove_value <span class="op">=</span> aic_candidates_backward[min_aic_remove_feature]</span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Solo consideramos eliminar si esto mejora el AIC *actual* del modelo</span></span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a>            <span class="co"># y tambi√©n si es mejor que a√±adir</span></span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> min_aic_remove_value <span class="op">&lt;</span> best_aic_this_step:</span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>                best_aic_this_step <span class="op">=</span> min_aic_remove_value</span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a>                feature_to_remove <span class="op">=</span> min_aic_remove_feature</span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a>                action <span class="op">=</span> <span class="st">'remove'</span></span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_aic_this_step <span class="op">&lt;</span> current_score:</span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a>            model_changed <span class="op">=</span> <span class="va">True</span></span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a>            current_score <span class="op">=</span> best_aic_this_step</span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> action <span class="op">==</span> <span class="st">'add'</span>:</span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a>                selected_features.append(feature_to_add)</span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a>                remaining_features.remove(feature_to_add)</span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"-&gt; A√±adiendo: '</span><span class="sc">{</span>feature_to_add<span class="sc">}</span><span class="ss">'. Nuevo AIC: </span><span class="sc">{</span>current_score<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> action <span class="op">==</span> <span class="st">'remove'</span>:</span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a>                remaining_features.append(feature_to_remove)</span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a>                selected_features.remove(feature_to_remove)</span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"-&gt; Eliminando: '</span><span class="sc">{</span>feature_to_remove<span class="sc">}</span><span class="ss">'. Nuevo AIC: </span><span class="sc">{</span>current_score<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a>            <span class="co"># No hay mejoras en el AIC, detener el proceso</span></span>
<span id="cb11-121"><a href="#cb11-121" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">No se encontr√≥ una mejora en el AIC. Deteniendo la selecci√≥n por pasos."</span>)</span>
<span id="cb11-122"><a href="#cb11-122" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ajustar el modelo final con las caracter√≠sticas seleccionadas</span></span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> selected_features:</span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a>        final_formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ 1"</span></span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a>        final_formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(selected_features)</span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a>    final_model <span class="op">=</span> smf.ols(formula<span class="op">=</span>final_formula, data<span class="op">=</span>data).fit()</span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> final_model</span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Aplicar la selecci√≥n por pasos ---</span></span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a><span class="co"># train_data_combined es el DataFrame que contiene X_train y y_train</span></span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a><span class="co"># target_variable es el nombre de tu columna 'mpg'</span></span>
<span id="cb11-136"><a href="#cb11-136" aria-hidden="true" tabindex="-1"></a>modelo_step_py <span class="op">=</span> stepwise_selection_aic(</span>
<span id="cb11-137"><a href="#cb11-137" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>train_data_combined,</span>
<span id="cb11-138"><a href="#cb11-138" aria-hidden="true" tabindex="-1"></a>    target_variable<span class="op">=</span><span class="st">'mpg'</span>,</span>
<span id="cb11-139"><a href="#cb11-139" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-140"><a href="#cb11-140" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-141"><a href="#cb11-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-142"><a href="#cb11-142" aria-hidden="true" tabindex="-1"></a><span class="co"># Revisar resumen del modelo_step final</span></span>
<span id="cb11-143"><a href="#cb11-143" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Resumen del Modelo OLS Despu√©s de la Selecci√≥n por Pasos (AIC) ---"</span>)</span>
<span id="cb11-144"><a href="#cb11-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(modelo_step_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Iniciando selecci√≥n de modelo por pasos con AIC (direcci√≥n 'both')...

--- Iteraci√≥n 1 ---
Caracter√≠sticas seleccionadas actualmente: []
Considerando a√±adir caracter√≠sticas:
  A√±adiendo 'Unnamed: 0': AIC = 163.35
  A√±adiendo 'cyl': AIC = 130.29
  A√±adiendo 'disp': AIC = 134.87
  A√±adiendo 'hp': AIC = 140.99
  A√±adiendo 'drat': AIC = 148.30
  A√±adiendo 'wt': AIC = 132.58
  A√±adiendo 'qsec': AIC = 155.89
  A√±adiendo 'vs': AIC = 146.77
  A√±adiendo 'am': AIC = 153.23
  A√±adiendo 'gear': AIC = 162.02
  A√±adiendo 'carb': AIC = 156.09
-&gt; A√±adiendo: 'cyl'. Nuevo AIC: 130.29

--- Iteraci√≥n 2 ---
Caracter√≠sticas seleccionadas actualmente: ['cyl']
Considerando a√±adir caracter√≠sticas:
  A√±adiendo 'Unnamed: 0': AIC = 130.29
  A√±adiendo 'disp': AIC = 130.63
  A√±adiendo 'hp': AIC = 130.68
  A√±adiendo 'drat': AIC = 130.98
  A√±adiendo 'wt': AIC = 124.37
  A√±adiendo 'qsec': AIC = 132.24
  A√±adiendo 'vs': AIC = 132.09
  A√±adiendo 'am': AIC = 129.94
  A√±adiendo 'gear': AIC = 132.13
  A√±adiendo 'carb': AIC = 130.25
Considerando eliminar caracter√≠sticas:
  Eliminando 'cyl': AIC = 163.35
-&gt; A√±adiendo: 'wt'. Nuevo AIC: 124.37

--- Iteraci√≥n 3 ---
Caracter√≠sticas seleccionadas actualmente: ['cyl', 'wt']
Considerando a√±adir caracter√≠sticas:
  A√±adiendo 'Unnamed: 0': AIC = 124.37
  A√±adiendo 'disp': AIC = 125.80
  A√±adiendo 'hp': AIC = 124.39
  A√±adiendo 'drat': AIC = 126.34
  A√±adiendo 'qsec': AIC = 123.27
  A√±adiendo 'vs': AIC = 126.30
  A√±adiendo 'am': AIC = 126.17
  A√±adiendo 'gear': AIC = 125.91
  A√±adiendo 'carb': AIC = 123.88
Considerando eliminar caracter√≠sticas:
  Eliminando 'cyl': AIC = 132.58
  Eliminando 'wt': AIC = 130.29
-&gt; A√±adiendo: 'qsec'. Nuevo AIC: 123.27

--- Iteraci√≥n 4 ---
Caracter√≠sticas seleccionadas actualmente: ['cyl', 'wt', 'qsec']
Considerando a√±adir caracter√≠sticas:
  A√±adiendo 'Unnamed: 0': AIC = 123.27
  A√±adiendo 'disp': AIC = 124.67
  A√±adiendo 'hp': AIC = 125.20
  A√±adiendo 'drat': AIC = 123.52
  A√±adiendo 'vs': AIC = 124.71
  A√±adiendo 'am': AIC = 117.58
  A√±adiendo 'gear': AIC = 124.46
  A√±adiendo 'carb': AIC = 125.13
Considerando eliminar caracter√≠sticas:
  Eliminando 'cyl': AIC = 122.40
  Eliminando 'wt': AIC = 132.24
  Eliminando 'qsec': AIC = 124.37
-&gt; A√±adiendo: 'am'. Nuevo AIC: 117.58

--- Iteraci√≥n 5 ---
Caracter√≠sticas seleccionadas actualmente: ['cyl', 'wt', 'qsec', 'am']
Considerando a√±adir caracter√≠sticas:
  A√±adiendo 'Unnamed: 0': AIC = 117.58
  A√±adiendo 'disp': AIC = 118.87
  A√±adiendo 'hp': AIC = 119.53
  A√±adiendo 'drat': AIC = 118.30
  A√±adiendo 'vs': AIC = 119.55
  A√±adiendo 'gear': AIC = 119.19
  A√±adiendo 'carb': AIC = 119.10
Considerando eliminar caracter√≠sticas:
  Eliminando 'cyl': AIC = 116.52
  Eliminando 'wt': AIC = 129.24
  Eliminando 'qsec': AIC = 126.17
  Eliminando 'am': AIC = 123.27
-&gt; Eliminando: 'cyl'. Nuevo AIC: 116.52

--- Iteraci√≥n 6 ---
Caracter√≠sticas seleccionadas actualmente: ['wt', 'qsec', 'am']
Considerando a√±adir caracter√≠sticas:
  A√±adiendo 'Unnamed: 0': AIC = 116.52
  A√±adiendo 'disp': AIC = 117.13
  A√±adiendo 'hp': AIC = 118.47
  A√±adiendo 'drat': AIC = 118.16
  A√±adiendo 'vs': AIC = 118.39
  A√±adiendo 'gear': AIC = 117.80
  A√±adiendo 'carb': AIC = 117.53
  A√±adiendo 'cyl': AIC = 117.58
Considerando eliminar caracter√≠sticas:
  Eliminando 'wt': AIC = 130.13
  Eliminando 'qsec': AIC = 134.30
  Eliminando 'am': AIC = 122.40

No se encontr√≥ una mejora en el AIC. Deteniendo la selecci√≥n por pasos.

--- Resumen del Modelo OLS Despu√©s de la Selecci√≥n por Pasos (AIC) ---
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.879
Model:                            OLS   Adj. R-squared:                  0.862
Method:                 Least Squares   F-statistic:                     50.92
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           8.26e-10
Time:                        15:18:00   Log-Likelihood:                -54.262
No. Observations:                  25   AIC:                             116.5
Df Residuals:                      21   BIC:                             121.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -3.0270      8.017     -0.378      0.710     -19.700      13.646
wt            -3.1064      0.728     -4.267      0.000      -4.620      -1.592
qsec           1.7715      0.352      5.033      0.000       1.039       2.504
am             3.9631      1.421      2.788      0.011       1.007       6.919
==============================================================================
Omnibus:                        1.036   Durbin-Watson:                   1.169
Prob(Omnibus):                  0.596   Jarque-Bera (JB):                1.008
Skew:                           0.368   Prob(JB):                        0.604
Kurtosis:                       2.347   Cond. No.                         314.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<p>El procedimiento va eliminando o agregando variables al modelo original para reducir el <strong>AIC (Criterio de Informaci√≥n de Akaike)</strong>. El objetivo es encontrar un modelo m√°s <strong>parsimonioso</strong> (simple) con <strong>buena capacidad predictiva</strong>.</p>
<ul>
<li><p>El proceso empieza con un modelo completo:<br>
<code>mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb</code> y un AIC inicial, por ejemplo: <code>AIC = 57.77</code>.</p></li>
<li><p>Luego eval√∫a qu√© pasa si <strong>quita</strong> una variable (<code>- vs</code>, <code>- cyl</code>, etc.).</p></li>
<li><p>Si al eliminar una variable el AIC <strong>baja</strong>, se acepta ese cambio.<br>
Ejemplo:<br>
<code>- vs    1    2.1293  102.57  56.353</code><br>
Significa que si quitas la variable <code>vs</code>, el AIC baja de 57.77 a 56.35 ‚Üí ¬°mejor!</p>
<ul>
<li>Se acepta esa modificaci√≥n y se repite el procedimiento, ahora con el nuevo modelo.</li>
</ul></li>
<li><p>Tambi√©n puede intentar <strong>agregar</strong> variables previamente eliminadas (<code>+ vs</code>, <code>+ hp</code>, etc.) si esto mejora el AIC.</p></li>
<li><p>Cuando <strong>ya no puede bajar m√°s el AIC</strong> quitando o agregando variables. El modelo final es el que <strong>tiene el AIC m√°s bajo</strong> alcanzado durante el proceso.</p></li>
</ul>
</section>
</section>
<section id="interpretaci√≥n-final" class="level3">
<h3 class="anchored" data-anchor-id="interpretaci√≥n-final">Interpretaci√≥n Final</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 43%">
<col style="width: 21%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Aspecto</th>
<th>Modelo Completo</th>
<th>Modelo por AIC (reducido)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>R¬≤ ajustado</strong></td>
<td>0.821</td>
<td>0.862 ‚úÖ</td>
</tr>
<tr class="even">
<td><strong>AIC</strong></td>
<td>126.9</td>
<td><strong>116.5 ‚úÖ</strong></td>
</tr>
<tr class="odd">
<td><strong>Coeficientes significativos</strong></td>
<td>Ninguno</td>
<td>Todos ‚úÖ</td>
</tr>
<tr class="even">
<td><strong>Multicolinealidad</strong></td>
<td>Alta ‚ö†Ô∏è</td>
<td>Baja ‚úÖ</td>
</tr>
<tr class="odd">
<td><strong>Interpretabilidad</strong></td>
<td>Difusa</td>
<td>Clara ‚úÖ</td>
</tr>
</tbody>
</table>
<p><strong>Conclusi√≥n del modelo reducido</strong>:</p>
<ul>
<li>Todas las variables son estad√≠sticamente significativas.</li>
<li>El modelo es m√°s simple (3 variables vs.&nbsp;10).</li>
<li>El AIC baj√≥ significativamente ‚áí mejora en calidad del modelo.</li>
<li>La interpretaci√≥n es mucho m√°s clara y robusta.</li>
</ul>
</section>
<section id="forward-or-backward-stepwise" class="level3">
<h3 class="anchored" data-anchor-id="forward-or-backward-stepwise">Forward or backward stepwise</h3>
<p>Los modelos ‚Äúforward‚Äù (hacia adelante) y ‚Äúbackward‚Äù (hacia atr√°s) son dos enfoques comunes dentro de la <strong>regresi√≥n stepwise (paso a paso)</strong>, un m√©todo de selecci√≥n autom√°tica de variables para construir modelos de regresi√≥n. El objetivo de la regresi√≥n stepwise es encontrar un subconjunto √≥ptimo de variables predictoras que expliquen la mayor parte de la varianza en la variable dependiente con la menor complejidad posible, evitando el sobreajuste y mejorando la interpretabilidad del modelo.</p>
<p>Ambos m√©todos operan de manera iterativa, agregando o eliminando variables bas√°ndose en un criterio estad√≠stico (como el p-valor, AIC, BIC, etc.).</p>
<section id="forward-selection-selecci√≥n-hacia-adelante" class="level4">
<h4 class="anchored" data-anchor-id="forward-selection-selecci√≥n-hacia-adelante"><strong>Forward Selection</strong> (Selecci√≥n Hacia Adelante)</h4>
<p>La selecci√≥n hacia adelante comienza con un modelo ‚Äúnulo‚Äù, es decir, un modelo que no contiene ninguna variable predictora (solo el intercepto). Luego, en cada paso, eval√∫a todas las variables predictoras no incluidas en el modelo y agrega aquella que, al ser incluida, produce la mejora m√°s significativa en el ajuste del modelo. Este proceso contin√∫a hasta que ninguna de las variables restantes cumple con el criterio de entrada preestablecido (por ejemplo, su p-valor es mayor que un umbral determinado).</p>
</section>
<section id="backward-elimination-eliminaci√≥n-hacia-atr√°s" class="level4">
<h4 class="anchored" data-anchor-id="backward-elimination-eliminaci√≥n-hacia-atr√°s"><strong>Backward Elimination</strong> (Eliminaci√≥n Hacia Atr√°s)</h4>
<p>La eliminaci√≥n hacia atr√°s comienza con un modelo ‚Äúcompleto‚Äù, es decir, un modelo que incluye todas las variables predictoras candidatas. Luego, en cada paso, eval√∫a la contribuci√≥n de cada variable predictora en el modelo y elimina aquella que, al ser retirada, tiene el menor impacto negativo en el ajuste del modelo (o la que es menos significativa, por ejemplo, la que tiene el p-valor m√°s alto). Este proceso contin√∫a hasta que todas las variables restantes en el modelo cumplen con un criterio de permanencia preestablecido (por ejemplo, su p-valor es menor que un umbral determinado).</p>
</section>
<section id="consideraciones-generales-sobre-la-regresi√≥n-stepwise" class="level4">
<h4 class="anchored" data-anchor-id="consideraciones-generales-sobre-la-regresi√≥n-stepwise">Consideraciones Generales sobre la Regresi√≥n Stepwise</h4>
<p>Es importante mencionar que, aunque los m√©todos forward y backward son populares por su automatizaci√≥n, tambi√©n tienen sus <strong>cr√≠ticas y desventajas</strong>:</p>
<ul>
<li><strong>Sobreajuste (Overfitting):</strong> Los modelos resultantes pueden ajustarse muy bien a los datos de entrenamiento, pero no generalizar bien a nuevos datos. Esto se debe a que el proceso de selecci√≥n de variables se basa en los datos observados, lo que puede llevar a incluir variables que parecen importantes por puro azar en esa muestra particular.</li>
<li><strong>P-valores y Coeficientes Sesgados:</strong> Los p-valores y los coeficientes de regresi√≥n obtenidos de un modelo stepwise pueden ser sesgados. Los p-valores tienden a ser m√°s peque√±os de lo que realmente son, lo que lleva a una falsa confianza en la significancia de las variables.</li>
<li><strong>No considera la teor√≠a:</strong> El proceso es puramente estad√≠stico y no incorpora el conocimiento del dominio o la teor√≠a subyacente sobre las relaciones entre las variables. Un modelo estad√≠sticamente ‚Äú√≥ptimo‚Äù podr√≠a carecer de sentido te√≥rico o pr√°ctico.</li>
<li><strong>Dependencia del orden:</strong> La selecci√≥n de variables puede ser sensible al orden en que se a√±aden o eliminan, especialmente en la selecci√≥n hacia adelante.</li>
</ul>
<p><strong>Selecci√≥n de Subconjuntos de Variables con <code>statsmodels</code> en Python</strong></p>
<p>En Python, no hay una funci√≥n directa que replique <code>regsubsets</code> con todos sus m√©todos (exhaustiva, forward, backward, etc.) en una sola llamada como en R.</p>
<p>Explicaci√≥n de la Funci√≥n Gen√©rica <code>regsubsets_exhaustive</code>:</p>
<ol type="1">
<li><strong>Par√°metros de Entrada</strong>:</li>
</ol>
<ul>
<li><code>X_train_df</code>: El DataFrame de variables predictoras de entrenamiento.</li>
<li><code>y_train_series</code>: La Serie de la variable dependiente de entrenamiento. <strong>Es crucial que <code>y_train_series</code> tenga un <code>.name</code> (e.g., <code>'mpg'</code>) asignado</strong>, ya que <code>statsmodels</code> lo usa para construir la f√≥rmula. Si <code>y_train</code> no tiene un nombre, se puede asign√°r (<code>y_train.name = 'nombre_columna'</code>).</li>
<li><code>nvmax</code>: El n√∫mero m√°ximo de variables a considerar.</li>
<li><code>id_column</code>: Un nuevo par√°metro para especificar el nombre de cualquier columna que sea un identificador (como <code>'name'</code> o <code>'Unnamed: 0'</code>) y que <strong>no debe usarse como predictor</strong>.</li>
</ul>
<ol start="2" type="1">
<li><p><strong><code>train_data_combined</code></strong>: Dentro de la funci√≥n, combinamos <code>X_train_df</code> y <code>y_train_series</code> en un solo DataFrame. Esto es lo que <code>statsmodels</code> espera para la funci√≥n <code>smf.ols</code> cuando se usa la sintaxis de f√≥rmula.</p></li>
<li><p><strong>Exclusi√≥n de <code>id_column</code></strong>: La lista <code>all_predictors</code> ahora filtra la <code>id_column</code> proporcionada. Esto te da control sobre qu√© columnas del <code>X_train_df</code> son realmente predictores.</p></li>
<li><p><strong>Almacenamiento de Objetos de Modelo</strong>: A√±adimos un diccionario <code>model_objects</code> que guarda cada objeto de modelo ajustado (<code>model_objects[formula] = model</code>). Esto es muy √∫til porque si luego se decide que un modelo espec√≠fico (por ejemplo, el mejor AIC con 5 caracter√≠sticas) es el que se quiere, se puede recuperar el diccionario y acceder a su <code>.summary()</code>, <code>.predict()</code>, etc.</p></li>
<li><p><strong>Retorno de Valores</strong>: La funci√≥n devuelve un diccionario <code>best_models</code> (que contiene DataFrames para los mejores modelos por R-cuadrado ajustado, AIC y BIC) y el diccionario <code>all_model_objects</code>.</p></li>
</ol>
<div id="regsubsets-generic-function" class="cell" data-message="false" data-results="as-is" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Definici√≥n de la funci√≥n gen√©rica para regsubsets (exhaustive) ---</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> regsubsets_exhaustive(X_train_df, y_train_series, nvmax<span class="op">=</span><span class="va">None</span>, id_column<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Realiza una b√∫squeda exhaustiva de los mejores subconjuntos de variables</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">    para un modelo de regresi√≥n lineal, similar a regsubsets en R.</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">        X_train_df (pd.DataFrame): DataFrame con las variables predictoras del conjunto de entrenamiento.</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">        y_train_series (pd.Series): Serie con la variable dependiente del conjunto de entrenamiento.</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">        nvmax (int, optional): N√∫mero m√°ximo de variables a considerar en los subconjuntos.</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">                               Si es None, se usa el n√∫mero total de predictores.</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">        id_column (str, optional): Nombre de una columna en X_train_df que es un identificador</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">                                   (como 'name' o 'Unnamed: 0') y debe excluirse de los predictores.</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: Un DataFrame con los mejores modelos para cada n√∫mero de caracter√≠sticas,</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">                      ordenados por R-cuadrado ajustado, AIC y BIC.</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">        dict: Un diccionario de los objetos de modelo ajustados para referencia,</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">              con la f√≥rmula como clave.</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine X_train and y_train into a single DataFrame for statsmodels</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    train_data_combined <span class="op">=</span> pd.concat([X_train_df, y_train_series], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure y_train_series.name is not None</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    target_variable_name <span class="op">=</span> y_train_series.name</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> target_variable_name <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"The 'y_train_series' Series must have a name assigned (e.g., y_train.name = 'mpg')"</span>)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define available predictor variables, excluding the ID column if provided</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    all_predictors <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> X_train_df.columns <span class="cf">if</span> col <span class="op">!=</span> id_column]</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Limit nvmax if it's greater than the actual number of predictors</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> nvmax <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        nvmax_final <span class="op">=</span> <span class="bu">len</span>(all_predictors)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>        nvmax_final <span class="op">=</span> <span class="bu">min</span>(nvmax, <span class="bu">len</span>(all_predictors))</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    model_objects <span class="op">=</span> {}</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Starting exhaustive subset search up to </span><span class="sc">{</span>nvmax_final<span class="sc">}</span><span class="ss"> variables..."</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, nvmax_final <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> subset_features_tuple <span class="kw">in</span> itertools.combinations(all_predictors, k):</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>            subset_features <span class="op">=</span> <span class="bu">list</span>(subset_features_tuple)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> subset_features:</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>                formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable_name<span class="sc">}</span><span class="ss"> ~ 1"</span></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>                formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable_name<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(subset_features)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>                model <span class="op">=</span> smf.ols(formula<span class="op">=</span>formula, data<span class="op">=</span>train_data_combined).fit()</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>                results.append({</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'n_features'</span>: k,</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'features'</span>: <span class="st">" + "</span>.join(subset_features),</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'adj_r_squared'</span>: model.rsquared_adj,</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'aic'</span>: model.aic,</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'bic'</span>: model.bic,</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'formula'</span>: formula</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>                model_objects[formula] <span class="op">=</span> model</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>                <span class="co"># We'll just print a warning for failed models, not a full debug trace</span></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Warning: Error fitting model with formula '</span><span class="sc">{</span>formula<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>    results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> results_df.empty:</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"No valid models could be fitted."</span>)</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pd.DataFrame(), {}</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>    best_models <span class="op">=</span> {}</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> metric <span class="kw">in</span> [<span class="st">'adj_r_squared'</span>, <span class="st">'aic'</span>, <span class="st">'bic'</span>]:</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> metric <span class="op">==</span> <span class="st">'adj_r_squared'</span>:</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> results_df.groupby(<span class="st">'n_features'</span>)[metric].idxmax()</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> results_df.groupby(<span class="st">'n_features'</span>)[metric].idxmin()</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> idx.empty:</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>            best_models[metric] <span class="op">=</span> results_df.loc[idx].set_index(<span class="st">'n_features'</span>)</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>            best_models[metric] <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>results_df.columns).set_index(<span class="st">'n_features'</span>)</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_models, model_objects</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="77372a1f" class="cell" data-message="false" data-results="as-is" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This line is crucial and should be present in your actual script</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># to ensure y_train has a name.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> y_train.name <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    y_train.name <span class="op">=</span> <span class="st">'mpg'</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Running exhaustive subset selection ---"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>best_models_results, all_model_objects <span class="op">=</span> regsubsets_exhaustive(</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>                                                                X_train_df<span class="op">=</span>X_train,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>                                                                y_train_series<span class="op">=</span>y_train,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                                                                nvmax<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>                                                                id_column<span class="op">=</span><span class="st">'Unnamed: 0'</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Displaying only the final summary ---</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Summary of the best global model by AIC ---"</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> best_models_results[<span class="st">'aic'</span>].empty:</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the row with the globally lowest AIC across all feature counts</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We combine all results and then find the minimum AIC</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    all_results_df_for_global <span class="op">=</span> pd.concat([best_models_results[<span class="st">'aic'</span>], </span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>                                           best_models_results[<span class="st">'bic'</span>], </span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                                           best_models_results[<span class="st">'adj_r_squared'</span>]]).drop_duplicates(subset<span class="op">=</span>[<span class="st">'formula'</span>])</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'formula'</span> <span class="kw">in</span> all_results_df_for_global.columns <span class="kw">and</span> <span class="st">'aic'</span> <span class="kw">in</span> all_results_df_for_global.columns:</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        global_best_aic_row <span class="op">=</span> all_results_df_for_global.loc[all_results_df_for_global[<span class="st">'aic'</span>].idxmin()]</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        global_best_aic_formula <span class="op">=</span> global_best_aic_row[<span class="st">'formula'</span>]</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Model with lowest global AIC: </span><span class="sc">{</span>global_best_aic_formula<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Now, print the full statsmodels summary for this specific model</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> global_best_aic_formula <span class="kw">in</span> all_model_objects:</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(all_model_objects[global_best_aic_formula].summary())</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Error: The object for the best global AIC model was not found in 'all_model_objects'."</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Error: 'formula' or 'aic' columns not found in combined results for global best model."</span>)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No valid models were found for subset selection. Cannot display global best model."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Running exhaustive subset selection ---
Starting exhaustive subset search up to 10 variables...

--- Summary of the best global model by AIC ---
Model with lowest global AIC: mpg ~ wt + qsec + am
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.879
Model:                            OLS   Adj. R-squared:                  0.862
Method:                 Least Squares   F-statistic:                     50.92
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           8.26e-10
Time:                        15:18:11   Log-Likelihood:                -54.262
No. Observations:                  25   AIC:                             116.5
Df Residuals:                      21   BIC:                             121.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -3.0270      8.017     -0.378      0.710     -19.700      13.646
wt            -3.1064      0.728     -4.267      0.000      -4.620      -1.592
qsec           1.7715      0.352      5.033      0.000       1.039       2.504
am             3.9631      1.421      2.788      0.011       1.007       6.919
==============================================================================
Omnibus:                        1.036   Durbin-Watson:                   1.169
Prob(Omnibus):                  0.596   Jarque-Bera (JB):                1.008
Skew:                           0.368   Prob(JB):                        0.604
Kurtosis:                       2.347   Cond. No.                         314.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<p><code>Selection Algorithm: exhaustive</code> <strong>: Esto es crucial. Significa que el algoritmo prob√≥ todas las combinaciones posibles</strong> de variables para cada tama√±o de subconjunto hasta <code>nvmax = 10</code> y seleccion√≥ el mejor para cada tama√±o. Esto asegura que, para cada n√∫mero de variables (1, 2, ‚Ä¶, 10), el modelo presentado es el √≥ptimo seg√∫n el criterio interno de <code>regsubsets_exhaustive</code> (generalmente <code>AIC</code>, <span class="math inline">\(R^2\)</span> ajustado, BIC a menos que se especifique otro en la funci√≥n).</p>
<div id="495b5841" class="cell" data-message="false" data-results="as-is" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">### Extracci√≥n de los datos de R2 Ajustado</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">#La informaci√≥n ya est√° en `best_models_results['adj_r_squared']`. Para obtenerla en un formato de DataFrame con columnas expl√≠citas para el n√∫mero de variables y el R2 ajustado, simplemente hacemos:</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtener el DataFrame de los mejores R2 Ajustados por n√∫mero de variables</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>adjr2_data_df <span class="op">=</span> best_models_results[<span class="st">'adj_r_squared'</span>].reset_index()</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Renombrar columnas para mayor claridad</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>adjr2_data_df.rename(columns<span class="op">=</span>{<span class="st">'n_features'</span>: <span class="st">'Numero_de_Variables'</span>, </span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>                              <span class="st">'adj_r_squared'</span>: <span class="st">'R2_Ajustado'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- DataFrame con R2 Ajustado por N√∫mero de Variables ---"</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(adjr2_data_df[[<span class="st">'Numero_de_Variables'</span>, <span class="st">'R2_Ajustado'</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> adjr2_data_df.empty:</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">5</span>)) <span class="co"># Tama√±o de la figura m√°s compacto</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Graficar l√≠nea y puntos</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    plt.plot(adjr2_data_df[<span class="st">'Numero_de_Variables'</span>], adjr2_data_df[<span class="st">'R2_Ajustado'</span>], </span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>             marker <span class="op">=</span> <span class="st">'o'</span>, linestyle <span class="op">=</span> <span class="st">'-'</span>, color <span class="op">=</span> <span class="st">'skyblue'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encontrar el punto de R2 ajustado m√°ximo</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    max_adjr2_row <span class="op">=</span> adjr2_data_df.loc[adjr2_data_df[<span class="st">'R2_Ajustado'</span>].idxmax()]</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    best_num_vars <span class="op">=</span> <span class="bu">int</span>(max_adjr2_row[<span class="st">'Numero_de_Variables'</span>])</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    max_adjr2_value <span class="op">=</span> max_adjr2_row[<span class="st">'R2_Ajustado'</span>]</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resaltar el punto m√°ximo</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    plt.plot(best_num_vars, max_adjr2_value, <span class="st">'ro'</span>, markersize <span class="op">=</span> <span class="dv">8</span>) <span class="co"># Punto rojo grande</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    plt.axvline(x <span class="op">=</span> best_num_vars, color <span class="op">=</span> <span class="st">'red'</span>, linestyle<span class="op">=</span> <span class="st">'--'</span>, linewidth <span class="op">=</span> <span class="dv">1</span>, alpha <span class="op">=</span> <span class="fl">0.7</span>) <span class="co"># L√≠nea vertical</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Etiquetas y t√≠tulo</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"R2 Ajustado vs. N√∫mero de Variables"</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"N√∫mero de Variables"</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"R2 Ajustado"</span>)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Asegurar que los ticks del eje X sean enteros y legibles</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">max</span>(adjr2_data_df[<span class="st">'Numero_de_Variables'</span>]) <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>, linestyle <span class="op">=</span> <span class="st">':'</span>, alpha <span class="op">=</span> <span class="fl">0.6</span>) <span class="co"># Cuadr√≠cula ligera</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No hay datos para generar el gr√°fico de R2 Ajustado."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>--- DataFrame con R2 Ajustado por N√∫mero de Variables ---
 Numero_de_Variables  R2_Ajustado
                   1     0.743288
                   2     0.819335
                   3     0.861870
                   4     0.862840
                   5     0.860304
                   6     0.858462
                   7     0.851836
                   8     0.842908
                   9     0.832837
                  10     0.820912</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_01_OLSR_py_files/figure-html/cell-18-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>*## Evaluaci√≥n del modelo</p>
<p>Ahora se va a trabajar con un <strong>modelo reducido (<code>modelo_step</code>)</strong>, es importante <strong>usar ese modelo</strong> para hacer predicciones en el conjunto de prueba. Adem√°s, como solo algunas variables quedaron en el modelo (<code>drat</code>, <code>wt</code>, <code>gear</code>, <code>carb</code>), el <code>test_data</code> debe contener esas columnas.</p>
<p><strong>Verificar qu√© variables necesita el modelo reducido</strong></p>
<div id="8004c67d" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>global_best_aic_row <span class="op">=</span> all_results_df_for_global.loc[all_results_df_for_global[<span class="st">'aic'</span>].idxmin()]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>global_best_aic_formula <span class="op">=</span> global_best_aic_row[<span class="st">'formula'</span>]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>global_best_aic_formula</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>'mpg ~ wt + qsec + am'</code></pre>
</div>
</div>
</section>
</section>
<section id="variance-inflation-factor-vif" class="level3">
<h3 class="anchored" data-anchor-id="variance-inflation-factor-vif">Variance Inflation Factor (<code>VIF</code>)</h3>
<p>El <strong>Factor de Inflaci√≥n de la Varianza (VIF)</strong> es una herramienta estad√≠stica fundamental utilizada para <strong>detectar y cuantificar la multicolinealidad</strong> en modelos de regresi√≥n lineal m√∫ltiple.</p>
<p><strong>Problemas que causa la multicolinealidad:</strong></p>
<ul>
<li><strong>Coeficientes de regresi√≥n inestables y dif√≠ciles de interpretar:</strong> Cuando las variables predictoras est√°n altamente correlacionadas, es dif√≠cil para el modelo determinar la contribuci√≥n √∫nica de cada variable a la variable dependiente. Peque√±os cambios en los datos pueden llevar a grandes cambios en los coeficientes estimados, haciendo que sean poco fiables.</li>
<li><strong>Errores est√°ndar inflados:</strong> La multicolinealidad aumenta los errores est√°ndar de los coeficientes de regresi√≥n, lo que a su vez disminuye los valores de las estad√≠sticas t y aumenta los p-valores. Esto puede llevar a la conclusi√≥n err√≥nea de que una variable no es estad√≠sticamente significativa cuando en realidad s√≠ lo es.</li>
<li><strong>Poder predictivo reducido:</strong> Aunque la multicolinealidad no necesariamente afecta la capacidad predictiva global del modelo (el <span class="math inline">\(R^2\)</span> ajustado puede seguir siendo alto), s√≠ afecta la precisi√≥n de las estimaciones de los coeficientes individuales, lo que hace dif√≠cil comprender la relaci√≥n real entre cada predictor y la variable de respuesta.</li>
</ul>
<p>El VIF mide <strong>cu√°nto se ‚Äúinfla‚Äù la varianza del coeficiente de regresi√≥n estimado de una variable predictora debido a su correlaci√≥n con otras variables predictoras</strong> en el modelo.</p>
<p><strong>La f√≥rmula del VIF para una variable</strong> <span class="math inline">\(X_j\)</span> es:</p>
<p><span class="math display">\[VIF_j = \frac{1}{1 - R_j^2}\]</span></p>
<p>Donde <span class="math inline">\(R_j^2\)</span> es el coeficiente de determinaci√≥n (<span class="math inline">\(R^2\)</span>) de una regresi√≥n auxiliar en la que la variable <span class="math inline">\(X_j\)</span> se predice utilizando todas las dem√°s variables independientes del modelo.</p>
<section id="c√≥mo-se-interpreta-el-vif" class="level4">
<h4 class="anchored" data-anchor-id="c√≥mo-se-interpreta-el-vif">¬øC√≥mo se interpreta el VIF?</h4>
<ul>
<li><strong>VIF = 1:</strong> Indica que la variable predictora no est√° correlacionada con ninguna de las otras variables predictoras en el modelo. No hay multicolinealidad.</li>
<li><strong>VIF &gt; 1:</strong> Indica que existe alg√∫n grado de multicolinealidad. Cuanto mayor sea el valor del VIF, mayor es el grado de multicolinealidad.</li>
</ul>
<p><strong>Reglas generales para interpretar los valores de VIF (son reglas de ‚Äúpulgar‚Äù y pueden variar ligeramente seg√∫n el contexto y el campo de estudio):</strong></p>
<ul>
<li><strong>VIF ‚â§ 5:</strong> Generalmente se considera que no hay problemas graves de multicolinealidad.</li>
<li><strong>5 &lt; VIF ‚â§ 10:</strong> Puede indicar un nivel moderado a alto de multicolinealidad que podr√≠a justificar una investigaci√≥n.</li>
<li><strong>VIF &gt; 10:</strong> A menudo se considera una indicaci√≥n clara de multicolinealidad grave y problem√°tica. Es un umbral com√∫nmente aceptado para se√±alar que una variable est√° fuertemente correlacionada con otras, lo que podr√≠a afectar la estabilidad y fiabilidad del modelo.</li>
</ul>
<p><strong>Regla pr√°ctica para interpretar VIF:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>VIF</th>
<th>Interpretaci√≥n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Sin colinealidad</td>
</tr>
<tr class="even">
<td>1‚Äì5</td>
<td>Colinealidad baja / aceptable</td>
</tr>
<tr class="odd">
<td>5‚Äì10</td>
<td>Colinealidad moderada a alta (requiere atenci√≥n)</td>
</tr>
<tr class="even">
<td>&gt; 10</td>
<td>‚ö†Ô∏è <strong>Colinealidad severa</strong> (problema serio)</td>
</tr>
</tbody>
</table>
<div id="4ddddb13" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.outliers_influence <span class="im">import</span> variance_inflation_factor</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tools.tools <span class="im">import</span> add_constant <span class="co"># Necesario para a√±adir la constante si tu modelo la usa</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># --- C√°lculo del VIF en Python ---</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Important: Remove 'Unnamed: 0' if it exists in X_train ---</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'Unnamed: 0'</span> <span class="kw">in</span> X_train.columns:</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>])</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.copy() <span class="co"># Use .copy() to avoid SettingWithCopyWarning</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Es crucial a√±adir una constante (intercepto) a las variables predictoras</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># si tu modelo OLS incluye un intercepto (que es lo com√∫n con smf.ols por defecto).</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># El 'add_constant' de statsmodels se encarga de esto.</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>X_with_constant <span class="op">=</span> add_constant(X_train_cleaned)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el VIF para cada variable predictora</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>vif_data <span class="op">=</span> pd.DataFrame()</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>vif_data[<span class="st">"feature"</span>] <span class="op">=</span> X_with_constant.columns</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>vif_data[<span class="st">"VIF"</span>] <span class="op">=</span> [variance_inflation_factor(X_with_constant.values, i)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>                   <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X_with_constant.shape[<span class="dv">1</span>])]</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Se ordenan los resultados para ver las variables con mayor VIF primero</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Factor de Inflaci√≥n de la Varianza (VIF) ordenado:"</span>)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vif_data.sort_values(by<span class="op">=</span><span class="st">"VIF"</span>, ascending<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Factor de Inflaci√≥n de la Varianza (VIF) ordenado:
   feature          VIF
0    const  3466.087877
1      cyl    24.921556
2     disp    23.705965
5       wt    18.751416
7       vs    17.461992
6     qsec    15.845728
8       am    13.277013
9     gear    12.589395
3       hp    11.166361
10    carb    10.005587
4     drat     4.308888</code></pre>
</div>
</div>
<ul>
<li><strong>Pr√°cticamente todas las variables (excepto <code>drat</code>) tienen VIF &gt; 10</strong>, lo cual indica <strong>multicolinealidad severa</strong>.</li>
<li>Esto <strong>explica por qu√© en el modelo original ninguno de los coeficientes era significativo</strong>, a pesar del R¬≤ alto.</li>
<li>Multicolinealidad <strong>infla los errores est√°ndar</strong> de los coeficientes y los hace <strong>menos confiables</strong>, incluso si el modelo global es significativo.</li>
</ul>
</section>
</section>
</section>
<section id="evaluaci√≥n-del-modelo" class="level2">
<h2 class="anchored" data-anchor-id="evaluaci√≥n-del-modelo">Evaluaci√≥n del modelo</h2>
<p>La partici√≥n de los datos en <code>X_train</code>, <code>X_test</code>, <code>y_train</code>, y <code>y_test</code> se hace una sola vez al principio de tu an√°lisis para asegurar que la evaluaci√≥n final del modelo (con <code>X_test</code> y <code>y_test</code>) sea imparcial.</p>
<p>Una vez que tienes la f√≥rmula del modelo √≥ptimo se selecciona (<code>'mpg ~ wt + qsec + am'</code>), lo que haces es <strong>re-entrenar el modelo con esta nueva f√≥rmula utilizando √∫nicamente los datos de entrenamiento (<code>X_train</code> y <code>y_train</code>)</strong>.</p>
<div id="6afe6a31" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train y y_train ya han sido definidos y que provienen de la partici√≥n original de los datos.</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Tambi√©n asumiendo que y_train.name ya fue asignado a 'mpg'.</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Se define la f√≥rmula del modelo con las variables seleccionadas</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>selected_formula <span class="op">=</span> <span class="st">'mpg ~ wt + qsec + am'</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Se prepara el DataFrame de entrenamiento solo con las variables seleccionadas</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Primero, se identifica las columnas predictoras de la f√≥rmula (wt, qsec, am)</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>predictors_in_selected_formula <span class="op">=</span> [<span class="st">'wt'</span>, <span class="st">'qsec'</span>, <span class="st">'am'</span>] <span class="co"># Se extraen estas de la f√≥rmula si es din√°mica</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Asegurarse de que estas columnas existen en X_train antes de seleccionarlas</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Si 'Unnamed: 0' fue un problema, aseg√∫rate de haberlo quitado de X_train previamente.</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Important: Remove 'Unnamed: 0' if it exists in X_train ---</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'Unnamed: 0'</span> <span class="kw">in</span> X_train.columns:</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>])</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.copy() <span class="co"># Use .copy() to avoid SettingWithCopyWarning</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Para este ejemplo, asumiremos que X_train ya es X_train_cleaned si usaste ese paso.</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>X_train_selected <span class="op">=</span> X_train[predictors_in_selected_formula]</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Se combina el X_train_selected y y_train en un solo DataFrame</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es necesario para statsmodels.formula.api.ols</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>train_data_selected_model <span class="op">=</span> pd.concat([X_train_selected, y_train], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Se entrena el modelo OLS con la f√≥rmula y los datos reducidos</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"--- Entrenando el modelo final con la f√≥rmula: </span><span class="sc">{</span>selected_formula<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>final_modelo_ols_py <span class="op">=</span> smf.ols(formula <span class="op">=</span> selected_formula, </span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>                              data <span class="op">=</span> train_data_selected_model).fit()</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Revisa el resumen del modelo final</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Resumen del Modelo OLS Final (Variables Seleccionadas):"</span>)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final_modelo_ols_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Entrenando el modelo final con la f√≥rmula: mpg ~ wt + qsec + am ---

Resumen del Modelo OLS Final (Variables Seleccionadas):
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.879
Model:                            OLS   Adj. R-squared:                  0.862
Method:                 Least Squares   F-statistic:                     50.92
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           8.26e-10
Time:                        15:18:11   Log-Likelihood:                -54.262
No. Observations:                  25   AIC:                             116.5
Df Residuals:                      21   BIC:                             121.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -3.0270      8.017     -0.378      0.710     -19.700      13.646
wt            -3.1064      0.728     -4.267      0.000      -4.620      -1.592
qsec           1.7715      0.352      5.033      0.000       1.039       2.504
am             3.9631      1.421      2.788      0.011       1.007       6.919
==============================================================================
Omnibus:                        1.036   Durbin-Watson:                   1.169
Prob(Omnibus):                  0.596   Jarque-Bera (JB):                1.008
Skew:                           0.368   Prob(JB):                        0.604
Kurtosis:                       2.347   Cond. No.                         314.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<section id="modelo-predictivo" class="level3">
<h3 class="anchored" data-anchor-id="modelo-predictivo">Modelo predictivo</h3>
<p>Con la funci√≥n <strong><code>predict()</code></strong> gen√©rica en R que se utiliza para obtener predicciones de varios tipos de objetos de modelos (lineales, √°rboles de decisi√≥n, series de tiempo, etc.). Su comportamiento exacto depende de la clase del objeto que se le pasa como primer argumento.</p>
<p>Esta operaci√≥n es un paso clave en el flujo de trabajo de modelado predictivo, ya que permite:</p>
<ol type="1">
<li><p><strong>Evaluaci√≥n del modelo:</strong> Una vez que se tienen las <code>predicciones</code> para el <code>test_data</code>, se puede compararlas con los valores reales (observados) de la variable dependiente en el <code>test_data</code> (si se tienen) para <strong>evaluar qu√© tan bien se desempe√±a el modelo</strong> en datos no vistos. Esto ayuda a estimar su rendimiento en el mundo real y a detectar problemas como el <strong>sobreajuste (overfitting)</strong>.</p></li>
<li><p><strong>Uso pr√°ctico del modelo:</strong> Despu√©s de validar que el modelo es bueno, se puede usarlo para predecir la variable dependiente para nuevas observaciones futuras de las que solo se conocen las variables predictoras (por ejemplo, predecir el precio de una casa bas√°ndose en sus caracter√≠sticas, si el modelo fue entrenado para eso).</p></li>
</ol>
<p>El objeto <code>final_modelo_ols_py</code> (que es un objeto de tipo <code>statsmodels.regression.linear_model.RegressionResultsWrapper</code>) tiene un m√©todo <code>.predict()</code> que hace exactamente esto.</p>
<div id="41263894" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Para el modelo en los datos de prueba</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># En R, usas 'newdata = test_data_reducido'. En Python, pasas el DataFrame</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># con las mismas columnas predictoras que el modelo fue entrenado con.</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Identificar las variables predictoras del modelo final</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Se pueden obtener directamente de la f√≥rmula o recordarlas:</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Por ejemplo, para 'mpg ~ wt + qsec + am', las predictoras son 'wt', 'qsec', 'am'</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>predictors_final_model <span class="op">=</span> [<span class="st">'wt'</span>, <span class="st">'qsec'</span>, <span class="st">'am'</span>]</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Se crea un dataFrame de datos de prueba con solo las columnas necesarias para la predicci√≥n</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Es crucial que X_test_reducido tenga las mismas columnas y en el mismo orden (aunque el orden no suele ser tan estricto</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># si usas DataFrames con nombres de columnas, es buena pr√°ctica) que X_train_selected.</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>X_test_reducido <span class="op">=</span> X_test[predictors_final_model]</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular las predicciones</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>predicciones_py <span class="op">=</span> final_modelo_ols_py.predict(X_test_reducido)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Predicciones del modelo en los datos de prueba:"</span>)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(predicciones_py)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Opcional: Si quieres comparar las predicciones con los valores reales de y_test</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Valores reales de mpg en el conjunto de prueba:"</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Predicciones del modelo en los datos de prueba:
7     22.493520
31    25.250166
5     22.044524
26    23.872414
8     27.755115
27    26.174421
12    16.564478
dtype: float64

Valores reales de mpg en el conjunto de prueba:
7     24.4
31    21.4
5     18.1
26    26.0
8     22.8
27    30.4
12    17.3
Name: mpg, dtype: float64</code></pre>
</div>
</div>
</section>
<section id="evaluar-el-desempe√±o-predictivo" class="level3">
<h3 class="anchored" data-anchor-id="evaluar-el-desempe√±o-predictivo">Evaluar el desempe√±o predictivo</h3>
<section id="mean-absolute-error-mae" class="level4">
<h4 class="anchored" data-anchor-id="mean-absolute-error-mae">Mean Absolute Error (<code>MAE</code>)</h4>
<p>El <strong>MAE (Mean Absolute Error)</strong>, o <strong>Error Absoluto Medio</strong> en espa√±ol, es una de las m√©tricas m√°s utilizadas para evaluar la precisi√≥n de un modelo de regresi√≥n. Mide la <strong>magnitud promedio de los errores</strong> entre los valores predichos por un modelo y los valores reales observados.</p>
<section id="f√≥rmula-del-mae" class="level5">
<h5 class="anchored" data-anchor-id="f√≥rmula-del-mae">F√≥rmula del MAE</h5>
<p>La f√≥rmula para calcular el MAE es la siguiente:</p>
<p><span class="math display">\[MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(n\)</span>: Es el n√∫mero total de observaciones (o puntos de datos) en el conjunto de datos.</li>
<li><span class="math inline">\(y_i\)</span>: Es el <strong>valor real u observado</strong> de la variable dependiente para la observaci√≥n <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(\hat{y}_i\)</span>: Es el <strong>valor predicho</strong> por el modelo para la observaci√≥n <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(|y_i - \hat{y}_i|\)</span>: Es el <strong>valor absoluto</strong> de la diferencia entre el valor real y el valor predicho para la observaci√≥n <span class="math inline">\(i\)</span>. Tomar el valor absoluto es crucial porque evita que los errores positivos y negativos se cancelen entre s√≠, lo que dar√≠a una falsa impresi√≥n de precisi√≥n.</li>
<li><span class="math inline">\(\sum_{i=1}^{n}\)</span>: Indica la suma de todos los errores absolutos para todas las <span class="math inline">\(n\)</span> observaciones.</li>
</ul>
<div id="2d222036" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># C√°lculo del MAE (Mean Absolute Error)</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y_test, predicciones_py)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MAE en conjunto de prueba: </span><span class="sc">{</span>mae<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MAE en conjunto de prueba: 3.1064</code></pre>
</div>
</div>
<p>Esto significa que, <strong>en promedio</strong>, el modelo reducido predice el consumo de combustible con un error de ¬±3.10 mpg. Esto es bueno o malo. Depende del rango de la variable <code>mpg</code> en <code>mtcars</code>.</p>
<div id="1af6c472" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el rango (m√≠nimo y m√°ximo) de la columna 'mpg'</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>min_mpg <span class="op">=</span> mtcars_df[<span class="st">'mpg'</span>].<span class="bu">min</span>()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>max_mpg <span class="op">=</span> mtcars_df[<span class="st">'mpg'</span>].<span class="bu">max</span>()</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimir el resultado</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Rango de mpg (m√≠nimo, m√°ximo): (</span><span class="sc">{</span>min_mpg<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>max_mpg<span class="sc">}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rango de mpg (m√≠nimo, m√°ximo): (10.4, 33.9)</code></pre>
</div>
</div>
<p>El rango de <code>mpg</code> es de <strong>10.4 a 33.9</strong>, es decir, abarca <strong>~23.5 unidades</strong>.</p>
<p>Por tanto:</p>
<pre><code>  * Un MAE de **3.10** representa alrededor de un **15% del rango total**. El modelo, en promedio, se equivoca por 3.10 millas por gal√≥n en sus predicciones.  
* No es un error enorme, pero **tampoco es excelente**.  
* Si el modelo completo (`modelo_ols`) ten√≠a un MAE menor, podr√≠a predecir mejor, aunque con m√°s colinealidad.</code></pre>
</section>
</section>
<section id="root-mean-squared-error-rmse" class="level4">
<h4 class="anchored" data-anchor-id="root-mean-squared-error-rmse">Root Mean Squared Error (<code>RMSE</code>)</h4>
<p>El <strong>RMSE (Root Mean Squared Error)</strong>, o <strong>Ra√≠z del Error Cuadr√°tico Medio</strong>, es una de las m√©tricas m√°s comunes y ampliamente utilizadas para evaluar la precisi√≥n de los modelos de regresi√≥n. Mide la <strong>magnitud promedio de los errores</strong> entre los valores predichos por un modelo y los valores reales observados, pero dando <strong>mayor peso a los errores m√°s grandes</strong>.</p>
</section>
<section id="f√≥rmula-del-rmse" class="level4">
<h4 class="anchored" data-anchor-id="f√≥rmula-del-rmse">F√≥rmula del RMSE</h4>
<p><span class="math display">\[RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(n\)</span>: Es el n√∫mero total de observaciones (o puntos de datos).<br>
</li>
<li><span class="math inline">\(y_i\)</span>: Es el <strong>valor real u observado</strong> de la variable dependiente para la observaci√≥n <span class="math inline">\(i\)</span>.<br>
</li>
<li><span class="math inline">\(\hat{y}_i\)</span>: Es el <strong>valor predicho</strong> por el modelo para la observaci√≥n <span class="math inline">\(i\)</span>.<br>
</li>
<li><span class="math inline">\((y_i - \hat{y}_i)^2\)</span>: Es el <strong>cuadrado de la diferencia</strong> entre el valor real y el valor predicho para la observaci√≥n <span class="math inline">\(i\)</span>.</li>
</ul>
<p>Elevar al cuadrado las diferencias tiene dos prop√≥sitos principales:</p>
<ul>
<li>Eliminar los signos negativos: Asegura que los errores positivos y negativos no se cancelen entre s√≠.<br>
</li>
<li>Penalizar m√°s los errores grandes: Los errores m√°s grandes tienen un impacto desproporcionadamente mayor en el resultado final del RMSE que los errores peque√±os, debido a la operaci√≥n al cuadrado.<br>
</li>
<li><span class="math inline">\(\sum_{i=1}^{n}\)</span>: Indica la suma de todos los errores al cuadrado para todas las <span class="math inline">\(n\)</span> observaciones.</li>
</ul>
<section id="interpretaci√≥n-del-rmse" class="level5">
<h5 class="anchored" data-anchor-id="interpretaci√≥n-del-rmse">Interpretaci√≥n del RMSE:</h5>
<ul>
<li>El RMSE se expresa en las <strong>mismas unidades que la variable dependiente original</strong>. Esto facilita su interpretaci√≥n. Por ejemplo, si est√°s prediciendo la altura en metros y el RMSE es 0.5, significa que, en promedio, las predicciones del modelo se desv√≠an aproximadamente 0.5 metros de la altura real.<br>
</li>
<li><strong>Un RMSE de 0 (cero) indica un modelo perfecto</strong>, donde todas las predicciones son exactamente iguales a los valores reales.</li>
<li><strong>Valores m√°s bajos de RMSE indican un mejor rendimiento del modelo.</strong>
<ul>
<li><strong>Sensibilidad a valores at√≠picos:</strong> Debido al t√©rmino al cuadrado, el RMSE penaliza m√°s fuertemente los errores grandes (valores at√≠picos) que el MAE. Esto significa que si tu modelo tiene algunos errores de predicci√≥n muy grandes, el RMSE ser√° significativamente m√°s alto que el MAE. Esta caracter√≠stica puede ser una ventaja o desventaja dependiendo del contexto:<br>
</li>
<li><strong>Ventaja:</strong> Si los errores grandes son particularmente indeseables en tu aplicaci√≥n, el RMSE es una buena m√©trica porque los destaca.<br>
</li>
</ul></li>
<li><strong>Desventaja:</strong> Si tu conjunto de datos contiene muchos valores at√≠picos reales o errores de medici√≥n que no son representativos del rendimiento general del modelo, el RMSE podr√≠a dar una visi√≥n pesimista.</li>
</ul>
<div id="66c3d9af" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># C√°lculo del RMSE (Root Mean Squared Error)</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test, predicciones_py))</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">RMSE en conjunto de prueba: </span><span class="sc">{</span>rmse<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
RMSE en conjunto de prueba: 3.4120</code></pre>
</div>
</div>
<ul>
<li>Un RMSE de <strong>3.4120</strong> significa que, en promedio, las predicciones difieren de los valores reales por <strong>¬±3.41 millas por gal√≥n</strong>.
<ul>
<li>Como <strong>los errores grandes tienen m√°s peso</strong> (al ser elevados al cuadrado), el RMSE ser√° siempre <strong>igual o mayor al MAE</strong>. Penaliza m√°s los errores grandes que el MAE.</li>
<li>Es <strong>aceptable para predicci√≥n en <code>mtcars</code></strong>, pero con espacio para mejora si se requiere mayor precisi√≥n.</li>
</ul></li>
</ul>
<p><strong>Compararlo con el MAE</strong></p>
<ul>
<li>Si <strong>RMSE est√° mucho m√°s alto que el MAE</strong>, el modelo est√° cometiendo <strong>errores grandes con frecuencia</strong> (outliers, mala especificaci√≥n).<br>
</li>
<li>Si <strong>RMSE ‚âà MAE</strong>, los errores est√°n bien distribuidos.</li>
</ul>
</section>
</section>
<section id="coeficiente-de-determinaci√≥n-r2" class="level4">
<h4 class="anchored" data-anchor-id="coeficiente-de-determinaci√≥n-r2">Coeficiente de determinaci√≥n <span class="math inline">\(R^2\)</span></h4>
<p><span class="math inline">\(R^{2}\)</span> (<strong>coeficiente de determinaci√≥n</strong>) mide qu√© proporci√≥n de la variabilidad de la <strong>variable dependiente</strong> es explicada por el modelo.</p>
<p>La f√≥rmula general del <span class="math inline">\(R^2\)</span> (coeficiente de determinaci√≥n) es:</p>
<p><span class="math display">\[R^2 = 1 - \frac{SSE}{SST}\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(SSE\)</span> (Sum of Squared Errors) o <span class="math inline">\(RSS\)</span> (Residual Sum of Squares): Es la <strong>Suma de Cuadrados de los Errores</strong> (o Suma de Cuadrados de los Residuos). Mide la variaci√≥n no explicada por el modelo. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados (<span class="math inline">\(y_i\)</span>) y los valores predichos por el modelo (<span class="math inline">\(\hat{y}_i\)</span>):</li>
</ul>
<p><span class="math display">\[SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span></p>
<ul>
<li><span class="math inline">\(SST\)</span> (Total Sum of Squares): Es la <strong>Suma Total de Cuadrados</strong>. Mide la variaci√≥n total de la variable dependiente respecto a su media. Representa la variabilidad total en los datos que el modelo intenta explicar. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados (<span class="math inline">\(y_i\)</span>) y la media de la variable dependiente (<span class="math inline">\(\bar{y}\)</span>):</li>
</ul>
<p><span class="math display">\[SST = \sum_{i=1}^{n} (y_i - \bar{y})^2\]</span></p>
<section id="interpretaci√≥n-del-r2" class="level5">
<h5 class="anchored" data-anchor-id="interpretaci√≥n-del-r2">Interpretaci√≥n del <span class="math inline">\(R^2\)</span>:</h5>
<ul>
<li>El <span class="math inline">\(R^2\)</span> es una m√©trica que var√≠a entre <strong>0 y 1</strong> (o 0% y 100%).<br>
</li>
<li><span class="math inline">\(R^2 = 0\)</span>: Indica que el modelo no explica ninguna de la variabilidad en la variable dependiente. Es tan bueno como simplemente usar la media de la variable dependiente para la predicci√≥n.<br>
</li>
<li><span class="math inline">\(R^2 = 1\)</span>: Indica que el modelo explica el 100% de la variabilidad en la variable dependiente. Esto rara vez ocurre en la pr√°ctica con datos del mundo real, y a menudo sugiere sobreajuste si sucede en un conjunto de entrenamiento.<br>
</li>
<li><strong>Valores m√°s altos de</strong> <span class="math inline">\(R^2\)</span> indican un mejor ajuste del modelo a los datos observados, lo que significa que las variables predictoras del modelo explican una mayor proporci√≥n de la variabilidad en la variable dependiente.</li>
</ul>
<div id="ed696922" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>r_squared_test <span class="op">=</span> r2_score(y_test, predicciones_py)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared en conjunto de prueba: </span><span class="sc">{</span>r_squared_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R-squared en conjunto de prueba: 0.3468</code></pre>
</div>
</div>
<ul>
<li>Esto significa que el <strong>65.3% de la variabilidad</strong> de <code>mpg</code> (consumo de combustible) en los datos de prueba <strong>es explicada por el modelo</strong>.
<ul>
<li>El <strong>34.6% restante</strong> es <strong>variabilidad no explicada</strong> (error, factores no incluidos, ruido).<br>
</li>
<li>El modelo predice <strong>m√°s de la mitad de la variabilidad de <code>mpg</code></strong> en los datos de prueba.</li>
</ul></li>
</ul>
</section>
</section>
<section id="distribuci√≥n-de-los-residuos" class="level4">
<h4 class="anchored" data-anchor-id="distribuci√≥n-de-los-residuos">Distribuci√≥n de los residuos</h4>
<p>Relaci√≥n lineal entre variable dependiente e independiente:</p>
<p>Se calculan los residuos para cada observaci√≥n y se representan (<code>scatterplot</code>). Si las observaciones siguen la l√≠nea del modelo, los residuos se deben distribuir aleatoriamente entorno al valor 0.</p>
<div id="5878c6f0" class="cell" data-message="false" data-results="as-is" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Se crea un dataframe 'tabla' con fitted.values y residuals</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># En statsmodels, los valores ajustados se obtienen con .fittedvalues y los residuos con .resid</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>tabla_py <span class="op">=</span> pd.DataFrame({</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>                         <span class="st">'prediccion'</span>: final_modelo_ols_py.fittedvalues,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>                         <span class="st">'residuo'</span>: final_modelo_ols_py.resid</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Configuraci√≥n de los estilos para el gr√°fico (similar a theme_bw y los ajustes de texto de ggplot2)</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Configura el estilo de seaborn</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>) <span class="co"># Similar a theme_bw() o theme_minimal()</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Se configura la fuente globalmente en Montserrat</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.family'</span>] <span class="op">=</span> <span class="st">'Montserrat'</span> <span class="co"># Descomenta si tienes la fuente instalada</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Se crea la figura y los ejes</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)) <span class="co"># Tama√±o de la figura</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Se crea el gr√°fico de dispersi√≥n con Seaborn</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Se usa scatterplot para los puntos y controlamos el color con 'hue'</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Se usa palette para la escala de colores, similar a scale_color_gradient2</span></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>scatterplot <span class="op">=</span> sns.scatterplot(</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>                              data <span class="op">=</span> tabla_py,</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>                              x <span class="op">=</span> <span class="st">'prediccion'</span>,</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>                              y <span class="op">=</span> <span class="st">'residuo'</span>,</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>                              hue <span class="op">=</span> <span class="st">'residuo'</span>, <span class="co"># Colorear por el valor del residuo</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>                              palette <span class="op">=</span> <span class="st">'RdBu_r'</span>, <span class="co"># 'RdBu_r' es una paleta divergente (rojo-azul, invertida para azul-rojo)</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>                                                <span class="co"># 'coolwarm' tambi√©n es una buena opci√≥n divergente.</span></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>                              legend <span class="op">=</span> <span class="va">False</span>,     <span class="co"># No mostrar leyenda de color, similar a legend.position = "none"</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>                              s <span class="op">=</span> <span class="dv">70</span>,             <span class="co"># Tama√±o de los puntos</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>                              alpha <span class="op">=</span> <span class="fl">0.8</span>         <span class="co"># Transparencia</span></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 4.Se a√±ade la l√≠nea horizontal en y=0</span></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>plt.axhline(y <span class="op">=</span> <span class="dv">0</span>, color <span class="op">=</span> <span class="st">'black'</span>, linestyle <span class="op">=</span> <span class="st">'-'</span>, linewidth <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Se a√±aden los segmentos desde los puntos hasta y = 0</span></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Se puede hacer iterando o usando una funci√≥n de matplotlib si fuera posible vectorizarlo</span></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Para simplicidad y control, iteramos aqu√≠. Ojo: para muchos puntos, esto puede ser lento.</span></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Para muchos puntos, podr√≠as considerar alternativas o quitarlo si no es cr√≠tico para la interpretaci√≥n.</span></span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tabla_py)):</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    x_val <span class="op">=</span> tabla_py[<span class="st">'prediccion'</span>].iloc[i]</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>    y_val <span class="op">=</span> tabla_py[<span class="st">'residuo'</span>].iloc[i]</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>    plt.plot([x_val, x_val], [y_val, <span class="dv">0</span>], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth <span class="op">=</span> <span class="fl">0.5</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>)</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Se configuran las etiquetas y t√≠tulo</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribuci√≥n de los residuos"</span>, fontsize <span class="op">=</span> <span class="dv">18</span>, loc <span class="op">=</span> <span class="st">'left'</span>, fontweight <span class="op">=</span> <span class="st">'bold'</span>)</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"predicci√≥n modelo"</span>, fontsize <span class="op">=</span> <span class="dv">14</span>)</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"residuo"</span>, fontsize <span class="op">=</span> <span class="dv">14</span>)</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustes de los ticks y etiquetas de los ejes</span></span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>plt.tick_params(axis <span class="op">=</span> <span class="st">'x'</span>, labelsize <span class="op">=</span> <span class="dv">12</span>)</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>plt.tick_params(axis  <span class="op">=</span><span class="st">'y'</span>, labelsize <span class="op">=</span> <span class="dv">12</span>)</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar los l√≠mites del eje y si es necesario para evitar que los puntos se corten</span></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.ylim(min(tabla_py['residuo']) * 1.1, max(tabla_py['residuo']) * 1.1)</span></span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar el gr√°fico</span></span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>plt.tight_layout() <span class="co"># Ajusta el dise√±o para que no se corten etiquetas</span></span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_01_OLSR_py_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>