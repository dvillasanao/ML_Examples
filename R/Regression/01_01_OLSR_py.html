<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Diana Villasana Ocampo">

<title>Ordinary Least Squares Regression (OLSR)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="01_01_OLSR_py_files/libs/clipboard/clipboard.min.js"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/popper.min.js"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="01_01_OLSR_py_files/libs/quarto-html/anchor.min.js"></script>
<link href="01_01_OLSR_py_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="01_01_OLSR_py_files/libs/quarto-html/quarto-syntax-highlighting-af5ec82acda093b5ee751184164e9432.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="01_01_OLSR_py_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="01_01_OLSR_py_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="01_01_OLSR_py_files/libs/bootstrap/bootstrap-7714f832e6fc2622986168d4fba84f88.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#objetivo" id="toc-objetivo" class="nav-link active" data-scroll-target="#objetivo">Objetivo</a></li>
  <li><a href="#metodología" id="toc-metodología" class="nav-link" data-scroll-target="#metodología">Metodología</a></li>
  <li><a href="#pasos-generales-del-machine-learning-supervisado" id="toc-pasos-generales-del-machine-learning-supervisado" class="nav-link" data-scroll-target="#pasos-generales-del-machine-learning-supervisado"><strong>Pasos generales del Machine Learning supervisado</strong></a></li>
  <li><a href="#base-de-datos" id="toc-base-de-datos" class="nav-link" data-scroll-target="#base-de-datos">Base de datos</a></li>
  <li><a href="#entrenamiento-de-los-datos-traintest" id="toc-entrenamiento-de-los-datos-traintest" class="nav-link" data-scroll-target="#entrenamiento-de-los-datos-traintest">Entrenamiento de los datos (train/test)</a></li>
  <li><a href="#entrenamiento-del-modelo" id="toc-entrenamiento-del-modelo" class="nav-link" data-scroll-target="#entrenamiento-del-modelo">Entrenamiento del modelo</a></li>
  <li><a href="#selección-de-variables" id="toc-selección-de-variables" class="nav-link" data-scroll-target="#selección-de-variables">Selección de variables</a>
  <ul class="collapse">
  <li><a href="#criterio-de-información-de-akaike" id="toc-criterio-de-información-de-akaike" class="nav-link" data-scroll-target="#criterio-de-información-de-akaike">Criterio de Información de Akaike</a></li>
  <li><a href="#interpretación-final" id="toc-interpretación-final" class="nav-link" data-scroll-target="#interpretación-final">Interpretación Final</a></li>
  <li><a href="#forward-or-backward-stepwise" id="toc-forward-or-backward-stepwise" class="nav-link" data-scroll-target="#forward-or-backward-stepwise">Forward or backward stepwise</a></li>
  <li><a href="#variance-inflation-factor-vif" id="toc-variance-inflation-factor-vif" class="nav-link" data-scroll-target="#variance-inflation-factor-vif">Variance Inflation Factor (<code>VIF</code>)</a></li>
  </ul></li>
  <li><a href="#evaluación-del-modelo" id="toc-evaluación-del-modelo" class="nav-link" data-scroll-target="#evaluación-del-modelo">Evaluación del modelo</a>
  <ul class="collapse">
  <li><a href="#modelo-predictivo" id="toc-modelo-predictivo" class="nav-link" data-scroll-target="#modelo-predictivo">Modelo predictivo</a></li>
  <li><a href="#evaluar-el-desempeño-predictivo" id="toc-evaluar-el-desempeño-predictivo" class="nav-link" data-scroll-target="#evaluar-el-desempeño-predictivo">Evaluar el desempeño predictivo</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Ordinary Least Squares Regression (OLSR)</h1>
<p class="subtitle lead">Apuntes y anotaciones personales</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Diana Villasana Ocampo </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<style type="text/css">
body {
text-align: justify;
font-style: normal;
font-family: "Montserrat";
font-size: 12px
}
h1.title {
  font-size: 40px;
  color: #000D3B;
}
h1 {
  font-size: 35px;
  color: #B6854D;
}
h2 {
  font-size: 30px;
  color: #172984;
}
h3 {
  font-size: 25px;
  color: #172984;
}
h4 {
  font-size: 22px;
  color: #172984;
}
h5 {
  ont-size: 20px;
  color: #172984;
}
h6{
  ont-size: 18px;
  color: #1864cb;
}
</style>
<style>
.nav>li>a {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #1C3BA4
}
.nav-pills>li.active>a, .nav-pills>li.active>a:hover, .nav-pills>li>a:focus {
    color: #ffffff;
    background-color: #09C2BC
}
</style>
<style>
.tile1-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6A87;
    list-style: none;
}
.top1-tiles a:nth-of-type(1):hover, .top-tiles1 a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6A87
}
</style>
<style>
.tile2-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6CC8;
    list-style: none;
}
.top2-tiles a:nth-of-type(1):hover, .top2-tiles a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6CC8
}
</style>
<style>
.math {
  font-size: 15px;
  color: #1e42ab;
}

.callout {
  border: 1px solid red; /* Yellow border */
  background-color: lightgrey; /* Light yellow background */
  padding: 15px;
  margin-bottom: 15px;
  border-left: 5px solid #ffcc00; /* Stronger left border */
}

</style>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Este material es reproducible en código Python utilizando Quarto
</div>
</div>
<div class="callout-body-container callout-body">

</div>
</div>
<p>La Regresión por Mínimos Cuadrados Ordinarios (Ordinary Least Squares Regression, <strong>OLSR</strong> u <strong>OLS</strong>) representa una metodología estadística esencial que permite analizar la correlación entre una <strong>variable dependiente</strong> (también conocida como variable de respuesta) y una o más <strong>variables independientes</strong> (o predictoras). Este método constituye una herramienta fundamental en el campo del análisis de regresión lineal.</p>
<p align="center">
</p><p><img src="../../img/Regression/01_image_OLSR.png" alt="Machine Learning Steps" width="40%"></p>
<p></p>
<p><strong>Librerías que se usaron en el documento</strong></p>
<div id="load-py-pckgs" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#conda install -c conda-forge numpy</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#conda install -c conda-forge pandas</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#conda install -c conda-forge scikit-learn</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpy2</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os <span class="co"># Necesario para la función os.makedirs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c8eccfd4" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display" data-execution_count="3">
<style type="text/css">
#T_0721e td {
  padding: 1px;
}
#T_0721e_row0_col0, #T_0721e_row0_col1, #T_0721e_row1_col0, #T_0721e_row1_col1, #T_0721e_row2_col0, #T_0721e_row2_col1, #T_0721e_row3_col0, #T_0721e_row3_col1, #T_0721e_row4_col0, #T_0721e_row4_col1, #T_0721e_row5_col0, #T_0721e_row5_col1, #T_0721e_row6_col0, #T_0721e_row6_col1, #T_0721e_row7_col0, #T_0721e_row7_col1, #T_0721e_row8_col0, #T_0721e_row8_col1, #T_0721e_row9_col0, #T_0721e_row9_col1, #T_0721e_row10_col0, #T_0721e_row10_col1, #T_0721e_row11_col0, #T_0721e_row11_col1, #T_0721e_row12_col0, #T_0721e_row12_col1 {
  width: 200px;
  text-align: left;
}
#T_0721e_row0_col2, #T_0721e_row1_col2, #T_0721e_row2_col2, #T_0721e_row3_col2, #T_0721e_row4_col2, #T_0721e_row5_col2, #T_0721e_row6_col2, #T_0721e_row7_col2, #T_0721e_row8_col2, #T_0721e_row9_col2, #T_0721e_row10_col2, #T_0721e_row11_col2, #T_0721e_row12_col2 {
  width: 500px;
  text-align: left;
}
</style>

<div id="T_0721e" class="quarto-float quarto-figure quarto-figure-center anchored" style="font-family: Century Gothic; font-size: 10pt;" data-quarto-postprocess="true">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="T_0721e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Fuente: Elaboración propia
</figcaption>
<div aria-describedby="T_0721e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table id="T_0721e" class="caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_0721e_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Criterio</th>
<th id="T_0721e_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Aplica</th>
<th id="T_0721e_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Detalles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_0721e_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_0721e_row0_col0" class="data row0 col0">🔍 Tipo de modelo</td>
<td id="T_0721e_row0_col1" class="data row0 col1">Supervisado</td>
<td id="T_0721e_row0_col2" class="data row0 col2">Se entrena con datos X → y</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_0721e_row1_col0" class="data row1 col0">🎯 Variable respuesta</td>
<td id="T_0721e_row1_col1" class="data row1 col1">Numérica continua</td>
<td id="T_0721e_row1_col2" class="data row1 col2">Ej. mpg, precio, ingresos</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_0721e_row2_col0" class="data row2 col0">🔢 Variables predictoras</td>
<td id="T_0721e_row2_col1" class="data row2 col1">Numéricas y/o categóricas</td>
<td id="T_0721e_row2_col2" class="data row2 col2">Categorías convertidas a dummies</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_0721e_row3_col0" class="data row3 col0">📈 Relación entre variables</td>
<td id="T_0721e_row3_col1" class="data row3 col1">Lineal (supuesto clave)</td>
<td id="T_0721e_row3_col2" class="data row3 col2">Se asume una relación lineal entre X e Y</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_0721e_row4_col0" class="data row4 col0">🧪 Normalidad de residuos</td>
<td id="T_0721e_row4_col1" class="data row4 col1">Deseable</td>
<td id="T_0721e_row4_col2" class="data row4 col2">Importante para intervalos de confianza válidos</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_0721e_row5_col0" class="data row5 col0">🔁 Independencia de errores</td>
<td id="T_0721e_row5_col1" class="data row5 col1">Necesaria</td>
<td id="T_0721e_row5_col2" class="data row5 col2">Errores deben ser independientes</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_0721e_row6_col0" class="data row6 col0">⚖️ Homoscedasticidad</td>
<td id="T_0721e_row6_col1" class="data row6 col1">Necesaria</td>
<td id="T_0721e_row6_col2" class="data row6 col2">Varianza de errores debe ser constante</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_0721e_row7_col0" class="data row7 col0">❗ Sensible a outliers</td>
<td id="T_0721e_row7_col1" class="data row7 col1">Sí</td>
<td id="T_0721e_row7_col2" class="data row7 col2">Outliers pueden influir mucho en el modelo</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_0721e_row8_col0" class="data row8 col0">🔗 Multicolinealidad entre predictores</td>
<td id="T_0721e_row8_col1" class="data row8 col1">Problema común</td>
<td id="T_0721e_row8_col2" class="data row8 col2">Usar VIF para detectar problemas</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_0721e_row9_col0" class="data row9 col0">🧠 Interpretabilidad</td>
<td id="T_0721e_row9_col1" class="data row9 col1">Alta</td>
<td id="T_0721e_row9_col2" class="data row9 col2">Modelo fácil de explicar</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">10</td>
<td id="T_0721e_row10_col0" class="data row10 col0">🚀 Velocidad y eficiencia</td>
<td id="T_0721e_row10_col1" class="data row10 col1">Muy alta</td>
<td id="T_0721e_row10_col2" class="data row10 col2">Rápido incluso con datos grandes</td>
</tr>
<tr class="even">
<td id="T_0721e_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">11</td>
<td id="T_0721e_row11_col0" class="data row11 col0">🧪 Validación cruzada</td>
<td id="T_0721e_row11_col1" class="data row11 col1">Compatible</td>
<td id="T_0721e_row11_col2" class="data row11 col2">Ayuda a prevenir overfitting</td>
</tr>
<tr class="odd">
<td id="T_0721e_level0_row12" class="row_heading level0 row12" data-quarto-table-cell-role="th">12</td>
<td id="T_0721e_row12_col0" class="data row12 col0">❌ No funciona bien si...</td>
<td id="T_0721e_row12_col1" class="data row12 col1">Relaciones no lineales, outliers severos, colinealidad</td>
<td id="T_0721e_row12_col2" class="data row12 col2">Evitar si no hay linealidad o hay muchos outliers</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
<section id="objetivo" class="level2">
<h2 class="anchored" data-anchor-id="objetivo">Objetivo</h2>
<p>La Regresión por Mínimos Cuadrados Ordinarios (<code>OLSR</code>) busca la línea que mejor se ajusta a los datos. Para lograrlo, reduce al mínimo la suma de los cuadrados de las diferencias entre los valores reales y los valores que predice el modelo. Estas diferencias son los <strong>residuos</strong> o <strong>errores</strong>. Al trabajar con los cuadrados de los errores, este método evita que los errores positivos y negativos se anulen entre sí, y da más peso a los errores grandes durante el proceso de minimización.</p>
</section>
<section id="metodología" class="level2">
<h2 class="anchored" data-anchor-id="metodología">Metodología</h2>
<p>La metodología de OLSR se basa en los siguientes pasos y principios:</p>
<ol type="1">
<li><p><strong>Modelo Lineal:</strong> OLSR asume una relación lineal entre las variables. Para una regresión lineal simple (una variable independiente), la ecuación es:<br>
<span class="math display">\[Y = \beta_0 + \beta_1X + \epsilon\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(Y\)</span> es la variable dependiente.</li>
</ul></li>
</ol>
<ul>
<li><span class="math inline">\(X\)</span> es la variable independiente.</li>
<li><span class="math inline">\(\beta_0\)</span> es el intercepto (el valor de <span class="math inline">\(Y\)</span> cuando <span class="math inline">\(X\)</span> es 0).</li>
<li><span class="math inline">\(\beta_1\)</span> es la pendiente (el cambio en <span class="math inline">\(Y\)</span> por cada unidad de cambio en <span class="math inline">\(X\)</span>).</li>
<li><span class="math inline">\(\epsilon\)</span> es el término de error o residual, que representa la parte de <span class="math inline">\(Y\)</span> que no puede ser explicada por <span class="math inline">\(X\)</span>.</li>
</ul>
<p>Para una regresión lineal múltiple (varias variables independientes), la ecuación se expande a:<br>
<span class="math display">\[Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k + \epsilon\]</span></p>
<ol start="2" type="1">
<li><strong>Minimización de la Suma de Cuadrados de Residuos (SSR):</strong> El corazón de OLS es encontrar los valores de los coeficientes (<span class="math inline">\(\beta_0, \beta_1\)</span>, etc.) que minimicen la siguiente función:<br>
<span class="math display">\[\text{Minimizar } \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span><br>
Donde:
<ul>
<li><span class="math inline">\(y_i\)</span> es el valor observado de la variable dependiente para la observación <span class="math inline">\(i\)</span>.</li>
</ul></li>
</ol>
<ul>
<li><span class="math inline">\(\hat{y}_i\)</span> es el valor predicho de la variable dependiente por el modelo para la observación <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\((y_i - \hat{y}_i)\)</span> es el residual para la observación <span class="math inline">\(i\)</span>.</li>
</ul>
<p>Para lograr esta minimización, se utilizan técnicas de cálculo (derivadas parciales) para encontrar los valores de los coeficientes que hacen que la pendiente de la función de suma de cuadrados sea cero.</p>
<ol start="3" type="1">
<li><p><strong>Estimación de Coeficientes:</strong> Los valores estimados de los coeficientes, denotados como <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span>, etc., son aquellos que resultan de la minimización. Estos coeficientes son los que definen la “línea de mejor ajuste”.</p></li>
<li><p><strong>Supuestos del OLS:</strong> Para que los estimadores de OLS sean los “mejores estimadores lineales insesgados” (según el Teorema de Gauss-Markov), se deben cumplir ciertas suposiciones:</p>
<ul>
<li><p><strong>Linealidad:</strong> La relación entre las variables es lineal.</p></li>
<li><p><strong>Independencia de los errores:</strong> Los errores de una observación no están correlacionados con los errores de otra.</p></li>
<li><p><strong>Homocedasticidad:</strong> La varianza de los errores es constante en todos los niveles de las variables independientes.</p></li>
<li><p><strong>Normalidad de los errores:</strong> Los errores se distribuyen normalmente (aunque no es estrictamente necesario para la estimación, sí lo es para la inferencia estadística).</p></li>
<li><p><strong>No multicolinealidad perfecta:</strong> Las variables independientes no están perfectamente correlacionadas entre sí.</p></li>
</ul></li>
</ol>
</section>
<section id="pasos-generales-del-machine-learning-supervisado" class="level2">
<h2 class="anchored" data-anchor-id="pasos-generales-del-machine-learning-supervisado"><strong>Pasos generales del Machine Learning supervisado</strong></h2>
<ol type="1">
<li><strong>Importar y explorar los datos</strong></li>
<li><strong>Preprocesamiento</strong></li>
<li><strong>División de los datos (train/test)</strong></li>
<li><strong>Entrenamiento del modelo</strong></li>
<li><strong>Evaluación del modelo</strong></li>
<li><strong>Ajustes o validación cruzada (si aplica)</strong></li>
<li><strong>Predicción con nuevos datos</strong></li>
<li><strong>Interpretación de resultados</strong></li>
</ol>
<p align="center">
<img src="../../img/ML_Steps.png" alt="Machine Learning Steps" width="100%">
</p>
<hr>
</section>
<section id="base-de-datos" class="level2">
<h2 class="anchored" data-anchor-id="base-de-datos">Base de datos</h2>
<p>La base de datos <code>mtcars</code> es un conjunto de datos clásico en R que contiene información sobre <strong>32 automóviles</strong> (modelos de 1973–74), y fue extraído de la revista <em>Motor Trend US</em>. Incluye <strong>variables técnicas</strong> del desempeño de los autos.</p>
<p>Aquí está una descripción de cada columna:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 47%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Significado</th>
<th>Tipo de dato</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>mpg</code></td>
<td>Miles per gallon (millas por galón)</td>
<td>Numérica</td>
</tr>
<tr class="even">
<td><code>cyl</code></td>
<td>Número de cilindros</td>
<td>Entero</td>
</tr>
<tr class="odd">
<td><code>disp</code></td>
<td>Desplazamiento del motor (en pulgadas cúbicas)</td>
<td>Numérica</td>
</tr>
<tr class="even">
<td><code>hp</code></td>
<td>Caballos de fuerza</td>
<td>Entero</td>
</tr>
<tr class="odd">
<td><code>drat</code></td>
<td>Relación del eje trasero (rear axle ratio)</td>
<td>Numérica</td>
</tr>
<tr class="even">
<td><code>wt</code></td>
<td>Peso del auto (en miles de libras)</td>
<td>Numérica</td>
</tr>
<tr class="odd">
<td><code>qsec</code></td>
<td>Tiempo en 1/4 de milla (segundos)</td>
<td>Numérica</td>
</tr>
<tr class="even">
<td><code>vs</code></td>
<td>Tipo de motor: 0 = V-shaped, 1 = straight (en línea)</td>
<td>Binaria (factor)</td>
</tr>
<tr class="odd">
<td><code>am</code></td>
<td>Tipo de transmisión: 0 = automática, 1 = manual</td>
<td>Binaria (factor)</td>
</tr>
<tr class="even">
<td><code>gear</code></td>
<td>Número de velocidades (marchas) adelante</td>
<td>Entero</td>
</tr>
<tr class="odd">
<td><code>carb</code></td>
<td>Número de carburadores</td>
<td>Entero</td>
</tr>
</tbody>
</table>
<div id="3657a813" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>require(reticulate)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>reticulate::repl_python() <span class="co">#can be used to interactively run Python code</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Cargar y se exploran los datos</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>data(<span class="st">"mtcars"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b4367e8d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#pip install openpyxl </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os <span class="co"># Necesario para la función os.makedirs</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar la base de datos mtcars directamente desde el entorno de R</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># r.mtcars accede al objeto 'mtcars' que R ha puesto a disposición</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Reticulate automáticamente lo convierte a un DataFrame de Pandas.</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> r.mtcars</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">## Se guarda la base de datos en un archivo Excel  </span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">file</span> <span class="op">=</span> Path.cwd().parent.parent <span class="op">/</span> <span class="st">"Data"</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>mtcars_df.to_excel(<span class="bu">file</span> <span class="op">/</span><span class="st">"mtcars_data.xlsx"</span>, index<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="50bfc000" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> pd.read_excel(Path.cwd().parent.parent <span class="op">/</span> <span class="st">"Data"</span> <span class="op">/</span> <span class="st">"mtcars_data.xlsx"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3e42bd2e" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">cyl</th>
<th data-quarto-table-cell-role="th">disp</th>
<th data-quarto-table-cell-role="th">hp</th>
<th data-quarto-table-cell-role="th">drat</th>
<th data-quarto-table-cell-role="th">wt</th>
<th data-quarto-table-cell-role="th">qsec</th>
<th data-quarto-table-cell-role="th">vs</th>
<th data-quarto-table-cell-role="th">am</th>
<th data-quarto-table-cell-role="th">gear</th>
<th data-quarto-table-cell-role="th">carb</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Mazda RX4</td>
<td>21.0</td>
<td>6</td>
<td>160.0</td>
<td>110</td>
<td>3.90</td>
<td>2.620</td>
<td>16.46</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Mazda RX4 Wag</td>
<td>21.0</td>
<td>6</td>
<td>160.0</td>
<td>110</td>
<td>3.90</td>
<td>2.875</td>
<td>17.02</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Datsun 710</td>
<td>22.8</td>
<td>4</td>
<td>108.0</td>
<td>93</td>
<td>3.85</td>
<td>2.320</td>
<td>18.61</td>
<td>1</td>
<td>1</td>
<td>4</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Hornet 4 Drive</td>
<td>21.4</td>
<td>6</td>
<td>258.0</td>
<td>110</td>
<td>3.08</td>
<td>3.215</td>
<td>19.44</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Hornet Sportabout</td>
<td>18.7</td>
<td>8</td>
<td>360.0</td>
<td>175</td>
<td>3.15</td>
<td>3.440</td>
<td>17.02</td>
<td>0</td>
<td>0</td>
<td>3</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>Valiant</td>
<td>18.1</td>
<td>6</td>
<td>225.0</td>
<td>105</td>
<td>2.76</td>
<td>3.460</td>
<td>20.22</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>Duster 360</td>
<td>14.3</td>
<td>8</td>
<td>360.0</td>
<td>245</td>
<td>3.21</td>
<td>3.570</td>
<td>15.84</td>
<td>0</td>
<td>0</td>
<td>3</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>Merc 240D</td>
<td>24.4</td>
<td>4</td>
<td>146.7</td>
<td>62</td>
<td>3.69</td>
<td>3.190</td>
<td>20.00</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>Merc 230</td>
<td>22.8</td>
<td>4</td>
<td>140.8</td>
<td>95</td>
<td>3.92</td>
<td>3.150</td>
<td>22.90</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>Merc 280</td>
<td>19.2</td>
<td>6</td>
<td>167.6</td>
<td>123</td>
<td>3.92</td>
<td>3.440</td>
<td>18.30</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><strong>Convertir todas las columnas a tipo numérico</strong></p>
<div id="f8e3e877" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- IMPORTANTE: Convertir todas las columnas a tipo numérico ---</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es crucial para evitar el TypeError</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 'errors='coerce'' convertirá cualquier valor no numérico a NaN</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># y luego se pueden manejar los NaNs (por ejemplo, rellenar o eliminar)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> mtcars_df.<span class="bu">apply</span>(pd.to_numeric, errors<span class="op">=</span><span class="st">'coerce'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="entrenamiento-de-los-datos-traintest" class="level2">
<h2 class="anchored" data-anchor-id="entrenamiento-de-los-datos-traintest">Entrenamiento de los datos (train/test)</h2>
<p>La división de datos en conjuntos de <strong>entrenamiento (train)</strong> y <strong>prueba (test)</strong> es una práctica fundamental en el aprendizaje automático y la modelización predictiva. Su importancia radica en la necesidad de obtener una evaluación <strong>realista y no sesgada</strong> del rendimiento de un modelo, y de asegurar que el modelo sea capaz de <strong>generalizar</strong> a datos nuevos y no vistos.</p>
<ul>
<li>En Python, <code>train_test_split()</code> devuelve directamente los cuatro conjuntos de datos:
<ul>
<li><code>X_train</code>: Predictoras para entrenamiento.</li>
</ul></li>
<li><code>X_test</code>: Predictoras para prueba.</li>
<li><code>y_train</code>: Variable objetivo para entrenamiento.</li>
<li><code>y_test</code>: Variable objetivo para prueba.</li>
</ul>
<div id="split-data" class="cell" data-message="false" data-execution_count="11">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np <span class="co"># Necesario si necesitas setear una semilla para numpy/pandas</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir la variable objetivo (dependiente)</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>target_variable <span class="op">=</span> <span class="st">'mpg'</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># X contendrá todas las variables predictoras (features)</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Y contendrá la variable objetivo</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> mtcars_df.drop(columns<span class="op">=</span>[target_variable])</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> mtcars_df[target_variable]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Dividir los datos en entrenamiento y prueba</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># random_state es el equivalente a set.seed() para reproducibilidad</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># test_size=0.2 significa que el 20% de los datos irán al conjunto de prueba (80% para entrenamiento)</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es importante para asegurar que las proporciones de 'mpg' sean similares en ambos conjuntos,</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># especialmente útil para variables categóricas o si la distribución de 'mpg' es importante.</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tamaño del conjunto de entrenamiento (X_train): </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tamaño del conjunto de prueba (X_test): </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tamaño del conjunto de entrenamiento (y_train): </span><span class="sc">{</span>y_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tamaño del conjunto de prueba (y_test): </span><span class="sc">{</span>y_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tamaño del conjunto de entrenamiento (X_train): (25, 11)
Tamaño del conjunto de prueba (X_test): (7, 11)
Tamaño del conjunto de entrenamiento (y_train): (25,)
Tamaño del conjunto de prueba (y_test): (7,)</code></pre>
</div>
</div>
<ul>
<li>Particionar los datos, evita el <strong>overfitting</strong> (cuando el modelo memoriza los datos de entrenamiento).</li>
<li>Permite una <strong>evaluación honesta</strong> del modelo al probarlo en datos que no vio durante el entrenamiento.</li>
<li>Es una práctica estándar en cualquier pipeline de aprendizaje automático.</li>
</ul>
</section>
<section id="entrenamiento-del-modelo" class="level2">
<h2 class="anchored" data-anchor-id="entrenamiento-del-modelo">Entrenamiento del modelo</h2>
<p>El <strong>entrenamiento de un modelo</strong> es el paso más importante en el aprendizaje automático. Usando un conjunto de datos de entrenamiento (<code>train_data</code>), el modelo aprende a reconocer patrones para hacer predicciones confiables con datos nuevos. Este proceso es esencial por estas razones:</p>
<ul>
<li>Durante el entrenamiento, el modelo <strong>identifica patrones específicos</strong> en los datos.</li>
<li>Separamos los datos en grupos de entrenamiento y prueba para asegurar que el modelo funcione bien no solo con datos conocidos, sino también con <strong>datos nuevos y no vistos</strong>.</li>
<li>Después del entrenamiento con <code>train_data</code>, usamos el <strong>conjunto de prueba (<code>test_data</code>)</strong> para medir el rendimiento. Las métricas (MAE, RMSE, <span class="math inline">\(R^2\)</span>) nos muestran qué tan bien el modelo <strong>maneja datos nuevos</strong>.</li>
<li>Un rendimiento peor en <code>test_data</code> que en <code>train_data</code> indica que el modelo está sobreajustado.</li>
<li>Con estos resultados, podemos decidir si el modelo está listo para usar o necesita ajustes.</li>
</ul>
<p><strong>Función de entrenamiento</strong></p>
<ul>
<li><code>modelo_ols_py = smf.ols(formula=formula, data=train_data_combined).fit()</code>:</li>
<li><code>smf.ols()</code>: Es la función para ajustar un modelo de Mínimos Cuadrados Ordinarios (Ordinary Least Squares - OLS).</li>
<li><code>formula=formula</code>: Le pasamos la cadena de fórmula que definimos.</li>
<li><code>data=train_data_combined</code>: Le indicamos de qué DataFrame debe tomar las variables.</li>
<li><code>.fit()</code>: Este método entrena el modelo sobre los datos.</li>
</ul>
<div id="train-ols-model" class="cell" data-message="false" data-results="as-is" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf <span class="co"># Para la sintaxis tipo R de fórmulas</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Asumiendo que X_train, X_test, y_train, y_test ya están definidos</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># por el chunk de división de datos anterior.</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Para asegurar que X_train y y_train se combinen correctamente para statsmodels</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># statsmodels prefiere un solo DataFrame que contenga todas las variables</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es similar a cómo `lm` en R usa `data = train_data`</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Combinar X_train y y_train en un solo DataFrame para statsmodels</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>train_data_combined <span class="op">=</span> pd.concat([X_train, y_train], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir la fórmula del modelo (similar a R)</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># mpg ~ . significa "mpg en función de todas las demás variables en el DataFrame"</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Para statsmodels, es mejor listar explícitamente las columnas si X_train tiene muchas</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># O si quieres un subconjunto específico, lo especificas aquí.</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Aquí construimos la fórmula dinámicamente para incluir todas las variables de X_train</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>y_train<span class="sc">.</span>name<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(X_train.columns)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Entrenar el modelo de regresión lineal (OLS)</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># statsmodels.formula.api permite usar la sintaxis de fórmula similar a R</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>modelo_ols_py <span class="op">=</span> smf.ols(formula <span class="op">=</span> formula, data <span class="op">=</span> train_data_combined).fit()</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Revisar resumen del modelo (similar a summary() en R)</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Resumen del Modelo OLS en Python:"</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(modelo_ols_py.summary()) <span class="co"># .as_html() para una salida bonita en Quarto</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Resumen del Modelo OLS en Python:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.896
Model:                            OLS   Adj. R-squared:                  0.821
Method:                 Least Squares   F-statistic:                     12.00
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           3.06e-05
Time:                        15:17:58   Log-Likelihood:                -52.439
No. Observations:                  25   AIC:                             126.9
Df Residuals:                      14   BIC:                             140.3
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept    -19.2700     31.016     -0.621      0.544     -85.792      47.252
cyl            1.0972      1.593      0.689      0.502      -2.319       4.513
disp           0.0062      0.020      0.307      0.764      -0.037       0.049
hp            -0.0053      0.025     -0.212      0.835      -0.059       0.048
drat           1.8203      2.101      0.866      0.401      -2.687       6.327
wt            -3.6682      2.289     -1.603      0.131      -8.577       1.241
qsec           2.1398      1.379      1.552      0.143      -0.817       5.097
vs             0.8514      4.586      0.186      0.855      -8.985      10.688
am             5.8806      3.918      1.501      0.156      -2.523      14.285
gear          -1.0928      2.698     -0.405      0.692      -6.879       4.694
carb           0.0325      0.975      0.033      0.974      -2.060       2.125
==============================================================================
Omnibus:                        2.342   Durbin-Watson:                   1.335
Prob(Omnibus):                  0.310   Jarque-Bera (JB):                1.544
Skew:                           0.374   Prob(JB):                        0.462
Kurtosis:                       2.040   Cond. No.                     1.94e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.94e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<p>Como resultado se da una visión general de qué tan bien el modelo se ajusta a los datos:</p>
<ul>
<li><strong><code>R-squared: 0.896</code></strong>: También conocido como <strong>coeficiente de determinación</strong>. Esto significa que el 89.6% de la variabilidad en <code>mpg</code> puede ser explicada por las variables predictoras en tu modelo. ¡Este es un valor bastante alto, lo que sugiere que tu modelo explica una gran parte de la variación en <code>mpg</code>!
<ul>
<li><strong><code>Adj. R-squared: 0.821</code></strong>: El <strong>R-cuadrado ajustado</strong> es una versión del R-cuadrado que penaliza el modelo por cada variable predictora adicional. Es más útil cuando comparas modelos con diferentes números de predictores. Un valor de 0.821 sigue siendo muy bueno y sugiere que el alto R-cuadrado no es solo por añadir muchas variables sin valor.</li>
</ul></li>
<li><strong><code>F-statistic: 12.00</code></strong>: La <strong>Estadística F</strong> evalúa la significancia global del modelo. Prueba la hipótesis nula de que todos los coeficientes de las variables predictoras son cero (es decir, que ninguna de tus variables predictoras tiene un efecto significativo sobre <code>mpg</code>).</li>
<li><strong><code>Prob (F-statistic): 3.06e-05</code></strong>: Este es el <strong>p-valor asociado a la Estadística F</strong>. Un valor tan pequeño (3.06e-05, que es 0.0000306) es mucho menor que el nivel de significancia común (0.05). Esto significa que <strong>el modelo en su conjunto es estadísticamente significativo</strong>, y al menos una de tus variables predictoras tiene un efecto significativo sobre <code>mpg</code>.</li>
</ul>
<p><strong>Estadísticos</strong></p>
<p>Estas métricas ayudan a evaluar si el modelo cumple con los supuestos de la regresión lineal:</p>
<ul>
<li><strong><code>Omnibus</code>, <code>Prob(Omnibus)</code>, <code>Jarque-Bera (JB)</code>, <code>Prob(JB)</code>, <code>Skew</code>, <code>Kurtosis</code></strong>: Estas son pruebas de <strong>normalidad de los residuos</strong>.</li>
<li><code>Prob(Omnibus): 0.310</code> y <code>Prob(JB): 0.462</code> (ambos &gt; 0.05) sugieren que <strong>los residuos son aproximadamente normales</strong>, lo cual es bueno.</li>
<li><code>Skew</code> (Asimetría) y <code>Kurtosis</code> (Curtosis) describen la forma de la distribución de los residuos. Valores cercanos a 0 para <code>Skew</code> y cercanos a 3 para <code>Kurtosis</code> (o 0 para <code>Excess Kurtosis</code>, que es lo que se interpreta a menudo) indican normalidad. Tus valores son razonables.</li>
<li><strong><code>Durbin-Watson: 1.335</code></strong>: Esta prueba detecta la <strong>autocorrelación en los residuos</strong>.
<ul>
<li>Un valor cercano a 2 indica poca o ninguna autocorrelación.</li>
<li>Valores muy por debajo de 2 (como 1.335) pueden sugerir cierta autocorrelación positiva (residuos adyacentes están correlacionados), lo cual es una violación de los supuestos y podría afectar la validez de tus errores estándar y p-valores.</li>
</ul></li>
<li><strong>`<code>Cond. No.: 1.94e+04</code></strong>: El <strong>Número de Condición</strong>.
<ul>
<li>Este valor es una medida de <strong>multicolinealidad</strong>.</li>
<li>Un valor alto (generalmente &gt; 1000, y este es de 19400) <strong>indica una fuerte multicolinealidad</strong> entre las variables predictoras. Esto confirma la sospecha de la tabla de coeficientes: tus variables están altamente correlacionadas entre sí, lo que dificulta al modelo discernir el efecto único de cada una. Esta es la razón más probable por la que el modelo es significativo en general, pero los predictores individuales no lo son.</li>
</ul></li>
</ul>
<p><strong>¿Por qué los resultados de R y Python son diferentes a pesar de usar la misma lógica?</strong></p>
<p>La razón principal por la que obtienes resultados ligeramente diferentes en R y Python para los coeficientes, errores estándar y p-valores (aunque las métricas generales como R-cuadrado y F-estadístico son muy similares) es debido a la <strong>naturaleza aleatoria de la división de los datos en entrenamiento y prueba</strong>.</p>
<section id="observaciones-generales" class="level4">
<h4 class="anchored" data-anchor-id="observaciones-generales">📌 <strong>Observaciones generales</strong></h4>
<ul>
<li><p>El modelo tiene un <strong>muy buen R²</strong> (89.6%) ⇒ explica bien la variabilidad en <code>mpg</code>.</p></li>
<li><p><strong>El modelo completo es estadísticamente significativo</strong>, pero <strong>ninguna variable individual lo es</strong>, lo que probablemente se deba a <strong>multicolinealidad</strong>.</p></li>
<li><p>Considera usar:</p>
<ul>
<li><strong>Análisis de VIF</strong> (Variance Inflation Factor) para detectar multicolinealidad.</li>
<li><strong>Reducción de dimensionalidad</strong> (PCA, selección de variables).</li>
<li><strong>Regularización</strong> (Ridge/Lasso) para mejorar la estabilidad del modelo.</li>
</ul></li>
</ul>
<div id="cell-scatter-plots-faceted" class="cell" data-fig-height="8" data-fig-width="10" data-message="false" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine <span class="im">import</span> (</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    ggplot, aes, geom_point, geom_smooth, facet_wrap,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    theme_bw, theme, element_text, labs</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar datos de ejemplo si no tienes mtcars_df</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine.data <span class="im">import</span> mtcars</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>mtcars_df <span class="op">=</span> mtcars.copy()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Preparación de los datos</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>tabla_py <span class="op">=</span> (</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>            mtcars_df</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>           .drop(columns <span class="op">=</span> [<span class="st">'name'</span>], errors <span class="op">=</span> <span class="st">'ignore'</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>           .melt(id_vars <span class="op">=</span> [<span class="st">"mpg"</span>], var_name <span class="op">=</span> <span class="st">"variable"</span>, value_name <span class="op">=</span> <span class="st">"value"</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Crear el gráfico con plotnine</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> (</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    ggplot(tabla_py, aes(y <span class="op">=</span> <span class="st">"mpg"</span>, x <span class="op">=</span> <span class="st">"value"</span>, color <span class="op">=</span> <span class="st">"variable"</span>))</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> geom_point()</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> geom_smooth(method<span class="op">=</span><span class="st">"lm"</span>, se<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> theme_bw()</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> theme(</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        plot_title<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">22</span>),</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        plot_subtitle<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">18</span>),</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>        plot_caption<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">11</span>),</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>        axis_text<span class="op">=</span>element_text(),</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        axis_text_x <span class="op">=</span> element_text(angle <span class="op">=</span> <span class="dv">45</span>),</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        axis_title<span class="op">=</span>element_text(size <span class="op">=</span> <span class="dv">15</span>),</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        legend_position<span class="op">=</span><span class="st">"none"</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> facet_wrap(<span class="st">"~variable"</span>, scales<span class="op">=</span><span class="st">"free"</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> labs(</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>        title<span class="op">=</span><span class="st">"Diagramas de dispersión"</span>,</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">""</span>,</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">""</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar el gráfico</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_01_OLSR_py_files/figure-html/scatter-plots-faceted-output-1.png" id="scatter-plots-faceted" width="672" height="480" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="selección-de-variables" class="level2">
<h2 class="anchored" data-anchor-id="selección-de-variables">Selección de variables</h2>
<section id="criterio-de-información-de-akaike" class="level3">
<h3 class="anchored" data-anchor-id="criterio-de-información-de-akaike">Criterio de Información de Akaike</h3>
<p>El Criterio de Información de Akaike (AIC, por sus siglas en inglés, Akaike Information Criterion) es una medida de la bondad de ajuste de un modelo estadístico que penaliza la complejidad del modelo. Su objetivo es seleccionar el modelo que mejor se ajusta a los datos con la menor cantidad de parámetros, evitando así el sobreajuste (overfitting).</p>
<p>La fórmula general para calcular el AIC es:</p>
<p><span class="math display">\[AIC = 2k - 2\ln(L)\]</span></p>
<p>Donde:<br>
* <span class="math inline">\(k\)</span> es el número de parámetros del modelo. En un modelo de regresión, esto incluye el intercepto y los coeficientes de las variables predictoras, más la varianza del error si se estima (en modelos de mínimos cuadrados ordinarios, esto es a menudo el caso, por lo que <span class="math inline">\(k\)</span> a veces se cuenta como el número de coeficientes + 1 para la varianza del error, o simplemente el número de coeficientes si la varianza del error se considera implícita en la función de verosimilitud).<br>
* <span class="math inline">\(\ln(L)\)</span> es el logaritmo natural del valor máximo de la función de verosimilitud (log-likelihood) del modelo. La función de verosimilitud mide qué tan bien el modelo reproduce los datos observados.</p>
<section id="cómo-se-interpreta" class="level4">
<h4 class="anchored" data-anchor-id="cómo-se-interpreta">Cómo se interpreta:</h4>
<ul>
<li><strong>Valores más bajos de AIC indican un mejor modelo.</strong> El AIC busca un equilibrio entre la bondad de ajuste del modelo a los datos (representada por <span class="math inline">\(\ln(L)\)</span>) y la complejidad del modelo (representada por <span class="math inline">\(2k\)</span>).<br>
</li>
<li>El término <span class="math inline">\(2k\)</span> es una <strong>penalización por la complejidad</strong>. Cada parámetro adicional en el modelo aumenta el valor de AIC, lo que desincentiva la inclusión de variables innecesarias que podrían sobreajustar los datos.</li>
</ul>
</section>
<section id="para-modelos-de-regresión-por-mínimos-cuadrados-ordinarios-ols" class="level4">
<h4 class="anchored" data-anchor-id="para-modelos-de-regresión-por-mínimos-cuadrados-ordinarios-ols">Para modelos de Regresión por Mínimos Cuadrados Ordinarios (OLS):</h4>
<p>Aunque la fórmula general del AIC es la que se mencionó, para modelos de OLS con residuos normalmente distribuidos, la función de log-verosimilitud tiene una forma específica, lo que permite reescribir el AIC de una manera más práctica.</p>
<p>Para un modelo de regresión lineal con <span class="math inline">\(n\)</span> observaciones y <span class="math inline">\(k\)</span> parámetros (incluyendo el intercepto), y asumiendo errores normales con varianza constante, el AIC se puede calcular como:</p>
<p><span class="math display">\[AIC = n \cdot \ln\left(\frac{RSS}{n}\right) + 2k\]</span></p>
<p>Donde:<br>
* <span class="math inline">\(n\)</span> es el número de observaciones (tamaño de la muestra).<br>
* <span class="math inline">\(RSS\)</span> es la Suma de Cuadrados de los Residuos (Residual Sum of Squares), que es la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo.<br>
* <span class="math inline">\(k\)</span> es el número de parámetros del modelo (coeficientes de las variables independientes + intercepto).</p>
<p><strong>Es importante recordar:</strong></p>
<ul>
<li>El AIC no es una prueba de hipótesis en el sentido tradicional; no te dice si un modelo es “bueno” o “malo” en un sentido absoluto.<br>
</li>
<li>Es una herramienta para la <strong>selección de modelos entre un conjunto de modelos candidatos</strong>. Siempre se compara el AIC de diferentes modelos ajustados a los <strong>mismos datos</strong>. El modelo con el AIC más bajo es el preferido.<br>
</li>
<li>Cuando la muestra es pequeña, a veces se prefiere el <strong>AIC corregido (AICc)</strong>, que añade una penalización adicional por el tamaño de la muestra:<br>
<span class="math display">\[AICc = AIC + \frac{2k(k+1)}{n-k-1}\]</span></li>
</ul>
<p>A medida que <span class="math inline">\(n\)</span> (tamaño de la muestra) es grande, el término de corrección se vuelve insignificante y el AICc converge al AIC.</p>
<p>Se realiza una selección automática de variables para un modelo de regresión lineal, utilizando el <strong>criterio AIC (Criterio de Información de Akaike</strong>)</p>
<p><strong>Implementación de Selección por Pasos (Stepwise) con AIC en Python</strong></p>
<p>Dado que <code>statsmodels</code> no tiene un <code>stepAIC</code> incorporado que funcione exactamente como en R con <code>direction="both"</code>, una forma común de lograr esto en Python es implementar la lógica de forma manual o usar una función auxiliar que la simule.</p>
<div id="stepwise-aic" class="cell" data-message="false" data-results="as-is" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Aunque no lo vamos a importar directamente aquí, el concepto de AIC</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># está implícito en los resultados de summary() de statsmodels</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Asumiendo que X_train, y_train y train_data_combined</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># (el DataFrame combinado para statsmodels) ya están definidos</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># desde los chunks anteriores.</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Y que modelo_ols_py ya fue ajustado.</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stepwise_selection_aic(data, target_variable, initial_features<span class="op">=</span><span class="va">None</span>, verbose<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Realiza una selección de características por pasos (forward y backward)</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">    basada en el Criterio de Información de Akaike (AIC).</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">        data (pd.DataFrame): El DataFrame de entrenamiento combinado (X y y).</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">        target_variable (str): El nombre de la columna de la variable dependiente.</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">        initial_features (list): Lista opcional de características para empezar.</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">                                 Si es None, empieza con un modelo nulo o con todas.</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose (bool): Si es True, imprime los pasos del proceso.</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co">        statsmodels.regression.linear_model.RegressionResultsWrapper: El modelo OLS final.</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    remaining_features <span class="op">=</span> <span class="bu">list</span>(data.drop(columns<span class="op">=</span>[target_variable]).columns)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    selected_features <span class="op">=</span> [] <span class="cf">if</span> initial_features <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> initial_features</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    current_score, best_new_score <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>), <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    best_model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    iteration <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Iniciando selección de modelo por pasos con AIC (dirección 'both')..."</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        iteration <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        model_changed <span class="op">=</span> <span class="va">False</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Iteración </span><span class="sc">{</span>iteration<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Características seleccionadas actualmente: </span><span class="sc">{</span>selected_features<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Paso hacia adelante (Forward Selection) ---</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        aic_candidates_forward <span class="op">=</span> {}</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> remaining_features: <span class="co"># Solo si hay características restantes para añadir</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="st">"Considerando añadir características:"</span>)</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> feature <span class="kw">in</span> remaining_features:</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>                temp_features <span class="op">=</span> selected_features <span class="op">+</span> [feature]</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="kw">not</span> temp_features: <span class="co"># Asegura que al menos haya un Intercept si no hay features</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ 1"</span> <span class="co"># Modelo solo con intercept</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(temp_features)</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>                    model <span class="op">=</span> smf.ols(formula<span class="op">=</span>formula, data<span class="op">=</span>data).fit()</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>                    aic_candidates_forward[feature] <span class="op">=</span> model.aic</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  Añadiendo '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': AIC = </span><span class="sc">{</span>model<span class="sc">.</span>aic<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  Error al probar '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Paso hacia atrás (Backward Elimination) ---</span></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>        aic_candidates_backward <span class="op">=</span> {}</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(selected_features) <span class="op">&gt;</span> <span class="dv">0</span>: <span class="co"># Solo si hay características para eliminar</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="st">"Considerando eliminar características:"</span>)</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> feature <span class="kw">in</span> selected_features:</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>                temp_features <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> selected_features <span class="cf">if</span> f <span class="op">!=</span> feature]</span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="kw">not</span> temp_features: <span class="co"># Si eliminamos todo y solo queda el intercept</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ 1"</span></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>                    formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(temp_features)</span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>                    model <span class="op">=</span> smf.ols(formula<span class="op">=</span>formula, data<span class="op">=</span>data).fit()</span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a>                    aic_candidates_backward[feature] <span class="op">=</span> model.aic</span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  Eliminando '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': AIC = </span><span class="sc">{</span>model<span class="sc">.</span>aic<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"  Error al probar quitar '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>        best_aic_this_step <span class="op">=</span> current_score</span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>        feature_to_add <span class="op">=</span> <span class="va">None</span></span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>        feature_to_remove <span class="op">=</span> <span class="va">None</span></span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>        action <span class="op">=</span> <span class="va">None</span> <span class="co"># 'add' o 'remove'</span></span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluar mejor movimiento: añadir o eliminar</span></span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mejor añadir</span></span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> aic_candidates_forward:</span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>            min_aic_add_feature <span class="op">=</span> <span class="bu">min</span>(aic_candidates_forward, key<span class="op">=</span>aic_candidates_forward.get)</span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a>            min_aic_add_value <span class="op">=</span> aic_candidates_forward[min_aic_add_feature]</span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> min_aic_add_value <span class="op">&lt;</span> best_aic_this_step:</span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>                best_aic_this_step <span class="op">=</span> min_aic_add_value</span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a>                feature_to_add <span class="op">=</span> min_aic_add_feature</span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a>                action <span class="op">=</span> <span class="st">'add'</span></span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mejor eliminar</span></span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> aic_candidates_backward:</span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>            min_aic_remove_feature <span class="op">=</span> <span class="bu">min</span>(aic_candidates_backward, key<span class="op">=</span>aic_candidates_backward.get)</span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a>            min_aic_remove_value <span class="op">=</span> aic_candidates_backward[min_aic_remove_feature]</span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Solo consideramos eliminar si esto mejora el AIC *actual* del modelo</span></span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a>            <span class="co"># y también si es mejor que añadir</span></span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> min_aic_remove_value <span class="op">&lt;</span> best_aic_this_step:</span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>                best_aic_this_step <span class="op">=</span> min_aic_remove_value</span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a>                feature_to_remove <span class="op">=</span> min_aic_remove_feature</span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a>                action <span class="op">=</span> <span class="st">'remove'</span></span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_aic_this_step <span class="op">&lt;</span> current_score:</span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a>            model_changed <span class="op">=</span> <span class="va">True</span></span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a>            current_score <span class="op">=</span> best_aic_this_step</span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> action <span class="op">==</span> <span class="st">'add'</span>:</span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a>                selected_features.append(feature_to_add)</span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a>                remaining_features.remove(feature_to_add)</span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"-&gt; Añadiendo: '</span><span class="sc">{</span>feature_to_add<span class="sc">}</span><span class="ss">'. Nuevo AIC: </span><span class="sc">{</span>current_score<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> action <span class="op">==</span> <span class="st">'remove'</span>:</span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a>                remaining_features.append(feature_to_remove)</span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a>                selected_features.remove(feature_to_remove)</span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"-&gt; Eliminando: '</span><span class="sc">{</span>feature_to_remove<span class="sc">}</span><span class="ss">'. Nuevo AIC: </span><span class="sc">{</span>current_score<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a>            <span class="co"># No hay mejoras en el AIC, detener el proceso</span></span>
<span id="cb11-121"><a href="#cb11-121" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">No se encontró una mejora en el AIC. Deteniendo la selección por pasos."</span>)</span>
<span id="cb11-122"><a href="#cb11-122" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ajustar el modelo final con las características seleccionadas</span></span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> selected_features:</span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a>        final_formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ 1"</span></span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a>        final_formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(selected_features)</span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a>    final_model <span class="op">=</span> smf.ols(formula<span class="op">=</span>final_formula, data<span class="op">=</span>data).fit()</span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> final_model</span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Aplicar la selección por pasos ---</span></span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a><span class="co"># train_data_combined es el DataFrame que contiene X_train y y_train</span></span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a><span class="co"># target_variable es el nombre de tu columna 'mpg'</span></span>
<span id="cb11-136"><a href="#cb11-136" aria-hidden="true" tabindex="-1"></a>modelo_step_py <span class="op">=</span> stepwise_selection_aic(</span>
<span id="cb11-137"><a href="#cb11-137" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>train_data_combined,</span>
<span id="cb11-138"><a href="#cb11-138" aria-hidden="true" tabindex="-1"></a>    target_variable<span class="op">=</span><span class="st">'mpg'</span>,</span>
<span id="cb11-139"><a href="#cb11-139" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-140"><a href="#cb11-140" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-141"><a href="#cb11-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-142"><a href="#cb11-142" aria-hidden="true" tabindex="-1"></a><span class="co"># Revisar resumen del modelo_step final</span></span>
<span id="cb11-143"><a href="#cb11-143" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Resumen del Modelo OLS Después de la Selección por Pasos (AIC) ---"</span>)</span>
<span id="cb11-144"><a href="#cb11-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(modelo_step_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Iniciando selección de modelo por pasos con AIC (dirección 'both')...

--- Iteración 1 ---
Características seleccionadas actualmente: []
Considerando añadir características:
  Añadiendo 'Unnamed: 0': AIC = 163.35
  Añadiendo 'cyl': AIC = 130.29
  Añadiendo 'disp': AIC = 134.87
  Añadiendo 'hp': AIC = 140.99
  Añadiendo 'drat': AIC = 148.30
  Añadiendo 'wt': AIC = 132.58
  Añadiendo 'qsec': AIC = 155.89
  Añadiendo 'vs': AIC = 146.77
  Añadiendo 'am': AIC = 153.23
  Añadiendo 'gear': AIC = 162.02
  Añadiendo 'carb': AIC = 156.09
-&gt; Añadiendo: 'cyl'. Nuevo AIC: 130.29

--- Iteración 2 ---
Características seleccionadas actualmente: ['cyl']
Considerando añadir características:
  Añadiendo 'Unnamed: 0': AIC = 130.29
  Añadiendo 'disp': AIC = 130.63
  Añadiendo 'hp': AIC = 130.68
  Añadiendo 'drat': AIC = 130.98
  Añadiendo 'wt': AIC = 124.37
  Añadiendo 'qsec': AIC = 132.24
  Añadiendo 'vs': AIC = 132.09
  Añadiendo 'am': AIC = 129.94
  Añadiendo 'gear': AIC = 132.13
  Añadiendo 'carb': AIC = 130.25
Considerando eliminar características:
  Eliminando 'cyl': AIC = 163.35
-&gt; Añadiendo: 'wt'. Nuevo AIC: 124.37

--- Iteración 3 ---
Características seleccionadas actualmente: ['cyl', 'wt']
Considerando añadir características:
  Añadiendo 'Unnamed: 0': AIC = 124.37
  Añadiendo 'disp': AIC = 125.80
  Añadiendo 'hp': AIC = 124.39
  Añadiendo 'drat': AIC = 126.34
  Añadiendo 'qsec': AIC = 123.27
  Añadiendo 'vs': AIC = 126.30
  Añadiendo 'am': AIC = 126.17
  Añadiendo 'gear': AIC = 125.91
  Añadiendo 'carb': AIC = 123.88
Considerando eliminar características:
  Eliminando 'cyl': AIC = 132.58
  Eliminando 'wt': AIC = 130.29
-&gt; Añadiendo: 'qsec'. Nuevo AIC: 123.27

--- Iteración 4 ---
Características seleccionadas actualmente: ['cyl', 'wt', 'qsec']
Considerando añadir características:
  Añadiendo 'Unnamed: 0': AIC = 123.27
  Añadiendo 'disp': AIC = 124.67
  Añadiendo 'hp': AIC = 125.20
  Añadiendo 'drat': AIC = 123.52
  Añadiendo 'vs': AIC = 124.71
  Añadiendo 'am': AIC = 117.58
  Añadiendo 'gear': AIC = 124.46
  Añadiendo 'carb': AIC = 125.13
Considerando eliminar características:
  Eliminando 'cyl': AIC = 122.40
  Eliminando 'wt': AIC = 132.24
  Eliminando 'qsec': AIC = 124.37
-&gt; Añadiendo: 'am'. Nuevo AIC: 117.58

--- Iteración 5 ---
Características seleccionadas actualmente: ['cyl', 'wt', 'qsec', 'am']
Considerando añadir características:
  Añadiendo 'Unnamed: 0': AIC = 117.58
  Añadiendo 'disp': AIC = 118.87
  Añadiendo 'hp': AIC = 119.53
  Añadiendo 'drat': AIC = 118.30
  Añadiendo 'vs': AIC = 119.55
  Añadiendo 'gear': AIC = 119.19
  Añadiendo 'carb': AIC = 119.10
Considerando eliminar características:
  Eliminando 'cyl': AIC = 116.52
  Eliminando 'wt': AIC = 129.24
  Eliminando 'qsec': AIC = 126.17
  Eliminando 'am': AIC = 123.27
-&gt; Eliminando: 'cyl'. Nuevo AIC: 116.52

--- Iteración 6 ---
Características seleccionadas actualmente: ['wt', 'qsec', 'am']
Considerando añadir características:
  Añadiendo 'Unnamed: 0': AIC = 116.52
  Añadiendo 'disp': AIC = 117.13
  Añadiendo 'hp': AIC = 118.47
  Añadiendo 'drat': AIC = 118.16
  Añadiendo 'vs': AIC = 118.39
  Añadiendo 'gear': AIC = 117.80
  Añadiendo 'carb': AIC = 117.53
  Añadiendo 'cyl': AIC = 117.58
Considerando eliminar características:
  Eliminando 'wt': AIC = 130.13
  Eliminando 'qsec': AIC = 134.30
  Eliminando 'am': AIC = 122.40

No se encontró una mejora en el AIC. Deteniendo la selección por pasos.

--- Resumen del Modelo OLS Después de la Selección por Pasos (AIC) ---
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.879
Model:                            OLS   Adj. R-squared:                  0.862
Method:                 Least Squares   F-statistic:                     50.92
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           8.26e-10
Time:                        15:18:00   Log-Likelihood:                -54.262
No. Observations:                  25   AIC:                             116.5
Df Residuals:                      21   BIC:                             121.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -3.0270      8.017     -0.378      0.710     -19.700      13.646
wt            -3.1064      0.728     -4.267      0.000      -4.620      -1.592
qsec           1.7715      0.352      5.033      0.000       1.039       2.504
am             3.9631      1.421      2.788      0.011       1.007       6.919
==============================================================================
Omnibus:                        1.036   Durbin-Watson:                   1.169
Prob(Omnibus):                  0.596   Jarque-Bera (JB):                1.008
Skew:                           0.368   Prob(JB):                        0.604
Kurtosis:                       2.347   Cond. No.                         314.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<p>El procedimiento va eliminando o agregando variables al modelo original para reducir el <strong>AIC (Criterio de Información de Akaike)</strong>. El objetivo es encontrar un modelo más <strong>parsimonioso</strong> (simple) con <strong>buena capacidad predictiva</strong>.</p>
<ul>
<li><p>El proceso empieza con un modelo completo:<br>
<code>mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb</code> y un AIC inicial, por ejemplo: <code>AIC = 57.77</code>.</p></li>
<li><p>Luego evalúa qué pasa si <strong>quita</strong> una variable (<code>- vs</code>, <code>- cyl</code>, etc.).</p></li>
<li><p>Si al eliminar una variable el AIC <strong>baja</strong>, se acepta ese cambio.<br>
Ejemplo:<br>
<code>- vs    1    2.1293  102.57  56.353</code><br>
Significa que si quitas la variable <code>vs</code>, el AIC baja de 57.77 a 56.35 → ¡mejor!</p>
<ul>
<li>Se acepta esa modificación y se repite el procedimiento, ahora con el nuevo modelo.</li>
</ul></li>
<li><p>También puede intentar <strong>agregar</strong> variables previamente eliminadas (<code>+ vs</code>, <code>+ hp</code>, etc.) si esto mejora el AIC.</p></li>
<li><p>Cuando <strong>ya no puede bajar más el AIC</strong> quitando o agregando variables. El modelo final es el que <strong>tiene el AIC más bajo</strong> alcanzado durante el proceso.</p></li>
</ul>
</section>
</section>
<section id="interpretación-final" class="level3">
<h3 class="anchored" data-anchor-id="interpretación-final">Interpretación Final</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 43%">
<col style="width: 21%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Aspecto</th>
<th>Modelo Completo</th>
<th>Modelo por AIC (reducido)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>R² ajustado</strong></td>
<td>0.821</td>
<td>0.862 ✅</td>
</tr>
<tr class="even">
<td><strong>AIC</strong></td>
<td>126.9</td>
<td><strong>116.5 ✅</strong></td>
</tr>
<tr class="odd">
<td><strong>Coeficientes significativos</strong></td>
<td>Ninguno</td>
<td>Todos ✅</td>
</tr>
<tr class="even">
<td><strong>Multicolinealidad</strong></td>
<td>Alta ⚠️</td>
<td>Baja ✅</td>
</tr>
<tr class="odd">
<td><strong>Interpretabilidad</strong></td>
<td>Difusa</td>
<td>Clara ✅</td>
</tr>
</tbody>
</table>
<p><strong>Conclusión del modelo reducido</strong>:</p>
<ul>
<li>Todas las variables son estadísticamente significativas.</li>
<li>El modelo es más simple (3 variables vs.&nbsp;10).</li>
<li>El AIC bajó significativamente ⇒ mejora en calidad del modelo.</li>
<li>La interpretación es mucho más clara y robusta.</li>
</ul>
</section>
<section id="forward-or-backward-stepwise" class="level3">
<h3 class="anchored" data-anchor-id="forward-or-backward-stepwise">Forward or backward stepwise</h3>
<p>Los modelos “forward” (hacia adelante) y “backward” (hacia atrás) son dos enfoques comunes dentro de la <strong>regresión stepwise (paso a paso)</strong>, un método de selección automática de variables para construir modelos de regresión. El objetivo de la regresión stepwise es encontrar un subconjunto óptimo de variables predictoras que expliquen la mayor parte de la varianza en la variable dependiente con la menor complejidad posible, evitando el sobreajuste y mejorando la interpretabilidad del modelo.</p>
<p>Ambos métodos operan de manera iterativa, agregando o eliminando variables basándose en un criterio estadístico (como el p-valor, AIC, BIC, etc.).</p>
<section id="forward-selection-selección-hacia-adelante" class="level4">
<h4 class="anchored" data-anchor-id="forward-selection-selección-hacia-adelante"><strong>Forward Selection</strong> (Selección Hacia Adelante)</h4>
<p>La selección hacia adelante comienza con un modelo “nulo”, es decir, un modelo que no contiene ninguna variable predictora (solo el intercepto). Luego, en cada paso, evalúa todas las variables predictoras no incluidas en el modelo y agrega aquella que, al ser incluida, produce la mejora más significativa en el ajuste del modelo. Este proceso continúa hasta que ninguna de las variables restantes cumple con el criterio de entrada preestablecido (por ejemplo, su p-valor es mayor que un umbral determinado).</p>
</section>
<section id="backward-elimination-eliminación-hacia-atrás" class="level4">
<h4 class="anchored" data-anchor-id="backward-elimination-eliminación-hacia-atrás"><strong>Backward Elimination</strong> (Eliminación Hacia Atrás)</h4>
<p>La eliminación hacia atrás comienza con un modelo “completo”, es decir, un modelo que incluye todas las variables predictoras candidatas. Luego, en cada paso, evalúa la contribución de cada variable predictora en el modelo y elimina aquella que, al ser retirada, tiene el menor impacto negativo en el ajuste del modelo (o la que es menos significativa, por ejemplo, la que tiene el p-valor más alto). Este proceso continúa hasta que todas las variables restantes en el modelo cumplen con un criterio de permanencia preestablecido (por ejemplo, su p-valor es menor que un umbral determinado).</p>
</section>
<section id="consideraciones-generales-sobre-la-regresión-stepwise" class="level4">
<h4 class="anchored" data-anchor-id="consideraciones-generales-sobre-la-regresión-stepwise">Consideraciones Generales sobre la Regresión Stepwise</h4>
<p>Es importante mencionar que, aunque los métodos forward y backward son populares por su automatización, también tienen sus <strong>críticas y desventajas</strong>:</p>
<ul>
<li><strong>Sobreajuste (Overfitting):</strong> Los modelos resultantes pueden ajustarse muy bien a los datos de entrenamiento, pero no generalizar bien a nuevos datos. Esto se debe a que el proceso de selección de variables se basa en los datos observados, lo que puede llevar a incluir variables que parecen importantes por puro azar en esa muestra particular.</li>
<li><strong>P-valores y Coeficientes Sesgados:</strong> Los p-valores y los coeficientes de regresión obtenidos de un modelo stepwise pueden ser sesgados. Los p-valores tienden a ser más pequeños de lo que realmente son, lo que lleva a una falsa confianza en la significancia de las variables.</li>
<li><strong>No considera la teoría:</strong> El proceso es puramente estadístico y no incorpora el conocimiento del dominio o la teoría subyacente sobre las relaciones entre las variables. Un modelo estadísticamente “óptimo” podría carecer de sentido teórico o práctico.</li>
<li><strong>Dependencia del orden:</strong> La selección de variables puede ser sensible al orden en que se añaden o eliminan, especialmente en la selección hacia adelante.</li>
</ul>
<p><strong>Selección de Subconjuntos de Variables con <code>statsmodels</code> en Python</strong></p>
<p>En Python, no hay una función directa que replique <code>regsubsets</code> con todos sus métodos (exhaustiva, forward, backward, etc.) en una sola llamada como en R.</p>
<p>Explicación de la Función Genérica <code>regsubsets_exhaustive</code>:</p>
<ol type="1">
<li><strong>Parámetros de Entrada</strong>:</li>
</ol>
<ul>
<li><code>X_train_df</code>: El DataFrame de variables predictoras de entrenamiento.</li>
<li><code>y_train_series</code>: La Serie de la variable dependiente de entrenamiento. <strong>Es crucial que <code>y_train_series</code> tenga un <code>.name</code> (e.g., <code>'mpg'</code>) asignado</strong>, ya que <code>statsmodels</code> lo usa para construir la fórmula. Si <code>y_train</code> no tiene un nombre, se puede asignár (<code>y_train.name = 'nombre_columna'</code>).</li>
<li><code>nvmax</code>: El número máximo de variables a considerar.</li>
<li><code>id_column</code>: Un nuevo parámetro para especificar el nombre de cualquier columna que sea un identificador (como <code>'name'</code> o <code>'Unnamed: 0'</code>) y que <strong>no debe usarse como predictor</strong>.</li>
</ul>
<ol start="2" type="1">
<li><p><strong><code>train_data_combined</code></strong>: Dentro de la función, combinamos <code>X_train_df</code> y <code>y_train_series</code> en un solo DataFrame. Esto es lo que <code>statsmodels</code> espera para la función <code>smf.ols</code> cuando se usa la sintaxis de fórmula.</p></li>
<li><p><strong>Exclusión de <code>id_column</code></strong>: La lista <code>all_predictors</code> ahora filtra la <code>id_column</code> proporcionada. Esto te da control sobre qué columnas del <code>X_train_df</code> son realmente predictores.</p></li>
<li><p><strong>Almacenamiento de Objetos de Modelo</strong>: Añadimos un diccionario <code>model_objects</code> que guarda cada objeto de modelo ajustado (<code>model_objects[formula] = model</code>). Esto es muy útil porque si luego se decide que un modelo específico (por ejemplo, el mejor AIC con 5 características) es el que se quiere, se puede recuperar el diccionario y acceder a su <code>.summary()</code>, <code>.predict()</code>, etc.</p></li>
<li><p><strong>Retorno de Valores</strong>: La función devuelve un diccionario <code>best_models</code> (que contiene DataFrames para los mejores modelos por R-cuadrado ajustado, AIC y BIC) y el diccionario <code>all_model_objects</code>.</p></li>
</ol>
<div id="regsubsets-generic-function" class="cell" data-message="false" data-results="as-is" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Definición de la función genérica para regsubsets (exhaustive) ---</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> regsubsets_exhaustive(X_train_df, y_train_series, nvmax<span class="op">=</span><span class="va">None</span>, id_column<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Realiza una búsqueda exhaustiva de los mejores subconjuntos de variables</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">    para un modelo de regresión lineal, similar a regsubsets en R.</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">        X_train_df (pd.DataFrame): DataFrame con las variables predictoras del conjunto de entrenamiento.</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">        y_train_series (pd.Series): Serie con la variable dependiente del conjunto de entrenamiento.</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">        nvmax (int, optional): Número máximo de variables a considerar en los subconjuntos.</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">                               Si es None, se usa el número total de predictores.</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">        id_column (str, optional): Nombre de una columna en X_train_df que es un identificador</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">                                   (como 'name' o 'Unnamed: 0') y debe excluirse de los predictores.</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: Un DataFrame con los mejores modelos para cada número de características,</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">                      ordenados por R-cuadrado ajustado, AIC y BIC.</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">        dict: Un diccionario de los objetos de modelo ajustados para referencia,</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">              con la fórmula como clave.</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine X_train and y_train into a single DataFrame for statsmodels</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    train_data_combined <span class="op">=</span> pd.concat([X_train_df, y_train_series], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure y_train_series.name is not None</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    target_variable_name <span class="op">=</span> y_train_series.name</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> target_variable_name <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"The 'y_train_series' Series must have a name assigned (e.g., y_train.name = 'mpg')"</span>)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define available predictor variables, excluding the ID column if provided</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    all_predictors <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> X_train_df.columns <span class="cf">if</span> col <span class="op">!=</span> id_column]</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Limit nvmax if it's greater than the actual number of predictors</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> nvmax <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        nvmax_final <span class="op">=</span> <span class="bu">len</span>(all_predictors)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>        nvmax_final <span class="op">=</span> <span class="bu">min</span>(nvmax, <span class="bu">len</span>(all_predictors))</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    model_objects <span class="op">=</span> {}</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Starting exhaustive subset search up to </span><span class="sc">{</span>nvmax_final<span class="sc">}</span><span class="ss"> variables..."</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, nvmax_final <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> subset_features_tuple <span class="kw">in</span> itertools.combinations(all_predictors, k):</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>            subset_features <span class="op">=</span> <span class="bu">list</span>(subset_features_tuple)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> subset_features:</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>                formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable_name<span class="sc">}</span><span class="ss"> ~ 1"</span></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>                formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>target_variable_name<span class="sc">}</span><span class="ss"> ~ "</span> <span class="op">+</span> <span class="st">" + "</span>.join(subset_features)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>                model <span class="op">=</span> smf.ols(formula<span class="op">=</span>formula, data<span class="op">=</span>train_data_combined).fit()</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>                results.append({</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'n_features'</span>: k,</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'features'</span>: <span class="st">" + "</span>.join(subset_features),</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'adj_r_squared'</span>: model.rsquared_adj,</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'aic'</span>: model.aic,</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'bic'</span>: model.bic,</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'formula'</span>: formula</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>                model_objects[formula] <span class="op">=</span> model</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>                <span class="co"># We'll just print a warning for failed models, not a full debug trace</span></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Warning: Error fitting model with formula '</span><span class="sc">{</span>formula<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>    results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> results_df.empty:</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"No valid models could be fitted."</span>)</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pd.DataFrame(), {}</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>    best_models <span class="op">=</span> {}</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> metric <span class="kw">in</span> [<span class="st">'adj_r_squared'</span>, <span class="st">'aic'</span>, <span class="st">'bic'</span>]:</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> metric <span class="op">==</span> <span class="st">'adj_r_squared'</span>:</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> results_df.groupby(<span class="st">'n_features'</span>)[metric].idxmax()</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> results_df.groupby(<span class="st">'n_features'</span>)[metric].idxmin()</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> idx.empty:</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>            best_models[metric] <span class="op">=</span> results_df.loc[idx].set_index(<span class="st">'n_features'</span>)</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>            best_models[metric] <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>results_df.columns).set_index(<span class="st">'n_features'</span>)</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_models, model_objects</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="77372a1f" class="cell" data-message="false" data-results="as-is" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This line is crucial and should be present in your actual script</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># to ensure y_train has a name.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> y_train.name <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    y_train.name <span class="op">=</span> <span class="st">'mpg'</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Running exhaustive subset selection ---"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>best_models_results, all_model_objects <span class="op">=</span> regsubsets_exhaustive(</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>                                                                X_train_df<span class="op">=</span>X_train,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>                                                                y_train_series<span class="op">=</span>y_train,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                                                                nvmax<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>                                                                id_column<span class="op">=</span><span class="st">'Unnamed: 0'</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Displaying only the final summary ---</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Summary of the best global model by AIC ---"</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> best_models_results[<span class="st">'aic'</span>].empty:</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the row with the globally lowest AIC across all feature counts</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We combine all results and then find the minimum AIC</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    all_results_df_for_global <span class="op">=</span> pd.concat([best_models_results[<span class="st">'aic'</span>], </span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>                                           best_models_results[<span class="st">'bic'</span>], </span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                                           best_models_results[<span class="st">'adj_r_squared'</span>]]).drop_duplicates(subset<span class="op">=</span>[<span class="st">'formula'</span>])</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'formula'</span> <span class="kw">in</span> all_results_df_for_global.columns <span class="kw">and</span> <span class="st">'aic'</span> <span class="kw">in</span> all_results_df_for_global.columns:</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        global_best_aic_row <span class="op">=</span> all_results_df_for_global.loc[all_results_df_for_global[<span class="st">'aic'</span>].idxmin()]</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        global_best_aic_formula <span class="op">=</span> global_best_aic_row[<span class="st">'formula'</span>]</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Model with lowest global AIC: </span><span class="sc">{</span>global_best_aic_formula<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Now, print the full statsmodels summary for this specific model</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> global_best_aic_formula <span class="kw">in</span> all_model_objects:</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(all_model_objects[global_best_aic_formula].summary())</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Error: The object for the best global AIC model was not found in 'all_model_objects'."</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Error: 'formula' or 'aic' columns not found in combined results for global best model."</span>)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No valid models were found for subset selection. Cannot display global best model."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Running exhaustive subset selection ---
Starting exhaustive subset search up to 10 variables...

--- Summary of the best global model by AIC ---
Model with lowest global AIC: mpg ~ wt + qsec + am
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.879
Model:                            OLS   Adj. R-squared:                  0.862
Method:                 Least Squares   F-statistic:                     50.92
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           8.26e-10
Time:                        15:18:11   Log-Likelihood:                -54.262
No. Observations:                  25   AIC:                             116.5
Df Residuals:                      21   BIC:                             121.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -3.0270      8.017     -0.378      0.710     -19.700      13.646
wt            -3.1064      0.728     -4.267      0.000      -4.620      -1.592
qsec           1.7715      0.352      5.033      0.000       1.039       2.504
am             3.9631      1.421      2.788      0.011       1.007       6.919
==============================================================================
Omnibus:                        1.036   Durbin-Watson:                   1.169
Prob(Omnibus):                  0.596   Jarque-Bera (JB):                1.008
Skew:                           0.368   Prob(JB):                        0.604
Kurtosis:                       2.347   Cond. No.                         314.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<p><code>Selection Algorithm: exhaustive</code> <strong>: Esto es crucial. Significa que el algoritmo probó todas las combinaciones posibles</strong> de variables para cada tamaño de subconjunto hasta <code>nvmax = 10</code> y seleccionó el mejor para cada tamaño. Esto asegura que, para cada número de variables (1, 2, …, 10), el modelo presentado es el óptimo según el criterio interno de <code>regsubsets_exhaustive</code> (generalmente <code>AIC</code>, <span class="math inline">\(R^2\)</span> ajustado, BIC a menos que se especifique otro en la función).</p>
<div id="495b5841" class="cell" data-message="false" data-results="as-is" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">### Extracción de los datos de R2 Ajustado</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">#La información ya está en `best_models_results['adj_r_squared']`. Para obtenerla en un formato de DataFrame con columnas explícitas para el número de variables y el R2 ajustado, simplemente hacemos:</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtener el DataFrame de los mejores R2 Ajustados por número de variables</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>adjr2_data_df <span class="op">=</span> best_models_results[<span class="st">'adj_r_squared'</span>].reset_index()</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Renombrar columnas para mayor claridad</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>adjr2_data_df.rename(columns<span class="op">=</span>{<span class="st">'n_features'</span>: <span class="st">'Numero_de_Variables'</span>, </span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>                              <span class="st">'adj_r_squared'</span>: <span class="st">'R2_Ajustado'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- DataFrame con R2 Ajustado por Número de Variables ---"</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(adjr2_data_df[[<span class="st">'Numero_de_Variables'</span>, <span class="st">'R2_Ajustado'</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> adjr2_data_df.empty:</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">5</span>)) <span class="co"># Tamaño de la figura más compacto</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Graficar línea y puntos</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    plt.plot(adjr2_data_df[<span class="st">'Numero_de_Variables'</span>], adjr2_data_df[<span class="st">'R2_Ajustado'</span>], </span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>             marker <span class="op">=</span> <span class="st">'o'</span>, linestyle <span class="op">=</span> <span class="st">'-'</span>, color <span class="op">=</span> <span class="st">'skyblue'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encontrar el punto de R2 ajustado máximo</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    max_adjr2_row <span class="op">=</span> adjr2_data_df.loc[adjr2_data_df[<span class="st">'R2_Ajustado'</span>].idxmax()]</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    best_num_vars <span class="op">=</span> <span class="bu">int</span>(max_adjr2_row[<span class="st">'Numero_de_Variables'</span>])</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    max_adjr2_value <span class="op">=</span> max_adjr2_row[<span class="st">'R2_Ajustado'</span>]</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resaltar el punto máximo</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    plt.plot(best_num_vars, max_adjr2_value, <span class="st">'ro'</span>, markersize <span class="op">=</span> <span class="dv">8</span>) <span class="co"># Punto rojo grande</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    plt.axvline(x <span class="op">=</span> best_num_vars, color <span class="op">=</span> <span class="st">'red'</span>, linestyle<span class="op">=</span> <span class="st">'--'</span>, linewidth <span class="op">=</span> <span class="dv">1</span>, alpha <span class="op">=</span> <span class="fl">0.7</span>) <span class="co"># Línea vertical</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Etiquetas y título</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"R2 Ajustado vs. Número de Variables"</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Número de Variables"</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"R2 Ajustado"</span>)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Asegurar que los ticks del eje X sean enteros y legibles</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">max</span>(adjr2_data_df[<span class="st">'Numero_de_Variables'</span>]) <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>, linestyle <span class="op">=</span> <span class="st">':'</span>, alpha <span class="op">=</span> <span class="fl">0.6</span>) <span class="co"># Cuadrícula ligera</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No hay datos para generar el gráfico de R2 Ajustado."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>--- DataFrame con R2 Ajustado por Número de Variables ---
 Numero_de_Variables  R2_Ajustado
                   1     0.743288
                   2     0.819335
                   3     0.861870
                   4     0.862840
                   5     0.860304
                   6     0.858462
                   7     0.851836
                   8     0.842908
                   9     0.832837
                  10     0.820912</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_01_OLSR_py_files/figure-html/cell-18-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>*## Evaluación del modelo</p>
<p>Ahora se va a trabajar con un <strong>modelo reducido (<code>modelo_step</code>)</strong>, es importante <strong>usar ese modelo</strong> para hacer predicciones en el conjunto de prueba. Además, como solo algunas variables quedaron en el modelo (<code>drat</code>, <code>wt</code>, <code>gear</code>, <code>carb</code>), el <code>test_data</code> debe contener esas columnas.</p>
<p><strong>Verificar qué variables necesita el modelo reducido</strong></p>
<div id="8004c67d" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>global_best_aic_row <span class="op">=</span> all_results_df_for_global.loc[all_results_df_for_global[<span class="st">'aic'</span>].idxmin()]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>global_best_aic_formula <span class="op">=</span> global_best_aic_row[<span class="st">'formula'</span>]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>global_best_aic_formula</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>'mpg ~ wt + qsec + am'</code></pre>
</div>
</div>
</section>
</section>
<section id="variance-inflation-factor-vif" class="level3">
<h3 class="anchored" data-anchor-id="variance-inflation-factor-vif">Variance Inflation Factor (<code>VIF</code>)</h3>
<p>El <strong>Factor de Inflación de la Varianza (VIF)</strong> es una herramienta estadística fundamental utilizada para <strong>detectar y cuantificar la multicolinealidad</strong> en modelos de regresión lineal múltiple.</p>
<p><strong>Problemas que causa la multicolinealidad:</strong></p>
<ul>
<li><strong>Coeficientes de regresión inestables y difíciles de interpretar:</strong> Cuando las variables predictoras están altamente correlacionadas, es difícil para el modelo determinar la contribución única de cada variable a la variable dependiente. Pequeños cambios en los datos pueden llevar a grandes cambios en los coeficientes estimados, haciendo que sean poco fiables.</li>
<li><strong>Errores estándar inflados:</strong> La multicolinealidad aumenta los errores estándar de los coeficientes de regresión, lo que a su vez disminuye los valores de las estadísticas t y aumenta los p-valores. Esto puede llevar a la conclusión errónea de que una variable no es estadísticamente significativa cuando en realidad sí lo es.</li>
<li><strong>Poder predictivo reducido:</strong> Aunque la multicolinealidad no necesariamente afecta la capacidad predictiva global del modelo (el <span class="math inline">\(R^2\)</span> ajustado puede seguir siendo alto), sí afecta la precisión de las estimaciones de los coeficientes individuales, lo que hace difícil comprender la relación real entre cada predictor y la variable de respuesta.</li>
</ul>
<p>El VIF mide <strong>cuánto se “infla” la varianza del coeficiente de regresión estimado de una variable predictora debido a su correlación con otras variables predictoras</strong> en el modelo.</p>
<p><strong>La fórmula del VIF para una variable</strong> <span class="math inline">\(X_j\)</span> es:</p>
<p><span class="math display">\[VIF_j = \frac{1}{1 - R_j^2}\]</span></p>
<p>Donde <span class="math inline">\(R_j^2\)</span> es el coeficiente de determinación (<span class="math inline">\(R^2\)</span>) de una regresión auxiliar en la que la variable <span class="math inline">\(X_j\)</span> se predice utilizando todas las demás variables independientes del modelo.</p>
<section id="cómo-se-interpreta-el-vif" class="level4">
<h4 class="anchored" data-anchor-id="cómo-se-interpreta-el-vif">¿Cómo se interpreta el VIF?</h4>
<ul>
<li><strong>VIF = 1:</strong> Indica que la variable predictora no está correlacionada con ninguna de las otras variables predictoras en el modelo. No hay multicolinealidad.</li>
<li><strong>VIF &gt; 1:</strong> Indica que existe algún grado de multicolinealidad. Cuanto mayor sea el valor del VIF, mayor es el grado de multicolinealidad.</li>
</ul>
<p><strong>Reglas generales para interpretar los valores de VIF (son reglas de “pulgar” y pueden variar ligeramente según el contexto y el campo de estudio):</strong></p>
<ul>
<li><strong>VIF ≤ 5:</strong> Generalmente se considera que no hay problemas graves de multicolinealidad.</li>
<li><strong>5 &lt; VIF ≤ 10:</strong> Puede indicar un nivel moderado a alto de multicolinealidad que podría justificar una investigación.</li>
<li><strong>VIF &gt; 10:</strong> A menudo se considera una indicación clara de multicolinealidad grave y problemática. Es un umbral comúnmente aceptado para señalar que una variable está fuertemente correlacionada con otras, lo que podría afectar la estabilidad y fiabilidad del modelo.</li>
</ul>
<p><strong>Regla práctica para interpretar VIF:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>VIF</th>
<th>Interpretación</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Sin colinealidad</td>
</tr>
<tr class="even">
<td>1–5</td>
<td>Colinealidad baja / aceptable</td>
</tr>
<tr class="odd">
<td>5–10</td>
<td>Colinealidad moderada a alta (requiere atención)</td>
</tr>
<tr class="even">
<td>&gt; 10</td>
<td>⚠️ <strong>Colinealidad severa</strong> (problema serio)</td>
</tr>
</tbody>
</table>
<div id="4ddddb13" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.outliers_influence <span class="im">import</span> variance_inflation_factor</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tools.tools <span class="im">import</span> add_constant <span class="co"># Necesario para añadir la constante si tu modelo la usa</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Cálculo del VIF en Python ---</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Important: Remove 'Unnamed: 0' if it exists in X_train ---</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'Unnamed: 0'</span> <span class="kw">in</span> X_train.columns:</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>])</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.copy() <span class="co"># Use .copy() to avoid SettingWithCopyWarning</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Es crucial añadir una constante (intercepto) a las variables predictoras</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># si tu modelo OLS incluye un intercepto (que es lo común con smf.ols por defecto).</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># El 'add_constant' de statsmodels se encarga de esto.</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>X_with_constant <span class="op">=</span> add_constant(X_train_cleaned)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el VIF para cada variable predictora</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>vif_data <span class="op">=</span> pd.DataFrame()</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>vif_data[<span class="st">"feature"</span>] <span class="op">=</span> X_with_constant.columns</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>vif_data[<span class="st">"VIF"</span>] <span class="op">=</span> [variance_inflation_factor(X_with_constant.values, i)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>                   <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X_with_constant.shape[<span class="dv">1</span>])]</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Se ordenan los resultados para ver las variables con mayor VIF primero</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Factor de Inflación de la Varianza (VIF) ordenado:"</span>)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vif_data.sort_values(by<span class="op">=</span><span class="st">"VIF"</span>, ascending<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Factor de Inflación de la Varianza (VIF) ordenado:
   feature          VIF
0    const  3466.087877
1      cyl    24.921556
2     disp    23.705965
5       wt    18.751416
7       vs    17.461992
6     qsec    15.845728
8       am    13.277013
9     gear    12.589395
3       hp    11.166361
10    carb    10.005587
4     drat     4.308888</code></pre>
</div>
</div>
<ul>
<li><strong>Prácticamente todas las variables (excepto <code>drat</code>) tienen VIF &gt; 10</strong>, lo cual indica <strong>multicolinealidad severa</strong>.</li>
<li>Esto <strong>explica por qué en el modelo original ninguno de los coeficientes era significativo</strong>, a pesar del R² alto.</li>
<li>Multicolinealidad <strong>infla los errores estándar</strong> de los coeficientes y los hace <strong>menos confiables</strong>, incluso si el modelo global es significativo.</li>
</ul>
</section>
</section>
</section>
<section id="evaluación-del-modelo" class="level2">
<h2 class="anchored" data-anchor-id="evaluación-del-modelo">Evaluación del modelo</h2>
<p>La partición de los datos en <code>X_train</code>, <code>X_test</code>, <code>y_train</code>, y <code>y_test</code> se hace una sola vez al principio de tu análisis para asegurar que la evaluación final del modelo (con <code>X_test</code> y <code>y_test</code>) sea imparcial.</p>
<p>Una vez que tienes la fórmula del modelo óptimo se selecciona (<code>'mpg ~ wt + qsec + am'</code>), lo que haces es <strong>re-entrenar el modelo con esta nueva fórmula utilizando únicamente los datos de entrenamiento (<code>X_train</code> y <code>y_train</code>)</strong>.</p>
<div id="6afe6a31" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train y y_train ya han sido definidos y que provienen de la partición original de los datos.</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># También asumiendo que y_train.name ya fue asignado a 'mpg'.</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Se define la fórmula del modelo con las variables seleccionadas</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>selected_formula <span class="op">=</span> <span class="st">'mpg ~ wt + qsec + am'</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Se prepara el DataFrame de entrenamiento solo con las variables seleccionadas</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Primero, se identifica las columnas predictoras de la fórmula (wt, qsec, am)</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>predictors_in_selected_formula <span class="op">=</span> [<span class="st">'wt'</span>, <span class="st">'qsec'</span>, <span class="st">'am'</span>] <span class="co"># Se extraen estas de la fórmula si es dinámica</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Asegurarse de que estas columnas existen en X_train antes de seleccionarlas</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Si 'Unnamed: 0' fue un problema, asegúrate de haberlo quitado de X_train previamente.</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Important: Remove 'Unnamed: 0' if it exists in X_train ---</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'Unnamed: 0'</span> <span class="kw">in</span> X_train.columns:</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>])</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    X_train_cleaned <span class="op">=</span> X_train.copy() <span class="co"># Use .copy() to avoid SettingWithCopyWarning</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Para este ejemplo, asumiremos que X_train ya es X_train_cleaned si usaste ese paso.</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>X_train_selected <span class="op">=</span> X_train[predictors_in_selected_formula]</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Se combina el X_train_selected y y_train en un solo DataFrame</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto es necesario para statsmodels.formula.api.ols</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>train_data_selected_model <span class="op">=</span> pd.concat([X_train_selected, y_train], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Se entrena el modelo OLS con la fórmula y los datos reducidos</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"--- Entrenando el modelo final con la fórmula: </span><span class="sc">{</span>selected_formula<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>final_modelo_ols_py <span class="op">=</span> smf.ols(formula <span class="op">=</span> selected_formula, </span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>                              data <span class="op">=</span> train_data_selected_model).fit()</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Revisa el resumen del modelo final</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Resumen del Modelo OLS Final (Variables Seleccionadas):"</span>)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final_modelo_ols_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Entrenando el modelo final con la fórmula: mpg ~ wt + qsec + am ---

Resumen del Modelo OLS Final (Variables Seleccionadas):
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.879
Model:                            OLS   Adj. R-squared:                  0.862
Method:                 Least Squares   F-statistic:                     50.92
Date:                Thu, 19 Jun 2025   Prob (F-statistic):           8.26e-10
Time:                        15:18:11   Log-Likelihood:                -54.262
No. Observations:                  25   AIC:                             116.5
Df Residuals:                      21   BIC:                             121.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -3.0270      8.017     -0.378      0.710     -19.700      13.646
wt            -3.1064      0.728     -4.267      0.000      -4.620      -1.592
qsec           1.7715      0.352      5.033      0.000       1.039       2.504
am             3.9631      1.421      2.788      0.011       1.007       6.919
==============================================================================
Omnibus:                        1.036   Durbin-Watson:                   1.169
Prob(Omnibus):                  0.596   Jarque-Bera (JB):                1.008
Skew:                           0.368   Prob(JB):                        0.604
Kurtosis:                       2.347   Cond. No.                         314.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<section id="modelo-predictivo" class="level3">
<h3 class="anchored" data-anchor-id="modelo-predictivo">Modelo predictivo</h3>
<p>Con la función <strong><code>predict()</code></strong> genérica en R que se utiliza para obtener predicciones de varios tipos de objetos de modelos (lineales, árboles de decisión, series de tiempo, etc.). Su comportamiento exacto depende de la clase del objeto que se le pasa como primer argumento.</p>
<p>Esta operación es un paso clave en el flujo de trabajo de modelado predictivo, ya que permite:</p>
<ol type="1">
<li><p><strong>Evaluación del modelo:</strong> Una vez que se tienen las <code>predicciones</code> para el <code>test_data</code>, se puede compararlas con los valores reales (observados) de la variable dependiente en el <code>test_data</code> (si se tienen) para <strong>evaluar qué tan bien se desempeña el modelo</strong> en datos no vistos. Esto ayuda a estimar su rendimiento en el mundo real y a detectar problemas como el <strong>sobreajuste (overfitting)</strong>.</p></li>
<li><p><strong>Uso práctico del modelo:</strong> Después de validar que el modelo es bueno, se puede usarlo para predecir la variable dependiente para nuevas observaciones futuras de las que solo se conocen las variables predictoras (por ejemplo, predecir el precio de una casa basándose en sus características, si el modelo fue entrenado para eso).</p></li>
</ol>
<p>El objeto <code>final_modelo_ols_py</code> (que es un objeto de tipo <code>statsmodels.regression.linear_model.RegressionResultsWrapper</code>) tiene un método <code>.predict()</code> que hace exactamente esto.</p>
<div id="41263894" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Para el modelo en los datos de prueba</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># En R, usas 'newdata = test_data_reducido'. En Python, pasas el DataFrame</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># con las mismas columnas predictoras que el modelo fue entrenado con.</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Identificar las variables predictoras del modelo final</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Se pueden obtener directamente de la fórmula o recordarlas:</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Por ejemplo, para 'mpg ~ wt + qsec + am', las predictoras son 'wt', 'qsec', 'am'</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>predictors_final_model <span class="op">=</span> [<span class="st">'wt'</span>, <span class="st">'qsec'</span>, <span class="st">'am'</span>]</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Se crea un dataFrame de datos de prueba con solo las columnas necesarias para la predicción</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Es crucial que X_test_reducido tenga las mismas columnas y en el mismo orden (aunque el orden no suele ser tan estricto</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># si usas DataFrames con nombres de columnas, es buena práctica) que X_train_selected.</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>X_test_reducido <span class="op">=</span> X_test[predictors_final_model]</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular las predicciones</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>predicciones_py <span class="op">=</span> final_modelo_ols_py.predict(X_test_reducido)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Predicciones del modelo en los datos de prueba:"</span>)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(predicciones_py)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Opcional: Si quieres comparar las predicciones con los valores reales de y_test</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Valores reales de mpg en el conjunto de prueba:"</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Predicciones del modelo en los datos de prueba:
7     22.493520
31    25.250166
5     22.044524
26    23.872414
8     27.755115
27    26.174421
12    16.564478
dtype: float64

Valores reales de mpg en el conjunto de prueba:
7     24.4
31    21.4
5     18.1
26    26.0
8     22.8
27    30.4
12    17.3
Name: mpg, dtype: float64</code></pre>
</div>
</div>
</section>
<section id="evaluar-el-desempeño-predictivo" class="level3">
<h3 class="anchored" data-anchor-id="evaluar-el-desempeño-predictivo">Evaluar el desempeño predictivo</h3>
<section id="mean-absolute-error-mae" class="level4">
<h4 class="anchored" data-anchor-id="mean-absolute-error-mae">Mean Absolute Error (<code>MAE</code>)</h4>
<p>El <strong>MAE (Mean Absolute Error)</strong>, o <strong>Error Absoluto Medio</strong> en español, es una de las métricas más utilizadas para evaluar la precisión de un modelo de regresión. Mide la <strong>magnitud promedio de los errores</strong> entre los valores predichos por un modelo y los valores reales observados.</p>
<section id="fórmula-del-mae" class="level5">
<h5 class="anchored" data-anchor-id="fórmula-del-mae">Fórmula del MAE</h5>
<p>La fórmula para calcular el MAE es la siguiente:</p>
<p><span class="math display">\[MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(n\)</span>: Es el número total de observaciones (o puntos de datos) en el conjunto de datos.</li>
<li><span class="math inline">\(y_i\)</span>: Es el <strong>valor real u observado</strong> de la variable dependiente para la observación <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(\hat{y}_i\)</span>: Es el <strong>valor predicho</strong> por el modelo para la observación <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(|y_i - \hat{y}_i|\)</span>: Es el <strong>valor absoluto</strong> de la diferencia entre el valor real y el valor predicho para la observación <span class="math inline">\(i\)</span>. Tomar el valor absoluto es crucial porque evita que los errores positivos y negativos se cancelen entre sí, lo que daría una falsa impresión de precisión.</li>
<li><span class="math inline">\(\sum_{i=1}^{n}\)</span>: Indica la suma de todos los errores absolutos para todas las <span class="math inline">\(n\)</span> observaciones.</li>
</ul>
<div id="2d222036" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cálculo del MAE (Mean Absolute Error)</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y_test, predicciones_py)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MAE en conjunto de prueba: </span><span class="sc">{</span>mae<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MAE en conjunto de prueba: 3.1064</code></pre>
</div>
</div>
<p>Esto significa que, <strong>en promedio</strong>, el modelo reducido predice el consumo de combustible con un error de ±3.10 mpg. Esto es bueno o malo. Depende del rango de la variable <code>mpg</code> en <code>mtcars</code>.</p>
<div id="1af6c472" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el rango (mínimo y máximo) de la columna 'mpg'</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>min_mpg <span class="op">=</span> mtcars_df[<span class="st">'mpg'</span>].<span class="bu">min</span>()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>max_mpg <span class="op">=</span> mtcars_df[<span class="st">'mpg'</span>].<span class="bu">max</span>()</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimir el resultado</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Rango de mpg (mínimo, máximo): (</span><span class="sc">{</span>min_mpg<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>max_mpg<span class="sc">}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rango de mpg (mínimo, máximo): (10.4, 33.9)</code></pre>
</div>
</div>
<p>El rango de <code>mpg</code> es de <strong>10.4 a 33.9</strong>, es decir, abarca <strong>~23.5 unidades</strong>.</p>
<p>Por tanto:</p>
<pre><code>  * Un MAE de **3.10** representa alrededor de un **15% del rango total**. El modelo, en promedio, se equivoca por 3.10 millas por galón en sus predicciones.  
* No es un error enorme, pero **tampoco es excelente**.  
* Si el modelo completo (`modelo_ols`) tenía un MAE menor, podría predecir mejor, aunque con más colinealidad.</code></pre>
</section>
</section>
<section id="root-mean-squared-error-rmse" class="level4">
<h4 class="anchored" data-anchor-id="root-mean-squared-error-rmse">Root Mean Squared Error (<code>RMSE</code>)</h4>
<p>El <strong>RMSE (Root Mean Squared Error)</strong>, o <strong>Raíz del Error Cuadrático Medio</strong>, es una de las métricas más comunes y ampliamente utilizadas para evaluar la precisión de los modelos de regresión. Mide la <strong>magnitud promedio de los errores</strong> entre los valores predichos por un modelo y los valores reales observados, pero dando <strong>mayor peso a los errores más grandes</strong>.</p>
</section>
<section id="fórmula-del-rmse" class="level4">
<h4 class="anchored" data-anchor-id="fórmula-del-rmse">Fórmula del RMSE</h4>
<p><span class="math display">\[RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(n\)</span>: Es el número total de observaciones (o puntos de datos).<br>
</li>
<li><span class="math inline">\(y_i\)</span>: Es el <strong>valor real u observado</strong> de la variable dependiente para la observación <span class="math inline">\(i\)</span>.<br>
</li>
<li><span class="math inline">\(\hat{y}_i\)</span>: Es el <strong>valor predicho</strong> por el modelo para la observación <span class="math inline">\(i\)</span>.<br>
</li>
<li><span class="math inline">\((y_i - \hat{y}_i)^2\)</span>: Es el <strong>cuadrado de la diferencia</strong> entre el valor real y el valor predicho para la observación <span class="math inline">\(i\)</span>.</li>
</ul>
<p>Elevar al cuadrado las diferencias tiene dos propósitos principales:</p>
<ul>
<li>Eliminar los signos negativos: Asegura que los errores positivos y negativos no se cancelen entre sí.<br>
</li>
<li>Penalizar más los errores grandes: Los errores más grandes tienen un impacto desproporcionadamente mayor en el resultado final del RMSE que los errores pequeños, debido a la operación al cuadrado.<br>
</li>
<li><span class="math inline">\(\sum_{i=1}^{n}\)</span>: Indica la suma de todos los errores al cuadrado para todas las <span class="math inline">\(n\)</span> observaciones.</li>
</ul>
<section id="interpretación-del-rmse" class="level5">
<h5 class="anchored" data-anchor-id="interpretación-del-rmse">Interpretación del RMSE:</h5>
<ul>
<li>El RMSE se expresa en las <strong>mismas unidades que la variable dependiente original</strong>. Esto facilita su interpretación. Por ejemplo, si estás prediciendo la altura en metros y el RMSE es 0.5, significa que, en promedio, las predicciones del modelo se desvían aproximadamente 0.5 metros de la altura real.<br>
</li>
<li><strong>Un RMSE de 0 (cero) indica un modelo perfecto</strong>, donde todas las predicciones son exactamente iguales a los valores reales.</li>
<li><strong>Valores más bajos de RMSE indican un mejor rendimiento del modelo.</strong>
<ul>
<li><strong>Sensibilidad a valores atípicos:</strong> Debido al término al cuadrado, el RMSE penaliza más fuertemente los errores grandes (valores atípicos) que el MAE. Esto significa que si tu modelo tiene algunos errores de predicción muy grandes, el RMSE será significativamente más alto que el MAE. Esta característica puede ser una ventaja o desventaja dependiendo del contexto:<br>
</li>
<li><strong>Ventaja:</strong> Si los errores grandes son particularmente indeseables en tu aplicación, el RMSE es una buena métrica porque los destaca.<br>
</li>
</ul></li>
<li><strong>Desventaja:</strong> Si tu conjunto de datos contiene muchos valores atípicos reales o errores de medición que no son representativos del rendimiento general del modelo, el RMSE podría dar una visión pesimista.</li>
</ul>
<div id="66c3d9af" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cálculo del RMSE (Root Mean Squared Error)</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test, predicciones_py))</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">RMSE en conjunto de prueba: </span><span class="sc">{</span>rmse<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
RMSE en conjunto de prueba: 3.4120</code></pre>
</div>
</div>
<ul>
<li>Un RMSE de <strong>3.4120</strong> significa que, en promedio, las predicciones difieren de los valores reales por <strong>±3.41 millas por galón</strong>.
<ul>
<li>Como <strong>los errores grandes tienen más peso</strong> (al ser elevados al cuadrado), el RMSE será siempre <strong>igual o mayor al MAE</strong>. Penaliza más los errores grandes que el MAE.</li>
<li>Es <strong>aceptable para predicción en <code>mtcars</code></strong>, pero con espacio para mejora si se requiere mayor precisión.</li>
</ul></li>
</ul>
<p><strong>Compararlo con el MAE</strong></p>
<ul>
<li>Si <strong>RMSE está mucho más alto que el MAE</strong>, el modelo está cometiendo <strong>errores grandes con frecuencia</strong> (outliers, mala especificación).<br>
</li>
<li>Si <strong>RMSE ≈ MAE</strong>, los errores están bien distribuidos.</li>
</ul>
</section>
</section>
<section id="coeficiente-de-determinación-r2" class="level4">
<h4 class="anchored" data-anchor-id="coeficiente-de-determinación-r2">Coeficiente de determinación <span class="math inline">\(R^2\)</span></h4>
<p><span class="math inline">\(R^{2}\)</span> (<strong>coeficiente de determinación</strong>) mide qué proporción de la variabilidad de la <strong>variable dependiente</strong> es explicada por el modelo.</p>
<p>La fórmula general del <span class="math inline">\(R^2\)</span> (coeficiente de determinación) es:</p>
<p><span class="math display">\[R^2 = 1 - \frac{SSE}{SST}\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(SSE\)</span> (Sum of Squared Errors) o <span class="math inline">\(RSS\)</span> (Residual Sum of Squares): Es la <strong>Suma de Cuadrados de los Errores</strong> (o Suma de Cuadrados de los Residuos). Mide la variación no explicada por el modelo. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados (<span class="math inline">\(y_i\)</span>) y los valores predichos por el modelo (<span class="math inline">\(\hat{y}_i\)</span>):</li>
</ul>
<p><span class="math display">\[SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span></p>
<ul>
<li><span class="math inline">\(SST\)</span> (Total Sum of Squares): Es la <strong>Suma Total de Cuadrados</strong>. Mide la variación total de la variable dependiente respecto a su media. Representa la variabilidad total en los datos que el modelo intenta explicar. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados (<span class="math inline">\(y_i\)</span>) y la media de la variable dependiente (<span class="math inline">\(\bar{y}\)</span>):</li>
</ul>
<p><span class="math display">\[SST = \sum_{i=1}^{n} (y_i - \bar{y})^2\]</span></p>
<section id="interpretación-del-r2" class="level5">
<h5 class="anchored" data-anchor-id="interpretación-del-r2">Interpretación del <span class="math inline">\(R^2\)</span>:</h5>
<ul>
<li>El <span class="math inline">\(R^2\)</span> es una métrica que varía entre <strong>0 y 1</strong> (o 0% y 100%).<br>
</li>
<li><span class="math inline">\(R^2 = 0\)</span>: Indica que el modelo no explica ninguna de la variabilidad en la variable dependiente. Es tan bueno como simplemente usar la media de la variable dependiente para la predicción.<br>
</li>
<li><span class="math inline">\(R^2 = 1\)</span>: Indica que el modelo explica el 100% de la variabilidad en la variable dependiente. Esto rara vez ocurre en la práctica con datos del mundo real, y a menudo sugiere sobreajuste si sucede en un conjunto de entrenamiento.<br>
</li>
<li><strong>Valores más altos de</strong> <span class="math inline">\(R^2\)</span> indican un mejor ajuste del modelo a los datos observados, lo que significa que las variables predictoras del modelo explican una mayor proporción de la variabilidad en la variable dependiente.</li>
</ul>
<div id="ed696922" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>r_squared_test <span class="op">=</span> r2_score(y_test, predicciones_py)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared en conjunto de prueba: </span><span class="sc">{</span>r_squared_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R-squared en conjunto de prueba: 0.3468</code></pre>
</div>
</div>
<ul>
<li>Esto significa que el <strong>65.3% de la variabilidad</strong> de <code>mpg</code> (consumo de combustible) en los datos de prueba <strong>es explicada por el modelo</strong>.
<ul>
<li>El <strong>34.6% restante</strong> es <strong>variabilidad no explicada</strong> (error, factores no incluidos, ruido).<br>
</li>
<li>El modelo predice <strong>más de la mitad de la variabilidad de <code>mpg</code></strong> en los datos de prueba.</li>
</ul></li>
</ul>
</section>
</section>
<section id="distribución-de-los-residuos" class="level4">
<h4 class="anchored" data-anchor-id="distribución-de-los-residuos">Distribución de los residuos</h4>
<p>Relación lineal entre variable dependiente e independiente:</p>
<p>Se calculan los residuos para cada observación y se representan (<code>scatterplot</code>). Si las observaciones siguen la línea del modelo, los residuos se deben distribuir aleatoriamente entorno al valor 0.</p>
<div id="5878c6f0" class="cell" data-message="false" data-results="as-is" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Se crea un dataframe 'tabla' con fitted.values y residuals</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># En statsmodels, los valores ajustados se obtienen con .fittedvalues y los residuos con .resid</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>tabla_py <span class="op">=</span> pd.DataFrame({</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>                         <span class="st">'prediccion'</span>: final_modelo_ols_py.fittedvalues,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>                         <span class="st">'residuo'</span>: final_modelo_ols_py.resid</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Configuración de los estilos para el gráfico (similar a theme_bw y los ajustes de texto de ggplot2)</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Configura el estilo de seaborn</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>) <span class="co"># Similar a theme_bw() o theme_minimal()</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Se configura la fuente globalmente en Montserrat</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.family'</span>] <span class="op">=</span> <span class="st">'Montserrat'</span> <span class="co"># Descomenta si tienes la fuente instalada</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Se crea la figura y los ejes</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)) <span class="co"># Tamaño de la figura</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Se crea el gráfico de dispersión con Seaborn</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Se usa scatterplot para los puntos y controlamos el color con 'hue'</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Se usa palette para la escala de colores, similar a scale_color_gradient2</span></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>scatterplot <span class="op">=</span> sns.scatterplot(</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>                              data <span class="op">=</span> tabla_py,</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>                              x <span class="op">=</span> <span class="st">'prediccion'</span>,</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>                              y <span class="op">=</span> <span class="st">'residuo'</span>,</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>                              hue <span class="op">=</span> <span class="st">'residuo'</span>, <span class="co"># Colorear por el valor del residuo</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>                              palette <span class="op">=</span> <span class="st">'RdBu_r'</span>, <span class="co"># 'RdBu_r' es una paleta divergente (rojo-azul, invertida para azul-rojo)</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>                                                <span class="co"># 'coolwarm' también es una buena opción divergente.</span></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>                              legend <span class="op">=</span> <span class="va">False</span>,     <span class="co"># No mostrar leyenda de color, similar a legend.position = "none"</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>                              s <span class="op">=</span> <span class="dv">70</span>,             <span class="co"># Tamaño de los puntos</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>                              alpha <span class="op">=</span> <span class="fl">0.8</span>         <span class="co"># Transparencia</span></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 4.Se añade la línea horizontal en y=0</span></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>plt.axhline(y <span class="op">=</span> <span class="dv">0</span>, color <span class="op">=</span> <span class="st">'black'</span>, linestyle <span class="op">=</span> <span class="st">'-'</span>, linewidth <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Se añaden los segmentos desde los puntos hasta y = 0</span></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Se puede hacer iterando o usando una función de matplotlib si fuera posible vectorizarlo</span></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Para simplicidad y control, iteramos aquí. Ojo: para muchos puntos, esto puede ser lento.</span></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Para muchos puntos, podrías considerar alternativas o quitarlo si no es crítico para la interpretación.</span></span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tabla_py)):</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    x_val <span class="op">=</span> tabla_py[<span class="st">'prediccion'</span>].iloc[i]</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>    y_val <span class="op">=</span> tabla_py[<span class="st">'residuo'</span>].iloc[i]</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>    plt.plot([x_val, x_val], [y_val, <span class="dv">0</span>], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth <span class="op">=</span> <span class="fl">0.5</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>)</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Se configuran las etiquetas y título</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribución de los residuos"</span>, fontsize <span class="op">=</span> <span class="dv">18</span>, loc <span class="op">=</span> <span class="st">'left'</span>, fontweight <span class="op">=</span> <span class="st">'bold'</span>)</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"predicción modelo"</span>, fontsize <span class="op">=</span> <span class="dv">14</span>)</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"residuo"</span>, fontsize <span class="op">=</span> <span class="dv">14</span>)</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustes de los ticks y etiquetas de los ejes</span></span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>plt.tick_params(axis <span class="op">=</span> <span class="st">'x'</span>, labelsize <span class="op">=</span> <span class="dv">12</span>)</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>plt.tick_params(axis  <span class="op">=</span><span class="st">'y'</span>, labelsize <span class="op">=</span> <span class="dv">12</span>)</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar los límites del eje y si es necesario para evitar que los puntos se corten</span></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.ylim(min(tabla_py['residuo']) * 1.1, max(tabla_py['residuo']) * 1.1)</span></span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar el gráfico</span></span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>plt.tight_layout() <span class="co"># Ajusta el diseño para que no se corten etiquetas</span></span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_01_OLSR_py_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>