---
title: "Ordinary Least Squares Regression (OLSR)"
subtitle: "Apuntes y anotaciones personales"
author: "Diana Villasana Ocampo"
format:
  html:
    code-fold: false
    highlight-style: tango
    theme: flatly
    toc: true
    toc-depth: 3
    toc-location: left
engine: jupyter
jupyter: python3
execute:
  echo: true      
  message: false   # Suprimir mensajes generados por R/Python
  warning: false   # Suprimir advertencias generadas por R/Python
  error: false     # Suprimir errores (muestra la ejecuci√≥n, pero no los errores)
  execute-dir: project
  # cache: true    # Habilitar el cach√© (si quieres, desactiva para depuraci√≥n)
output-dir: ../../Output/Regression
---

```{python}
#| include: false
#| echo: false
#| eval: false
import subprocess
import os

input_file = os.path.join(os.getcwd(), "\\R", "\\Regression", "\\01.01.OLSR_py.qmd")
output_dir = os.path.join(os.getcwd(), "\\Output\\Regression\\")

subprocess.run([
    "quarto",
    "render",
    input_file,
    "--output-dir", output_dir
])
```

```{=html}
<style type="text/css">
body {
text-align: justify;
font-style: normal;
font-family: "Montserrat";
font-size: 12px
}
h1.title {
  font-size: 40px;
  color: #000D3B;
}
h1 {
  font-size: 35px;
  color: #B6854D;
}
h2 {
  font-size: 30px;
  color: #172984;
}
h3 {
  font-size: 25px;
  color: #172984;
}
h4 {
  font-size: 22px;
  color: #172984;
}
h5 {
  ont-size: 20px;
  color: #172984;
}
h6{
  ont-size: 18px;
  color: #1864cb;
}
</style>
```

```{=html}
<style>
.nav>li>a {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #1C3BA4
}
.nav-pills>li.active>a, .nav-pills>li.active>a:hover, .nav-pills>li>a:focus {
    color: #ffffff;
    background-color: #09C2BC
}
</style>
```

```{=html}
<style>
.tile1-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6A87;
    list-style: none;
}
.top1-tiles a:nth-of-type(1):hover, .top-tiles1 a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6A87
}
</style>
```

```{=html}
<style>
.tile2-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6CC8;
    list-style: none;
}
.top2-tiles a:nth-of-type(1):hover, .top2-tiles a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6CC8
}
</style>
```

```{=html}
<style>
.math {
  font-size: 15px;
  color: #1e42ab;
}

.callout {
  border: 1px solid red; /* Yellow border */
  background-color: lightgrey; /* Light yellow background */
  padding: 15px;
  margin-bottom: 15px;
  border-left: 5px solid #ffcc00; /* Stronger left border */
}

</style>
```

::: {.callout-note appearance="default" icon="üéØ"}
## Este material es reproducible en c√≥digo Python utilizando Quarto
:::

La Regresi√≥n por M√≠nimos Cuadrados Ordinarios (Ordinary Least Squares Regression, **OLSR** u **OLS**) representa una metodolog√≠a estad√≠stica esencial que permite analizar la correlaci√≥n entre una **variable dependiente** (tambi√©n conocida como variable de respuesta) y una o m√°s **variables independientes** (o predictoras). Este m√©todo constituye una herramienta fundamental en el campo del an√°lisis de regresi√≥n lineal.

<p align="center">

<img src="../../img/Regression/01_image_OLSR.png" alt="Machine Learning Steps" width="40%"/>

</p>

```{python}
#| echo: false
#| eval: false
import sys
print(sys.path)

```

```{python}
#| label: setup-python
#| include: false # Oculta este chunk ya que es solo para configuraci√≥n

# Importar reticulate en Python y asegurar la inicializaci√≥n del puente R
# Esto crea el objeto 'r' en el entorno de Python
#import rpy2.robjects as ro
#import rpy2.situation
#from rpy2.robjects import pandas2ri
#from rpy2.robjects.conversion import localconverter

# Activar la conversi√≥n autom√°tica de R a pandas DataFrame
#pandas2ri.activate()

# Puedes incluso hacer una peque√±a prueba para asegurarte de que R est√° activo
# print(ro.r('R.version.string'))
```

**Librer√≠as que se usaron en el documento**

```{python}
#| label: load-py-pckgs

#conda install -c conda-forge numpy
#conda install -c conda-forge pandas
#conda install -c conda-forge scikit-learn

import re
import rpy2
import pandas as pd
from pathlib import Path
import seaborn as sns
import os # Necesario para la funci√≥n os.makedirs
```

```{python}
#| echo: false
#| eval: true

# Datos de la tabla
criterios = [
    "üîç Tipo de modelo",
    "üéØ Variable respuesta",
    "üî¢ Variables predictoras",
    "üìà Relaci√≥n entre variables",
    "üß™ Normalidad de residuos",
    "üîÅ Independencia de errores",
    "‚öñÔ∏è Homoscedasticidad",
    "‚ùó Sensible a outliers",
    "üîó Multicolinealidad entre predictores",
    "üß† Interpretabilidad",
    "üöÄ Velocidad y eficiencia",
    "üß™ Validaci√≥n cruzada",
    "‚ùå No funciona bien si..."
]

aplica = [
    "Supervisado",
    "Num√©rica continua",
    "Num√©ricas y/o categ√≥ricas",
    "Lineal (supuesto clave)",
    "Deseable",
    "Necesaria",
    "Necesaria",
    "S√≠",
    "Problema com√∫n",
    "Alta",
    "Muy alta",
    "Compatible",
    "Relaciones no lineales, outliers severos, colinealidad"
]

detalles = [
    "Se entrena con datos X ‚Üí y",
    "Ej. mpg, precio, ingresos",
    "Categor√≠as convertidas a dummies",
    "Se asume una relaci√≥n lineal entre X e Y",
    "Importante para intervalos de confianza v√°lidos",
    "Errores deben ser independientes",
    "Varianza de errores debe ser constante",
    "Outliers pueden influir mucho en el modelo",
    "Usar VIF para detectar problemas",
    "Modelo f√°cil de explicar",
    "R√°pido incluso con datos grandes",
    "Ayuda a prevenir overfitting",
    "Evitar si no hay linealidad o hay muchos outliers"
]

# Crear DataFrame de Pandas
tabla_olsr = pd.DataFrame({
    "Criterio": criterios,
    "Aplica": aplica,
    "Detalles": detalles
})

# Estilizar la tabla con Pandas Styler
# Nota: La estilizaci√≥n exacta como 'gt' es compleja de replicar pixel a pixel con Pandas Styler
# pero podemos acercarnos a la mayor√≠a de los requerimientos.
# Para fuentes personalizadas como 'Century Gothic', puede que necesites CSS externo
# o que el navegador del usuario tenga la fuente instalada.

styled_table = (
    tabla_olsr.style
    .set_table_attributes("style='font-family: Century Gothic; font-size: 10pt;'")
    .set_caption("<h2 style='text-align: left; font-weight: bold; font-size: 14pt;'>Gu√≠a r√°pida para elegir OLSR</h2><p style='text-align: left; font-size: 12pt;'>Fuente: Elaboraci√≥n propia</p>")
    .set_properties(subset=['Criterio', 'Aplica'], **{'width': '200px'})
    .set_properties(subset=['Detalles'], **{'width': '500px'})
    .set_properties(**{'text-align': 'left'}) # Alinea todo a la izquierda por defecto
    .set_table_styles([ # Para aplicar el padding a las celdas
        {'selector': 'td', 'props': [('padding', '1px')]}
    ], overwrite=False)
)

styled_table
```

## Objetivo

La Regresi√≥n por M√≠nimos Cuadrados Ordinarios (`OLSR`) busca la l√≠nea que mejor se ajusta a los datos. Para lograrlo, reduce al m√≠nimo la suma de los cuadrados de las diferencias entre los valores reales y los valores que predice el modelo. Estas diferencias son los **residuos** o **errores**. Al trabajar con los cuadrados de los errores, este m√©todo evita que los errores positivos y negativos se anulen entre s√≠, y da m√°s peso a los errores grandes durante el proceso de minimizaci√≥n.

## Metodolog√≠a

La metodolog√≠a de OLSR se basa en los siguientes pasos y principios:

1.  **Modelo Lineal:** OLSR asume una relaci√≥n lineal entre las variables. Para una regresi√≥n lineal simple (una variable independiente), la ecuaci√≥n es:\
    $$Y = \beta_0 + \beta_1X + \epsilon$$

    Donde:

    -   $Y$ es la variable dependiente.

-   $X$ es la variable independiente.
-   $\beta_0$ es el intercepto (el valor de $Y$ cuando $X$ es 0).
-   $\beta_1$ es la pendiente (el cambio en $Y$ por cada unidad de cambio en $X$).
-   $\epsilon$ es el t√©rmino de error o residual, que representa la parte de $Y$ que no puede ser explicada por $X$.

Para una regresi√≥n lineal m√∫ltiple (varias variables independientes), la ecuaci√≥n se expande a:\
$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k + \epsilon$$

2.  **Minimizaci√≥n de la Suma de Cuadrados de Residuos (SSR):** El coraz√≥n de OLS es encontrar los valores de los coeficientes ($\beta_0, \beta_1$, etc.) que minimicen la siguiente funci√≥n:\
    $$\text{Minimizar } \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$\
    Donde:
    -   $y_i$ es el valor observado de la variable dependiente para la observaci√≥n $i$.

-   $\hat{y}_i$ es el valor predicho de la variable dependiente por el modelo para la observaci√≥n $i$.
-   $(y_i - \hat{y}_i)$ es el residual para la observaci√≥n $i$.

Para lograr esta minimizaci√≥n, se utilizan t√©cnicas de c√°lculo (derivadas parciales) para encontrar los valores de los coeficientes que hacen que la pendiente de la funci√≥n de suma de cuadrados sea cero.

3.  **Estimaci√≥n de Coeficientes:** Los valores estimados de los coeficientes, denotados como $\hat{\beta}_0, \hat{\beta}_1$, etc., son aquellos que resultan de la minimizaci√≥n. Estos coeficientes son los que definen la "l√≠nea de mejor ajuste".

4.  **Supuestos del OLS:** Para que los estimadores de OLS sean los "mejores estimadores lineales insesgados" (seg√∫n el Teorema de Gauss-Markov), se deben cumplir ciertas suposiciones:

    -   **Linealidad:** La relaci√≥n entre las variables es lineal.

    -   **Independencia de los errores:** Los errores de una observaci√≥n no est√°n correlacionados con los errores de otra.

    -   **Homocedasticidad:** La varianza de los errores es constante en todos los niveles de las variables independientes.

    -   **Normalidad de los errores:** Los errores se distribuyen normalmente (aunque no es estrictamente necesario para la estimaci√≥n, s√≠ lo es para la inferencia estad√≠stica).

    -   **No multicolinealidad perfecta:** Las variables independientes no est√°n perfectamente correlacionadas entre s√≠.

## **Pasos generales del Machine Learning supervisado**

1.  **Importar y explorar los datos**
2.  **Preprocesamiento**
3.  **Divisi√≥n de los datos (train/test)**
4.  **Entrenamiento del modelo**
5.  **Evaluaci√≥n del modelo**
6.  **Ajustes o validaci√≥n cruzada (si aplica)**
7.  **Predicci√≥n con nuevos datos**
8.  **Interpretaci√≥n de resultados**

<p align="center">
<img src="../../img/ML_Steps.png" alt="Machine Learning Steps" width="100%"/>
</p>

------------------------------------------------------------------------

## Base de datos

La base de datos `mtcars` es un conjunto de datos cl√°sico en R que contiene informaci√≥n sobre **32 autom√≥viles** (modelos de 1973‚Äì74), y fue extra√≠do de la revista *Motor Trend US*. Incluye **variables t√©cnicas** del desempe√±o de los autos.

Aqu√≠ est√° una descripci√≥n de cada columna:

| Variable | Significado | Tipo de dato |
|-------------------|----------------------------------|-------------------|
| `mpg` | Miles per gallon (millas por gal√≥n) | Num√©rica |
| `cyl` | N√∫mero de cilindros | Entero |
| `disp` | Desplazamiento del motor (en pulgadas c√∫bicas) | Num√©rica |
| `hp` | Caballos de fuerza | Entero |
| `drat` | Relaci√≥n del eje trasero (rear axle ratio) | Num√©rica |
| `wt` | Peso del auto (en miles de libras) | Num√©rica |
| `qsec` | Tiempo en 1/4 de milla (segundos) | Num√©rica |
| `vs` | Tipo de motor: 0 = V-shaped, 1 = straight (en l√≠nea) | Binaria (factor) |
| `am` | Tipo de transmisi√≥n: 0 = autom√°tica, 1 = manual | Binaria (factor) |
| `gear` | N√∫mero de velocidades (marchas) adelante | Entero |
| `carb` | N√∫mero de carburadores | Entero |

```{python}
#| eval: false
require(reticulate)
reticulate::repl_python() #can be used to interactively run Python code
# 2. Cargar y se exploran los datos
data("mtcars")
```

```{python}
#| echo: true
#| eval: false 

#pip install openpyxl 
import pandas as pd
from pathlib import Path
import os # Necesario para la funci√≥n os.makedirs

# Cargar la base de datos mtcars directamente desde el entorno de R
# r.mtcars accede al objeto 'mtcars' que R ha puesto a disposici√≥n
# Reticulate autom√°ticamente lo convierte a un DataFrame de Pandas.
mtcars_df = r.mtcars

## Se guarda la base de datos en un archivo Excel  
file = Path.cwd().parent.parent / "Data"

mtcars_df.to_excel(file /"mtcars_data.xlsx", index=True)
```

```{python}
mtcars_df = pd.read_excel(Path.cwd().parent.parent / "Data" / "mtcars_data.xlsx")
```

```{python}
#| echo: false
mtcars_df.head(10)
```
**Convertir todas las columnas a tipo num√©rico** 

```{python}
# --- IMPORTANTE: Convertir todas las columnas a tipo num√©rico ---
# Esto es crucial para evitar el TypeError
# 'errors='coerce'' convertir√° cualquier valor no num√©rico a NaN
# y luego se pueden manejar los NaNs (por ejemplo, rellenar o eliminar)

mtcars_df = mtcars_df.apply(pd.to_numeric, errors='coerce')
```


## Entrenamiento de los datos (train/test)

La divisi√≥n de datos en conjuntos de **entrenamiento (train)** y **prueba (test)** es una pr√°ctica fundamental en el aprendizaje autom√°tico y la modelizaci√≥n predictiva. Su importancia radica en la necesidad de obtener una evaluaci√≥n **realista y no sesgada** del rendimiento de un modelo, y de asegurar que el modelo sea capaz de **generalizar** a datos nuevos y no vistos.

-   En Python, `train_test_split()` devuelve directamente los cuatro conjuntos de datos:
    -   `X_train`: Predictoras para entrenamiento.
-   `X_test`: Predictoras para prueba.
-   `y_train`: Variable objetivo para entrenamiento.
-   `y_test`: Variable objetivo para prueba.

```{python}
#| label: split-data
#| echo: true
#| message: false
#| warning: false

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np # Necesario si necesitas setear una semilla para numpy/pandas

# Definir la variable objetivo (dependiente)
target_variable = 'mpg'

# X contendr√° todas las variables predictoras (features)
# Y contendr√° la variable objetivo
X = mtcars_df.drop(columns=[target_variable])
y = mtcars_df[target_variable]

# 3. Dividir los datos en entrenamiento y prueba
# random_state es el equivalente a set.seed() para reproducibilidad
# test_size=0.2 significa que el 20% de los datos ir√°n al conjunto de prueba (80% para entrenamiento)
# Esto es importante para asegurar que las proporciones de 'mpg' sean similares en ambos conjuntos,
# especialmente √∫til para variables categ√≥ricas o si la distribuci√≥n de 'mpg' es importante.
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=123
)

print(f"Tama√±o del conjunto de entrenamiento (X_train): {X_train.shape}")
print(f"Tama√±o del conjunto de prueba (X_test): {X_test.shape}")
print(f"Tama√±o del conjunto de entrenamiento (y_train): {y_train.shape}")
print(f"Tama√±o del conjunto de prueba (y_test): {y_test.shape}")
```

-   Particionar los datos, evita el **overfitting** (cuando el modelo memoriza los datos de entrenamiento).
-   Permite una **evaluaci√≥n honesta** del modelo al probarlo en datos que no vio durante el entrenamiento.
-   Es una pr√°ctica est√°ndar en cualquier pipeline de aprendizaje autom√°tico.

## Entrenamiento del modelo

El **entrenamiento de un modelo** es el paso m√°s importante en el aprendizaje autom√°tico. Usando un conjunto de datos de entrenamiento (`train_data`), el modelo aprende a reconocer patrones para hacer predicciones confiables con datos nuevos. Este proceso es esencial por estas razones:

-   Durante el entrenamiento, el modelo **identifica patrones espec√≠ficos** en los datos.
-   Separamos los datos en grupos de entrenamiento y prueba para asegurar que el modelo funcione bien no solo con datos conocidos, sino tambi√©n con **datos nuevos y no vistos**.
-   Despu√©s del entrenamiento con `train_data`, usamos el **conjunto de prueba (`test_data`)** para medir el rendimiento. Las m√©tricas (MAE, RMSE, $R^2$) nos muestran qu√© tan bien el modelo **maneja datos nuevos**.
-   Un rendimiento peor en `test_data` que en `train_data` indica que el modelo est√° sobreajustado.
-   Con estos resultados, podemos decidir si el modelo est√° listo para usar o necesita ajustes.

**Funci√≥n de entrenamiento**

-   `modelo_ols_py = smf.ols(formula=formula, data=train_data_combined).fit()`:
-   `smf.ols()`: Es la funci√≥n para ajustar un modelo de M√≠nimos Cuadrados Ordinarios (Ordinary Least Squares - OLS).
-   `formula=formula`: Le pasamos la cadena de f√≥rmula que definimos.
-   `data=train_data_combined`: Le indicamos de qu√© DataFrame debe tomar las variables.
-   `.fit()`: Este m√©todo entrena el modelo sobre los datos.

```{python}
#| label: train-ols-model
#| echo: true
#| message: false
#| warning: false
#| results: as-is # Importante para mostrar el resumen del modelo como HTML

import pandas as pd
import statsmodels.formula.api as smf # Para la sintaxis tipo R de f√≥rmulas

# Asumiendo que X_train, X_test, y_train, y_test ya est√°n definidos
# por el chunk de divisi√≥n de datos anterior.

# Para asegurar que X_train y y_train se combinen correctamente para statsmodels
# statsmodels prefiere un solo DataFrame que contenga todas las variables
# Esto es similar a c√≥mo `lm` en R usa `data = train_data`

# Combinar X_train y y_train en un solo DataFrame para statsmodels
train_data_combined = pd.concat([X_train, y_train], axis=1)

# Definir la f√≥rmula del modelo (similar a R)
# mpg ~ . significa "mpg en funci√≥n de todas las dem√°s variables en el DataFrame"
# Para statsmodels, es mejor listar expl√≠citamente las columnas si X_train tiene muchas
# O si quieres un subconjunto espec√≠fico, lo especificas aqu√≠.
# Aqu√≠ construimos la f√≥rmula din√°micamente para incluir todas las variables de X_train
formula = f"{y_train.name} ~ " + " + ".join(X_train.columns)

# 4. Entrenar el modelo de regresi√≥n lineal (OLS)
# statsmodels.formula.api permite usar la sintaxis de f√≥rmula similar a R
modelo_ols_py = smf.ols(formula = formula, data = train_data_combined).fit()

# Revisar resumen del modelo (similar a summary() en R)
print("Resumen del Modelo OLS en Python:")
print(modelo_ols_py.summary()) # .as_html() para una salida bonita en Quarto
```

Como resultado se da una visi√≥n general de qu√© tan bien el modelo se ajusta a los datos:

-   **`R-squared: 0.896`**: Tambi√©n conocido como **coeficiente de determinaci√≥n**. Esto significa que el 89.6% de la variabilidad en `mpg` puede ser explicada por las variables predictoras en tu modelo. ¬°Este es un valor bastante alto, lo que sugiere que tu modelo explica una gran parte de la variaci√≥n en `mpg`!
    -   **`Adj. R-squared: 0.821`**: El **R-cuadrado ajustado** es una versi√≥n del R-cuadrado que penaliza el modelo por cada variable predictora adicional. Es m√°s √∫til cuando comparas modelos con diferentes n√∫meros de predictores. Un valor de 0.821 sigue siendo muy bueno y sugiere que el alto R-cuadrado no es solo por a√±adir muchas variables sin valor.
-   **`F-statistic: 12.00`**: La **Estad√≠stica F** eval√∫a la significancia global del modelo. Prueba la hip√≥tesis nula de que todos los coeficientes de las variables predictoras son cero (es decir, que ninguna de tus variables predictoras tiene un efecto significativo sobre `mpg`).
-   **`Prob (F-statistic): 3.06e-05`**: Este es el **p-valor asociado a la Estad√≠stica F**. Un valor tan peque√±o (3.06e-05, que es 0.0000306) es mucho menor que el nivel de significancia com√∫n (0.05). Esto significa que **el modelo en su conjunto es estad√≠sticamente significativo**, y al menos una de tus variables predictoras tiene un efecto significativo sobre `mpg`.

**Estad√≠sticos**

Estas m√©tricas ayudan a evaluar si el modelo cumple con los supuestos de la regresi√≥n lineal:

-   **`Omnibus`, `Prob(Omnibus)`, `Jarque-Bera (JB)`, `Prob(JB)`, `Skew`, `Kurtosis`**: Estas son pruebas de **normalidad de los residuos**.
-   `Prob(Omnibus): 0.310` y `Prob(JB): 0.462` (ambos \> 0.05) sugieren que **los residuos son aproximadamente normales**, lo cual es bueno.
-   `Skew` (Asimetr√≠a) y `Kurtosis` (Curtosis) describen la forma de la distribuci√≥n de los residuos. Valores cercanos a 0 para `Skew` y cercanos a 3 para `Kurtosis` (o 0 para `Excess Kurtosis`, que es lo que se interpreta a menudo) indican normalidad. Tus valores son razonables.
-   **`Durbin-Watson: 1.335`**: Esta prueba detecta la **autocorrelaci√≥n en los residuos**.
    -   Un valor cercano a 2 indica poca o ninguna autocorrelaci√≥n.
    -   Valores muy por debajo de 2 (como 1.335) pueden sugerir cierta autocorrelaci√≥n positiva (residuos adyacentes est√°n correlacionados), lo cual es una violaci√≥n de los supuestos y podr√≠a afectar la validez de tus errores est√°ndar y p-valores.
-   **\``Cond. No.: 1.94e+04`**: El **N√∫mero de Condici√≥n**.
    -   Este valor es una medida de **multicolinealidad**.
    -   Un valor alto (generalmente \> 1000, y este es de 19400) **indica una fuerte multicolinealidad** entre las variables predictoras. Esto confirma la sospecha de la tabla de coeficientes: tus variables est√°n altamente correlacionadas entre s√≠, lo que dificulta al modelo discernir el efecto √∫nico de cada una. Esta es la raz√≥n m√°s probable por la que el modelo es significativo en general, pero los predictores individuales no lo son.

**¬øPor qu√© los resultados de R y Python son diferentes a pesar de usar la misma l√≥gica?**

La raz√≥n principal por la que obtienes resultados ligeramente diferentes en R y Python para los coeficientes, errores est√°ndar y p-valores (aunque las m√©tricas generales como R-cuadrado y F-estad√≠stico son muy similares) es debido a la **naturaleza aleatoria de la divisi√≥n de los datos en entrenamiento y prueba**.

#### üìå **Observaciones generales**

-   El modelo tiene un **muy buen R¬≤** (89.6%) ‚áí explica bien la variabilidad en `mpg`.

-   **El modelo completo es estad√≠sticamente significativo**, pero **ninguna variable individual lo es**, lo que probablemente se deba a **multicolinealidad**.

-   Considera usar:

    -   **An√°lisis de VIF** (Variance Inflation Factor) para detectar multicolinealidad.
    -   **Reducci√≥n de dimensionalidad** (PCA, selecci√≥n de variables).
    -   **Regularizaci√≥n** (Ridge/Lasso) para mejorar la estabilidad del modelo.  
    
    
```{python}
#| label: scatter-plots-faceted
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
#| fig-width: 10 # Ajusta el ancho de la figura
#| fig-height: 8  # Ajusta la altura de la figura

import pandas as pd
from plotnine import (
    ggplot, aes, geom_point, geom_smooth, facet_wrap,
    theme_bw, theme, element_text, labs
)

# Cargar datos de ejemplo si no tienes mtcars_df
from plotnine.data import mtcars
mtcars_df = mtcars.copy()


# 1. Preparaci√≥n de los datos
tabla_py = (
            mtcars_df
           .drop(columns = ['name'], errors = 'ignore')
           .melt(id_vars = ["mpg"], var_name = "variable", value_name = "value")
)

# 2. Crear el gr√°fico con plotnine
p = (
    ggplot(tabla_py, aes(y = "mpg", x = "value", color = "variable"))
    + geom_point()
    + geom_smooth(method="lm", se=True, color="black")
    + theme_bw()
    + theme(
        plot_title=element_text(size = 22),
        plot_subtitle=element_text(size = 18),
        plot_caption=element_text(size = 11),
        axis_text=element_text(),
        axis_text_x = element_text(angle = 45),
        axis_title=element_text(size = 15),
        legend_position="none"
    )
    + facet_wrap("~variable", scales="free")
    + labs(
        title="Diagramas de dispersi√≥n",
        x="",
        y=""
    )
)

# Mostrar el gr√°fico
p
```


## Selecci√≥n de variables

### Criterio de Informaci√≥n de Akaike

El Criterio de Informaci√≥n de Akaike (AIC, por sus siglas en ingl√©s, Akaike Information Criterion) es una medida de la bondad de ajuste de un modelo estad√≠stico que penaliza la complejidad del modelo. Su objetivo es seleccionar el modelo que mejor se ajusta a los datos con la menor cantidad de par√°metros, evitando as√≠ el sobreajuste (overfitting).

La f√≥rmula general para calcular el AIC es:

$$AIC = 2k - 2\ln(L)$$

Donde:\
\* $k$ es el n√∫mero de par√°metros del modelo. En un modelo de regresi√≥n, esto incluye el intercepto y los coeficientes de las variables predictoras, m√°s la varianza del error si se estima (en modelos de m√≠nimos cuadrados ordinarios, esto es a menudo el caso, por lo que $k$ a veces se cuenta como el n√∫mero de coeficientes + 1 para la varianza del error, o simplemente el n√∫mero de coeficientes si la varianza del error se considera impl√≠cita en la funci√≥n de verosimilitud).\
\* $\ln(L)$ es el logaritmo natural del valor m√°ximo de la funci√≥n de verosimilitud (log-likelihood) del modelo. La funci√≥n de verosimilitud mide qu√© tan bien el modelo reproduce los datos observados.

#### C√≥mo se interpreta:

-   **Valores m√°s bajos de AIC indican un mejor modelo.** El AIC busca un equilibrio entre la bondad de ajuste del modelo a los datos (representada por $\ln(L)$) y la complejidad del modelo (representada por $2k$).\
-   El t√©rmino $2k$ es una **penalizaci√≥n por la complejidad**. Cada par√°metro adicional en el modelo aumenta el valor de AIC, lo que desincentiva la inclusi√≥n de variables innecesarias que podr√≠an sobreajustar los datos.

#### Para modelos de Regresi√≥n por M√≠nimos Cuadrados Ordinarios (OLS):

Aunque la f√≥rmula general del AIC es la que se mencion√≥, para modelos de OLS con residuos normalmente distribuidos, la funci√≥n de log-verosimilitud tiene una forma espec√≠fica, lo que permite reescribir el AIC de una manera m√°s pr√°ctica.

Para un modelo de regresi√≥n lineal con $n$ observaciones y $k$ par√°metros (incluyendo el intercepto), y asumiendo errores normales con varianza constante, el AIC se puede calcular como:

$$AIC = n \cdot \ln\left(\frac{RSS}{n}\right) + 2k$$

Donde:\
\* $n$ es el n√∫mero de observaciones (tama√±o de la muestra).\
\* $RSS$ es la Suma de Cuadrados de los Residuos (Residual Sum of Squares), que es la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo.\
\* $k$ es el n√∫mero de par√°metros del modelo (coeficientes de las variables independientes + intercepto).

**Es importante recordar:**

-   El AIC no es una prueba de hip√≥tesis en el sentido tradicional; no te dice si un modelo es "bueno" o "malo" en un sentido absoluto.\
-   Es una herramienta para la **selecci√≥n de modelos entre un conjunto de modelos candidatos**. Siempre se compara el AIC de diferentes modelos ajustados a los **mismos datos**. El modelo con el AIC m√°s bajo es el preferido.\
-   Cuando la muestra es peque√±a, a veces se prefiere el **AIC corregido (AICc)**, que a√±ade una penalizaci√≥n adicional por el tama√±o de la muestra:\
    $$AICc = AIC + \frac{2k(k+1)}{n-k-1}$$

A medida que $n$ (tama√±o de la muestra) es grande, el t√©rmino de correcci√≥n se vuelve insignificante y el AICc converge al AIC.

Se realiza una selecci√≥n autom√°tica de variables para un modelo de regresi√≥n lineal, utilizando el **criterio AIC (Criterio de Informaci√≥n de Akaike**)


**Implementaci√≥n de Selecci√≥n por Pasos (Stepwise) con AIC en Python**

Dado que `statsmodels` no tiene un `stepAIC` incorporado que funcione exactamente como en R con `direction="both"`, una forma com√∫n de lograr esto en Python es implementar la l√≥gica de forma manual o usar una funci√≥n auxiliar que la simule. 

```{python}
#| label: stepwise-aic
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
#| results: as-is # Para mostrar el resumen del modelo final

import pandas as pd
import statsmodels.formula.api as smf
# Aunque no lo vamos a importar directamente aqu√≠, el concepto de AIC
# est√° impl√≠cito en los resultados de summary() de statsmodels

# Asumiendo que X_train, y_train y train_data_combined
# (el DataFrame combinado para statsmodels) ya est√°n definidos
# desde los chunks anteriores.
# Y que modelo_ols_py ya fue ajustado.

def stepwise_selection_aic(data, target_variable, initial_features=None, verbose=True):
    """
    Realiza una selecci√≥n de caracter√≠sticas por pasos (forward y backward)
    basada en el Criterio de Informaci√≥n de Akaike (AIC).

    Args:
        data (pd.DataFrame): El DataFrame de entrenamiento combinado (X y y).
        target_variable (str): El nombre de la columna de la variable dependiente.
        initial_features (list): Lista opcional de caracter√≠sticas para empezar.
                                 Si es None, empieza con un modelo nulo o con todas.
        verbose (bool): Si es True, imprime los pasos del proceso.

    Returns:
        statsmodels.regression.linear_model.RegressionResultsWrapper: El modelo OLS final.
    """
    remaining_features = list(data.drop(columns=[target_variable]).columns)
    selected_features = [] if initial_features is None else initial_features

    current_score, best_new_score = float('inf'), float('inf')
    best_model = None
    iteration = 0

    if verbose:
        print("Iniciando selecci√≥n de modelo por pasos con AIC (direcci√≥n 'both')...")

    while True:
        iteration += 1
        model_changed = False
        if verbose:
            print(f"\n--- Iteraci√≥n {iteration} ---")
            print(f"Caracter√≠sticas seleccionadas actualmente: {selected_features}")

        # --- Paso hacia adelante (Forward Selection) ---
        aic_candidates_forward = {}
        if remaining_features: # Solo si hay caracter√≠sticas restantes para a√±adir
            if verbose: print("Considerando a√±adir caracter√≠sticas:")
            for feature in remaining_features:
                temp_features = selected_features + [feature]
                if not temp_features: # Asegura que al menos haya un Intercept si no hay features
                    formula = f"{target_variable} ~ 1" # Modelo solo con intercept
                else:
                    formula = f"{target_variable} ~ " + " + ".join(temp_features)
                
                try:
                    model = smf.ols(formula=formula, data=data).fit()
                    aic_candidates_forward[feature] = model.aic
                    if verbose: print(f"  A√±adiendo '{feature}': AIC = {model.aic:.2f}")
                except Exception as e:
                    if verbose: print(f"  Error al probar '{feature}': {e}")


        # --- Paso hacia atr√°s (Backward Elimination) ---
        aic_candidates_backward = {}
        if len(selected_features) > 0: # Solo si hay caracter√≠sticas para eliminar
            if verbose: print("Considerando eliminar caracter√≠sticas:")
            for feature in selected_features:
                temp_features = [f for f in selected_features if f != feature]
                if not temp_features: # Si eliminamos todo y solo queda el intercept
                    formula = f"{target_variable} ~ 1"
                else:
                    formula = f"{target_variable} ~ " + " + ".join(temp_features)
                
                try:
                    model = smf.ols(formula=formula, data=data).fit()
                    aic_candidates_backward[feature] = model.aic
                    if verbose: print(f"  Eliminando '{feature}': AIC = {model.aic:.2f}")
                except Exception as e:
                    if verbose: print(f"  Error al probar quitar '{feature}': {e}")


        best_aic_this_step = current_score
        feature_to_add = None
        feature_to_remove = None
        action = None # 'add' o 'remove'

        # Evaluar mejor movimiento: a√±adir o eliminar
        # Mejor a√±adir
        if aic_candidates_forward:
            min_aic_add_feature = min(aic_candidates_forward, key=aic_candidates_forward.get)
            min_aic_add_value = aic_candidates_forward[min_aic_add_feature]
            if min_aic_add_value < best_aic_this_step:
                best_aic_this_step = min_aic_add_value
                feature_to_add = min_aic_add_feature
                action = 'add'

        # Mejor eliminar
        if aic_candidates_backward:
            min_aic_remove_feature = min(aic_candidates_backward, key=aic_candidates_backward.get)
            min_aic_remove_value = aic_candidates_backward[min_aic_remove_feature]
            # Solo consideramos eliminar si esto mejora el AIC *actual* del modelo
            # y tambi√©n si es mejor que a√±adir
            if min_aic_remove_value < best_aic_this_step:
                best_aic_this_step = min_aic_remove_value
                feature_to_remove = min_aic_remove_feature
                action = 'remove'


        if best_aic_this_step < current_score:
            model_changed = True
            current_score = best_aic_this_step
            if action == 'add':
                selected_features.append(feature_to_add)
                remaining_features.remove(feature_to_add)
                if verbose: print(f"-> A√±adiendo: '{feature_to_add}'. Nuevo AIC: {current_score:.2f}")
            elif action == 'remove':
                remaining_features.append(feature_to_remove)
                selected_features.remove(feature_to_remove)
                if verbose: print(f"-> Eliminando: '{feature_to_remove}'. Nuevo AIC: {current_score:.2f}")
        else:
            # No hay mejoras en el AIC, detener el proceso
            if verbose: print("\nNo se encontr√≥ una mejora en el AIC. Deteniendo la selecci√≥n por pasos.")
            break

    # Ajustar el modelo final con las caracter√≠sticas seleccionadas
    if not selected_features:
        final_formula = f"{target_variable} ~ 1"
    else:
        final_formula = f"{target_variable} ~ " + " + ".join(selected_features)

    final_model = smf.ols(formula=final_formula, data=data).fit()
    return final_model

# --- Aplicar la selecci√≥n por pasos ---
# train_data_combined es el DataFrame que contiene X_train y y_train
# target_variable es el nombre de tu columna 'mpg'
modelo_step_py = stepwise_selection_aic(
    data=train_data_combined,
    target_variable='mpg',
    verbose=True
)

# Revisar resumen del modelo_step final
print("\n--- Resumen del Modelo OLS Despu√©s de la Selecci√≥n por Pasos (AIC) ---")
print(modelo_step_py.summary())
```

El procedimiento va eliminando o agregando variables al modelo original para reducir el **AIC (Criterio de Informaci√≥n de Akaike)**. El objetivo es encontrar un modelo m√°s **parsimonioso** (simple) con **buena capacidad predictiva**.

-   El proceso empieza con un modelo completo:\
    `mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb` y un AIC inicial, por ejemplo: `AIC = 57.77`.

-   Luego eval√∫a qu√© pasa si **quita** una variable (`- vs`, `- cyl`, etc.).

-   Si al eliminar una variable el AIC **baja**, se acepta ese cambio.\
    Ejemplo:\
    `- vs    1    2.1293  102.57  56.353`\
    Significa que si quitas la variable `vs`, el AIC baja de 57.77 a 56.35 ‚Üí ¬°mejor!

    -   Se acepta esa modificaci√≥n y se repite el procedimiento, ahora con el nuevo modelo.

-   Tambi√©n puede intentar **agregar** variables previamente eliminadas (`+ vs`, `+ hp`, etc.) si esto mejora el AIC.

-   Cuando **ya no puede bajar m√°s el AIC** quitando o agregando variables. El modelo final es el que **tiene el AIC m√°s bajo** alcanzado durante el proceso.



### Interpretaci√≥n Final
  
  | Aspecto                         | Modelo Completo | Modelo por AIC (reducido) |
  | ------------------------------- | --------------- | ------------------------- |
  | **R¬≤ ajustado**                 | 0.821           | 0.862 ‚úÖ                   |
  | **AIC**                         | 126.9           | **116.5 ‚úÖ**               |
  | **Coeficientes significativos** | Ninguno         | Todos ‚úÖ                   |
  | **Multicolinealidad**           | Alta ‚ö†Ô∏è         | Baja ‚úÖ                    |
  | **Interpretabilidad**           | Difusa          | Clara ‚úÖ                   |
  

**Conclusi√≥n del modelo reducido**:
  
  * Todas las variables son estad√≠sticamente significativas.
* El modelo es m√°s simple (3 variables vs. 10).
* El AIC baj√≥ significativamente ‚áí mejora en calidad del modelo.
* La interpretaci√≥n es mucho m√°s clara y robusta.


### Forward or backward stepwise

Los modelos "forward" (hacia adelante) y "backward" (hacia atr√°s) son dos enfoques comunes dentro de la **regresi√≥n stepwise (paso a paso)**, un m√©todo de selecci√≥n autom√°tica de variables para construir modelos de regresi√≥n. El objetivo de la regresi√≥n stepwise es encontrar un subconjunto √≥ptimo de variables predictoras que expliquen la mayor parte de la varianza en la variable dependiente con la menor complejidad posible, evitando el sobreajuste y mejorando la interpretabilidad del modelo.

Ambos m√©todos operan de manera iterativa, agregando o eliminando variables bas√°ndose en un criterio estad√≠stico (como el p-valor, AIC, BIC, etc.).

#### **Forward Selection** (Selecci√≥n Hacia Adelante)

La selecci√≥n hacia adelante comienza con un modelo "nulo", es decir, un modelo que no contiene ninguna variable predictora (solo el intercepto). Luego, en cada paso, eval√∫a todas las variables predictoras no incluidas en el modelo y agrega aquella que, al ser incluida, produce la mejora m√°s significativa en el ajuste del modelo. Este proceso contin√∫a hasta que ninguna de las variables restantes cumple con el criterio de entrada preestablecido (por ejemplo, su p-valor es mayor que un umbral determinado).

#### **Backward Elimination** (Eliminaci√≥n Hacia Atr√°s)

La eliminaci√≥n hacia atr√°s comienza con un modelo "completo", es decir, un modelo que incluye todas las variables predictoras candidatas. Luego, en cada paso, eval√∫a la contribuci√≥n de cada variable predictora en el modelo y elimina aquella que, al ser retirada, tiene el menor impacto negativo en el ajuste del modelo (o la que es menos significativa, por ejemplo, la que tiene el p-valor m√°s alto). Este proceso contin√∫a hasta que todas las variables restantes en el modelo cumplen con un criterio de permanencia preestablecido (por ejemplo, su p-valor es menor que un umbral determinado).

#### Consideraciones Generales sobre la Regresi√≥n Stepwise

Es importante mencionar que, aunque los m√©todos forward y backward son populares por su automatizaci√≥n, tambi√©n tienen sus **cr√≠ticas y desventajas**:

-   **Sobreajuste (Overfitting):** Los modelos resultantes pueden ajustarse muy bien a los datos de entrenamiento, pero no generalizar bien a nuevos datos. Esto se debe a que el proceso de selecci√≥n de variables se basa en los datos observados, lo que puede llevar a incluir variables que parecen importantes por puro azar en esa muestra particular.
-   **P-valores y Coeficientes Sesgados:** Los p-valores y los coeficientes de regresi√≥n obtenidos de un modelo stepwise pueden ser sesgados. Los p-valores tienden a ser m√°s peque√±os de lo que realmente son, lo que lleva a una falsa confianza en la significancia de las variables.
-   **No considera la teor√≠a:** El proceso es puramente estad√≠stico y no incorpora el conocimiento del dominio o la teor√≠a subyacente sobre las relaciones entre las variables. Un modelo estad√≠sticamente "√≥ptimo" podr√≠a carecer de sentido te√≥rico o pr√°ctico.
-   **Dependencia del orden:** La selecci√≥n de variables puede ser sensible al orden en que se a√±aden o eliminan, especialmente en la selecci√≥n hacia adelante.


**Selecci√≥n de Subconjuntos de Variables con `statsmodels` en Python**  

En Python, no hay una funci√≥n directa que replique `regsubsets` con todos sus m√©todos (exhaustiva, forward, backward, etc.) en una sola llamada como en R.  

Explicaci√≥n de la Funci√≥n Gen√©rica `regsubsets_exhaustive`:
  
1.  **Par√°metros de Entrada**:
  * `X_train_df`: El DataFrame de variables predictoras de entrenamiento.
* `y_train_series`: La Serie de la variable dependiente de entrenamiento. **Es crucial que `y_train_series` tenga un `.name` (e.g., `'mpg'`) asignado**, ya que `statsmodels` lo usa para construir la f√≥rmula. Si `y_train` no tiene un nombre, se puede asign√°r (`y_train.name = 'nombre_columna'`).
* `nvmax`: El n√∫mero m√°ximo de variables a considerar.
* `id_column`: Un nuevo par√°metro para especificar el nombre de cualquier columna que sea un identificador (como `'name'` o `'Unnamed: 0'`) y que **no debe usarse como predictor**.

2.  **`train_data_combined`**: Dentro de la funci√≥n, combinamos `X_train_df` y `y_train_series` en un solo DataFrame. Esto es lo que `statsmodels` espera para la funci√≥n `smf.ols` cuando se usa la sintaxis de f√≥rmula.

3.  **Exclusi√≥n de `id_column`**: La lista `all_predictors` ahora filtra la `id_column` proporcionada. Esto te da control sobre qu√© columnas del `X_train_df` son realmente predictores.

4.  **Almacenamiento de Objetos de Modelo**: A√±adimos un diccionario `model_objects` que guarda cada objeto de modelo ajustado (`model_objects[formula] = model`). Esto es muy √∫til porque si luego se decide que un modelo espec√≠fico (por ejemplo, el mejor AIC con 5 caracter√≠sticas) es el que se quiere, se puede recuperar el diccionario y acceder a su `.summary()`, `.predict()`, etc.

5.  **Retorno de Valores**: La funci√≥n devuelve un diccionario `best_models` (que contiene DataFrames para los mejores modelos por R-cuadrado ajustado, AIC y BIC) y el diccionario `all_model_objects`.


```{python}
#| label: regsubsets-generic-function
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
#| results: as-is # Para mostrar la tabla de resultados


import pandas as pd
import statsmodels.formula.api as smf
import itertools
import numpy as np

# --- Definici√≥n de la funci√≥n gen√©rica para regsubsets (exhaustive) ---
def regsubsets_exhaustive(X_train_df, y_train_series, nvmax=None, id_column=None):
    """
    Realiza una b√∫squeda exhaustiva de los mejores subconjuntos de variables
    para un modelo de regresi√≥n lineal, similar a regsubsets en R.

    Args:
        X_train_df (pd.DataFrame): DataFrame con las variables predictoras del conjunto de entrenamiento.
        y_train_series (pd.Series): Serie con la variable dependiente del conjunto de entrenamiento.
        nvmax (int, optional): N√∫mero m√°ximo de variables a considerar en los subconjuntos.
                               Si es None, se usa el n√∫mero total de predictores.
        id_column (str, optional): Nombre de una columna en X_train_df que es un identificador
                                   (como 'name' o 'Unnamed: 0') y debe excluirse de los predictores.

    Returns:
        pd.DataFrame: Un DataFrame con los mejores modelos para cada n√∫mero de caracter√≠sticas,
                      ordenados por R-cuadrado ajustado, AIC y BIC.
        dict: Un diccionario de los objetos de modelo ajustados para referencia,
              con la f√≥rmula como clave.
    """
    # Combine X_train and y_train into a single DataFrame for statsmodels
    train_data_combined = pd.concat([X_train_df, y_train_series], axis=1)
    
    # Ensure y_train_series.name is not None
    target_variable_name = y_train_series.name
    if target_variable_name is None:
        raise ValueError("The 'y_train_series' Series must have a name assigned (e.g., y_train.name = 'mpg')")
    
    # Define available predictor variables, excluding the ID column if provided
    all_predictors = [col for col in X_train_df.columns if col != id_column]
    
    # Limit nvmax if it's greater than the actual number of predictors
    if nvmax is None:
        nvmax_final = len(all_predictors)
    else:
        nvmax_final = min(nvmax, len(all_predictors))

    results = []
    model_objects = {}
    
    print(f"Starting exhaustive subset search up to {nvmax_final} variables...")

    for k in range(1, nvmax_final + 1):
        for subset_features_tuple in itertools.combinations(all_predictors, k):
            subset_features = list(subset_features_tuple)

            if not subset_features:
                formula = f"{target_variable_name} ~ 1"
            else:
                formula = f"{target_variable_name} ~ " + " + ".join(subset_features)
            
            try:
                model = smf.ols(formula=formula, data=train_data_combined).fit()
                
                results.append({
                    'n_features': k,
                    'features': " + ".join(subset_features),
                    'adj_r_squared': model.rsquared_adj,
                    'aic': model.aic,
                    'bic': model.bic,
                    'formula': formula
                })
                model_objects[formula] = model

            except Exception as e:
                # We'll just print a warning for failed models, not a full debug trace
                print(f"Warning: Error fitting model with formula '{formula}': {e}")

    results_df = pd.DataFrame(results)

    if results_df.empty:
        print("No valid models could be fitted.")
        return pd.DataFrame(), {}

    best_models = {}
    for metric in ['adj_r_squared', 'aic', 'bic']:
        if metric == 'adj_r_squared':
            idx = results_df.groupby('n_features')[metric].idxmax()
        else:
            idx = results_df.groupby('n_features')[metric].idxmin()
        
        if not idx.empty:
            best_models[metric] = results_df.loc[idx].set_index('n_features')
        else:
            best_models[metric] = pd.DataFrame(columns=results_df.columns).set_index('n_features')

    return best_models, model_objects

```


```{python}
#| echo: true
#| message: false
#| warning: false
#| results: as-is # Para mostrar la tabla de resultados

# This line is crucial and should be present in your actual script
# to ensure y_train has a name.
if y_train.name is None:
    y_train.name = 'mpg'

print("--- Running exhaustive subset selection ---")
best_models_results, all_model_objects = regsubsets_exhaustive(
                                                                X_train_df=X_train,
                                                                y_train_series=y_train,
                                                                nvmax=10,
                                                                id_column='Unnamed: 0'
)

# --- Displaying only the final summary ---
print("\n--- Summary of the best global model by AIC ---")

if not best_models_results['aic'].empty:
    # Find the row with the globally lowest AIC across all feature counts
    # We combine all results and then find the minimum AIC
    all_results_df_for_global = pd.concat([best_models_results['aic'], 
                                           best_models_results['bic'], 
                                           best_models_results['adj_r_squared']]).drop_duplicates(subset=['formula'])

    if 'formula' in all_results_df_for_global.columns and 'aic' in all_results_df_for_global.columns:
        global_best_aic_row = all_results_df_for_global.loc[all_results_df_for_global['aic'].idxmin()]
        global_best_aic_formula = global_best_aic_row['formula']
        
        print(f"Model with lowest global AIC: {global_best_aic_formula}")
        
        # Now, print the full statsmodels summary for this specific model
        if global_best_aic_formula in all_model_objects:
            print(all_model_objects[global_best_aic_formula].summary())
        else:
            print("Error: The object for the best global AIC model was not found in 'all_model_objects'.")
    else:
        print("Error: 'formula' or 'aic' columns not found in combined results for global best model.")
else:
    print("No valid models were found for subset selection. Cannot display global best model.")
```
`Selection Algorithm: exhaustive` **: Esto es crucial. Significa que el algoritmo prob√≥ todas las combinaciones posibles** de variables para cada tama√±o de subconjunto hasta `nvmax = 10` y seleccion√≥ el mejor para cada tama√±o. Esto asegura que, para cada n√∫mero de variables (1, 2, ..., 10), el modelo presentado es el √≥ptimo seg√∫n el criterio interno de `regsubsets_exhaustive` (generalmente `AIC`, $R^2$ ajustado, BIC a menos que se especifique otro en la funci√≥n).  


```{python}
#| echo: true
#| message: false
#| warning: false
#| results: as-is
#| code-fold: true

import matplotlib.pyplot as plt

### Extracci√≥n de los datos de R2 Ajustado
#La informaci√≥n ya est√° en `best_models_results['adj_r_squared']`. Para obtenerla en un formato de DataFrame con columnas expl√≠citas para el n√∫mero de variables y el R2 ajustado, simplemente hacemos:

# Obtener el DataFrame de los mejores R2 Ajustados por n√∫mero de variables
adjr2_data_df = best_models_results['adj_r_squared'].reset_index()

# Renombrar columnas para mayor claridad
adjr2_data_df.rename(columns={'n_features': 'Numero_de_Variables', 
                              'adj_r_squared': 'R2_Ajustado'}, inplace=True)

print("--- DataFrame con R2 Ajustado por N√∫mero de Variables ---")
print(adjr2_data_df[['Numero_de_Variables', 'R2_Ajustado']].to_string(index=False))

if not adjr2_data_df.empty:
    plt.figure(figsize = (8, 5)) # Tama√±o de la figura m√°s compacto
    
    # Graficar l√≠nea y puntos
    plt.plot(adjr2_data_df['Numero_de_Variables'], adjr2_data_df['R2_Ajustado'], 
             marker = 'o', linestyle = '-', color = 'skyblue')

    # Encontrar el punto de R2 ajustado m√°ximo
    max_adjr2_row = adjr2_data_df.loc[adjr2_data_df['R2_Ajustado'].idxmax()]
    best_num_vars = int(max_adjr2_row['Numero_de_Variables'])
    max_adjr2_value = max_adjr2_row['R2_Ajustado']

    # Resaltar el punto m√°ximo
    plt.plot(best_num_vars, max_adjr2_value, 'ro', markersize = 8) # Punto rojo grande
    plt.axvline(x = best_num_vars, color = 'red', linestyle= '--', linewidth = 1, alpha = 0.7) # L√≠nea vertical

    # Etiquetas y t√≠tulo
    plt.title("R2 Ajustado vs. N√∫mero de Variables")
    plt.xlabel("N√∫mero de Variables")
    plt.ylabel("R2 Ajustado")
    
    # Asegurar que los ticks del eje X sean enteros y legibles
    plt.xticks(range(1, max(adjr2_data_df['Numero_de_Variables']) + 1))
    
    plt.grid(True, linestyle = ':', alpha = 0.6) # Cuadr√≠cula ligera
    plt.tight_layout()
    plt.show()
else:
    print("No hay datos para generar el gr√°fico de R2 Ajustado.")
```
*## Evaluaci√≥n del modelo

Ahora se va a trabajar con un **modelo reducido (`modelo_step`)**, es importante **usar ese modelo** para hacer predicciones en el conjunto de prueba. Adem√°s, como solo algunas variables quedaron en el modelo (`drat`, `wt`, `gear`, `carb`), el `test_data` debe contener esas columnas.

**Verificar qu√© variables necesita el modelo reducido**

```{python}
global_best_aic_row = all_results_df_for_global.loc[all_results_df_for_global['aic'].idxmin()]
global_best_aic_formula = global_best_aic_row['formula']
global_best_aic_formula
```

### Variance Inflation Factor (`VIF`)

El **Factor de Inflaci√≥n de la Varianza (VIF)** es una herramienta estad√≠stica fundamental utilizada para **detectar y cuantificar la multicolinealidad** en modelos de regresi√≥n lineal m√∫ltiple.

**Problemas que causa la multicolinealidad:**

-   **Coeficientes de regresi√≥n inestables y dif√≠ciles de interpretar:** Cuando las variables predictoras est√°n altamente correlacionadas, es dif√≠cil para el modelo determinar la contribuci√≥n √∫nica de cada variable a la variable dependiente. Peque√±os cambios en los datos pueden llevar a grandes cambios en los coeficientes estimados, haciendo que sean poco fiables.
-   **Errores est√°ndar inflados:** La multicolinealidad aumenta los errores est√°ndar de los coeficientes de regresi√≥n, lo que a su vez disminuye los valores de las estad√≠sticas t y aumenta los p-valores. Esto puede llevar a la conclusi√≥n err√≥nea de que una variable no es estad√≠sticamente significativa cuando en realidad s√≠ lo es.
-   **Poder predictivo reducido:** Aunque la multicolinealidad no necesariamente afecta la capacidad predictiva global del modelo (el $R^2$ ajustado puede seguir siendo alto), s√≠ afecta la precisi√≥n de las estimaciones de los coeficientes individuales, lo que hace dif√≠cil comprender la relaci√≥n real entre cada predictor y la variable de respuesta.

El VIF mide **cu√°nto se "infla" la varianza del coeficiente de regresi√≥n estimado de una variable predictora debido a su correlaci√≥n con otras variables predictoras** en el modelo.

**La f√≥rmula del VIF para una variable** $X_j$ es:

$$VIF_j = \frac{1}{1 - R_j^2}$$

Donde $R_j^2$ es el coeficiente de determinaci√≥n ($R^2$) de una regresi√≥n auxiliar en la que la variable $X_j$ se predice utilizando todas las dem√°s variables independientes del modelo.

#### ¬øC√≥mo se interpreta el VIF?

-   **VIF = 1:** Indica que la variable predictora no est√° correlacionada con ninguna de las otras variables predictoras en el modelo. No hay multicolinealidad.
-   **VIF \> 1:** Indica que existe alg√∫n grado de multicolinealidad. Cuanto mayor sea el valor del VIF, mayor es el grado de multicolinealidad.

**Reglas generales para interpretar los valores de VIF (son reglas de "pulgar" y pueden variar ligeramente seg√∫n el contexto y el campo de estudio):**

-   **VIF ‚â§ 5:** Generalmente se considera que no hay problemas graves de multicolinealidad.
-   **5 \< VIF ‚â§ 10:** Puede indicar un nivel moderado a alto de multicolinealidad que podr√≠a justificar una investigaci√≥n.
-   **VIF \> 10:** A menudo se considera una indicaci√≥n clara de multicolinealidad grave y problem√°tica. Es un umbral com√∫nmente aceptado para se√±alar que una variable est√° fuertemente correlacionada con otras, lo que podr√≠a afectar la estabilidad y fiabilidad del modelo.

**Regla pr√°ctica para interpretar VIF:**    

| VIF  | Interpretaci√≥n                                   |
  | ---- | ------------------------------------------------ |
  | 1    | Sin colinealidad                                 |
  | 1‚Äì5  | Colinealidad baja / aceptable                    |
  | 5‚Äì10 | Colinealidad moderada a alta (requiere atenci√≥n) |
  | > 10 | ‚ö†Ô∏è **Colinealidad severa** (problema serio)      |
  

```{python}
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant # Necesario para a√±adir la constante si tu modelo la usa

# --- C√°lculo del VIF en Python ---

# --- Important: Remove 'Unnamed: 0' if it exists in X_train ---
if 'Unnamed: 0' in X_train.columns:
    X_train_cleaned = X_train.drop(columns=['Unnamed: 0'])
else:
    X_train_cleaned = X_train.copy() # Use .copy() to avoid SettingWithCopyWarning

# Es crucial a√±adir una constante (intercepto) a las variables predictoras
# si tu modelo OLS incluye un intercepto (que es lo com√∫n con smf.ols por defecto).
# El 'add_constant' de statsmodels se encarga de esto.
X_with_constant = add_constant(X_train_cleaned)

# Calcular el VIF para cada variable predictora
vif_data = pd.DataFrame()
vif_data["feature"] = X_with_constant.columns
vif_data["VIF"] = [variance_inflation_factor(X_with_constant.values, i)
                   for i in range(X_with_constant.shape[1])]


# Se ordenan los resultados para ver las variables con mayor VIF primero
print("\nFactor de Inflaci√≥n de la Varianza (VIF) ordenado:")
print(vif_data.sort_values(by="VIF", ascending=False))
```

* **Pr√°cticamente todas las variables (excepto `drat`) tienen VIF > 10**, lo cual indica **multicolinealidad severa**.
* Esto **explica por qu√© en el modelo original ninguno de los coeficientes era significativo**, a pesar del R¬≤ alto.
* Multicolinealidad **infla los errores est√°ndar** de los coeficientes y los hace **menos confiables**, incluso si el modelo global es significativo.


## Evaluaci√≥n del modelo

La partici√≥n de los datos en `X_train`, `X_test`, `y_train`, y `y_test` se hace una sola vez al principio de tu an√°lisis para asegurar que la evaluaci√≥n final del modelo (con `X_test` y `y_test`) sea imparcial.


Una vez que tienes la f√≥rmula del modelo √≥ptimo se selecciona (`'mpg ~ wt + qsec + am'`), lo que haces es **re-entrenar el modelo con esta nueva f√≥rmula utilizando √∫nicamente los datos de entrenamiento (`X_train` y `y_train`)**.

```{python}
import pandas as pd
import statsmodels.formula.api as smf

# X_train y y_train ya han sido definidos y que provienen de la partici√≥n original de los datos.
# Tambi√©n asumiendo que y_train.name ya fue asignado a 'mpg'.

# 1. Se define la f√≥rmula del modelo con las variables seleccionadas
selected_formula = 'mpg ~ wt + qsec + am'

# 2. Se prepara el DataFrame de entrenamiento solo con las variables seleccionadas

# Primero, se identifica las columnas predictoras de la f√≥rmula (wt, qsec, am)
predictors_in_selected_formula = ['wt', 'qsec', 'am'] # Se extraen estas de la f√≥rmula si es din√°mica

# Asegurarse de que estas columnas existen en X_train antes de seleccionarlas
# Si 'Unnamed: 0' fue un problema, aseg√∫rate de haberlo quitado de X_train previamente.
# --- Important: Remove 'Unnamed: 0' if it exists in X_train ---
if 'Unnamed: 0' in X_train.columns:
    X_train_cleaned = X_train.drop(columns=['Unnamed: 0'])
else:
    X_train_cleaned = X_train.copy() # Use .copy() to avoid SettingWithCopyWarning
    
# Para este ejemplo, asumiremos que X_train ya es X_train_cleaned si usaste ese paso.
X_train_selected = X_train[predictors_in_selected_formula]

# Se combina el X_train_selected y y_train en un solo DataFrame
# Esto es necesario para statsmodels.formula.api.ols
train_data_selected_model = pd.concat([X_train_selected, y_train], axis = 1)

# 3. Se entrena el modelo OLS con la f√≥rmula y los datos reducidos
print(f"--- Entrenando el modelo final con la f√≥rmula: {selected_formula} ---")
final_modelo_ols_py = smf.ols(formula = selected_formula, 
                              data = train_data_selected_model).fit()

# 4. Revisa el resumen del modelo final
print("\nResumen del Modelo OLS Final (Variables Seleccionadas):")
print(final_modelo_ols_py.summary())
```

### Modelo predictivo

Con la funci√≥n **`predict()`** gen√©rica en R que se utiliza para obtener predicciones de varios tipos de objetos de modelos (lineales, √°rboles de decisi√≥n, series de tiempo, etc.). Su comportamiento exacto depende de la clase del objeto que se le pasa como primer argumento.

Esta operaci√≥n es un paso clave en el flujo de trabajo de modelado predictivo, ya que permite:

1.  **Evaluaci√≥n del modelo:** Una vez que se tienen las `predicciones` para el `test_data`, se puede compararlas con los valores reales (observados) de la variable dependiente en el `test_data` (si se tienen) para **evaluar qu√© tan bien se desempe√±a el modelo** en datos no vistos. Esto ayuda a estimar su rendimiento en el mundo real y a detectar problemas como el **sobreajuste (overfitting)**.

2.  **Uso pr√°ctico del modelo:** Despu√©s de validar que el modelo es bueno, se puede usarlo para predecir la variable dependiente para nuevas observaciones futuras de las que solo se conocen las variables predictoras (por ejemplo, predecir el precio de una casa bas√°ndose en sus caracter√≠sticas, si el modelo fue entrenado para eso).


El objeto `final_modelo_ols_py` (que es un objeto de tipo `statsmodels.regression.linear_model.RegressionResultsWrapper`) tiene un m√©todo `.predict()` que hace exactamente esto.


```{python}
# 5. Para el modelo en los datos de prueba
# En R, usas 'newdata = test_data_reducido'. En Python, pasas el DataFrame
# con las mismas columnas predictoras que el modelo fue entrenado con.

# Identificar las variables predictoras del modelo final
# Se pueden obtener directamente de la f√≥rmula o recordarlas:
# Por ejemplo, para 'mpg ~ wt + qsec + am', las predictoras son 'wt', 'qsec', 'am'
predictors_final_model = ['wt', 'qsec', 'am']

# Se crea un dataFrame de datos de prueba con solo las columnas necesarias para la predicci√≥n
# Es crucial que X_test_reducido tenga las mismas columnas y en el mismo orden (aunque el orden no suele ser tan estricto
# si usas DataFrames con nombres de columnas, es buena pr√°ctica) que X_train_selected.
X_test_reducido = X_test[predictors_final_model]

# Calcular las predicciones
predicciones_py = final_modelo_ols_py.predict(X_test_reducido)

print("\nPredicciones del modelo en los datos de prueba:")
print(predicciones_py)

# Opcional: Si quieres comparar las predicciones con los valores reales de y_test
print("\nValores reales de mpg en el conjunto de prueba:")
print(y_test)
```

### Evaluar el desempe√±o predictivo

#### Mean Absolute Error (`MAE`)

El **MAE (Mean Absolute Error)**, o **Error Absoluto Medio** en espa√±ol, es una de las m√©tricas m√°s utilizadas para evaluar la precisi√≥n de un modelo de regresi√≥n. Mide la **magnitud promedio de los errores** entre los valores predichos por un modelo y los valores reales observados.

##### F√≥rmula del MAE

La f√≥rmula para calcular el MAE es la siguiente:

$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

Donde:

-   $n$: Es el n√∫mero total de observaciones (o puntos de datos) en el conjunto de datos.
-   $y_i$: Es el **valor real u observado** de la variable dependiente para la observaci√≥n $i$.
-   $\hat{y}_i$: Es el **valor predicho** por el modelo para la observaci√≥n $i$.
-   $|y_i - \hat{y}_i|$: Es el **valor absoluto** de la diferencia entre el valor real y el valor predicho para la observaci√≥n $i$. Tomar el valor absoluto es crucial porque evita que los errores positivos y negativos se cancelen entre s√≠, lo que dar√≠a una falsa impresi√≥n de precisi√≥n.
-   $\sum_{i=1}^{n}$: Indica la suma de todos los errores absolutos para todas las $n$ observaciones.


```{python}
# Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# C√°lculo del MAE (Mean Absolute Error)
mae = mean_absolute_error(y_test, predicciones_py)

print(f"MAE en conjunto de prueba: {mae:.4f}")
```

Esto significa que, **en promedio**, el modelo reducido predice el consumo de combustible con un error de ¬±3.10 mpg. Esto es bueno o malo. Depende del rango de la variable `mpg` en `mtcars`.

```{python}
import pandas as pd

# Calcular el rango (m√≠nimo y m√°ximo) de la columna 'mpg'
min_mpg = mtcars_df['mpg'].min()
max_mpg = mtcars_df['mpg'].max()

# Imprimir el resultado
print(f"Rango de mpg (m√≠nimo, m√°ximo): ({min_mpg}, {max_mpg})")
```

El rango de `mpg` es de **10.4 a 33.9**, es decir, abarca **\~23.5 unidades**.

Por tanto:

```         
  * Un MAE de **3.10** representa alrededor de un **15% del rango total**. El modelo, en promedio, se equivoca por 3.10 millas por gal√≥n en sus predicciones.  
* No es un error enorme, pero **tampoco es excelente**.  
* Si el modelo completo (`modelo_ols`) ten√≠a un MAE menor, podr√≠a predecir mejor, aunque con m√°s colinealidad.
```

#### Root Mean Squared Error (`RMSE`)

El **RMSE (Root Mean Squared Error)**, o **Ra√≠z del Error Cuadr√°tico Medio**, es una de las m√©tricas m√°s comunes y ampliamente utilizadas para evaluar la precisi√≥n de los modelos de regresi√≥n. Mide la **magnitud promedio de los errores** entre los valores predichos por un modelo y los valores reales observados, pero dando **mayor peso a los errores m√°s grandes**.

#### F√≥rmula del RMSE

$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

Donde:

-   $n$: Es el n√∫mero total de observaciones (o puntos de datos).\
-   $y_i$: Es el **valor real u observado** de la variable dependiente para la observaci√≥n $i$.\
-   $\hat{y}_i$: Es el **valor predicho** por el modelo para la observaci√≥n $i$.\
-   $(y_i - \hat{y}_i)^2$: Es el **cuadrado de la diferencia** entre el valor real y el valor predicho para la observaci√≥n $i$.

Elevar al cuadrado las diferencias tiene dos prop√≥sitos principales:

-   Eliminar los signos negativos: Asegura que los errores positivos y negativos no se cancelen entre s√≠.\
-   Penalizar m√°s los errores grandes: Los errores m√°s grandes tienen un impacto desproporcionadamente mayor en el resultado final del RMSE que los errores peque√±os, debido a la operaci√≥n al cuadrado.\
-   $\sum_{i=1}^{n}$: Indica la suma de todos los errores al cuadrado para todas las $n$ observaciones.

##### Interpretaci√≥n del RMSE:

-   El RMSE se expresa en las **mismas unidades que la variable dependiente original**. Esto facilita su interpretaci√≥n. Por ejemplo, si est√°s prediciendo la altura en metros y el RMSE es 0.5, significa que, en promedio, las predicciones del modelo se desv√≠an aproximadamente 0.5 metros de la altura real.\
-   **Un RMSE de 0 (cero) indica un modelo perfecto**, donde todas las predicciones son exactamente iguales a los valores reales.
-   **Valores m√°s bajos de RMSE indican un mejor rendimiento del modelo.**
    -   **Sensibilidad a valores at√≠picos:** Debido al t√©rmino al cuadrado, el RMSE penaliza m√°s fuertemente los errores grandes (valores at√≠picos) que el MAE. Esto significa que si tu modelo tiene algunos errores de predicci√≥n muy grandes, el RMSE ser√° significativamente m√°s alto que el MAE. Esta caracter√≠stica puede ser una ventaja o desventaja dependiendo del contexto:\
    -   **Ventaja:** Si los errores grandes son particularmente indeseables en tu aplicaci√≥n, el RMSE es una buena m√©trica porque los destaca.\
-   **Desventaja:** Si tu conjunto de datos contiene muchos valores at√≠picos reales o errores de medici√≥n que no son representativos del rendimiento general del modelo, el RMSE podr√≠a dar una visi√≥n pesimista.


```{python}
# Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# C√°lculo del RMSE (Root Mean Squared Error)
rmse = np.sqrt(mean_squared_error(y_test, predicciones_py))

print(f"\nRMSE en conjunto de prueba: {rmse:.4f}")
```

-   Un RMSE de **3.4120** significa que, en promedio, las predicciones difieren de los valores reales por **¬±3.41 millas por gal√≥n**.
    -   Como **los errores grandes tienen m√°s peso** (al ser elevados al cuadrado), el RMSE ser√° siempre **igual o mayor al MAE**. Penaliza m√°s los errores grandes que el MAE.
    -   Es **aceptable para predicci√≥n en `mtcars`**, pero con espacio para mejora si se requiere mayor precisi√≥n.

**Compararlo con el MAE**

-   Si **RMSE est√° mucho m√°s alto que el MAE**, el modelo est√° cometiendo **errores grandes con frecuencia** (outliers, mala especificaci√≥n).\
-   Si **RMSE ‚âà MAE**, los errores est√°n bien distribuidos.

#### Coeficiente de determinaci√≥n $R^2$

$R^{2}$ (**coeficiente de determinaci√≥n**) mide qu√© proporci√≥n de la variabilidad de la **variable dependiente** es explicada por el modelo.

La f√≥rmula general del $R^2$ (coeficiente de determinaci√≥n) es:

$$R^2 = 1 - \frac{SSE}{SST}$$

Donde:

-   $SSE$ (Sum of Squared Errors) o $RSS$ (Residual Sum of Squares): Es la **Suma de Cuadrados de los Errores** (o Suma de Cuadrados de los Residuos). Mide la variaci√≥n no explicada por el modelo. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados ($y_i$) y los valores predichos por el modelo ($\hat{y}_i$):

$$SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

-   $SST$ (Total Sum of Squares): Es la **Suma Total de Cuadrados**. Mide la variaci√≥n total de la variable dependiente respecto a su media. Representa la variabilidad total en los datos que el modelo intenta explicar. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados ($y_i$) y la media de la variable dependiente ($\bar{y}$):

$$SST = \sum_{i=1}^{n} (y_i - \bar{y})^2$$

##### Interpretaci√≥n del $R^2$:

-   El $R^2$ es una m√©trica que var√≠a entre **0 y 1** (o 0% y 100%).\
-   $R^2 = 0$: Indica que el modelo no explica ninguna de la variabilidad en la variable dependiente. Es tan bueno como simplemente usar la media de la variable dependiente para la predicci√≥n.\
-   $R^2 = 1$: Indica que el modelo explica el 100% de la variabilidad en la variable dependiente. Esto rara vez ocurre en la pr√°ctica con datos del mundo real, y a menudo sugiere sobreajuste si sucede en un conjunto de entrenamiento.\
-   **Valores m√°s altos de** $R^2$ indican un mejor ajuste del modelo a los datos observados, lo que significa que las variables predictoras del modelo explican una mayor proporci√≥n de la variabilidad en la variable dependiente.


```{python}
# Para evaluar el rendimiento del modelo (Ej: RMSE, MAE, R^2 en test)
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

r_squared_test = r2_score(y_test, predicciones_py)

print(f"R-squared en conjunto de prueba: {r_squared_test:.4f}")
```


-   Esto significa que el **65.3% de la variabilidad** de `mpg` (consumo de combustible) en los datos de prueba **es explicada por el modelo**.
    -   El **34.6% restante** es **variabilidad no explicada** (error, factores no incluidos, ruido).\
    -   El modelo predice **m√°s de la mitad de la variabilidad de `mpg`** en los datos de prueba.   
    
    
#### Distribuci√≥n de los residuos

Relaci√≥n lineal entre variable dependiente e independiente:

Se calculan los residuos para cada observaci√≥n y se representan (`scatterplot`). Si las observaciones siguen la l√≠nea del modelo, los residuos se deben distribuir aleatoriamente entorno al valor 0.


```{python}
#| echo: true
#| message: false
#| warning: false
#| results: as-is
#| code-fold: true

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf

# 1. Se crea un dataframe 'tabla' con fitted.values y residuals
# En statsmodels, los valores ajustados se obtienen con .fittedvalues y los residuos con .resid
tabla_py = pd.DataFrame({
                         'prediccion': final_modelo_ols_py.fittedvalues,
                         'residuo': final_modelo_ols_py.resid
})

# 2. Configuraci√≥n de los estilos para el gr√°fico (similar a theme_bw y los ajustes de texto de ggplot2)
# Configura el estilo de seaborn
sns.set_style("whitegrid") # Similar a theme_bw() o theme_minimal()

# Se configura la fuente globalmente en Montserrat
plt.rcParams['font.family'] = 'Montserrat' # Descomenta si tienes la fuente instalada

# Se crea la figura y los ejes
plt.figure(figsize = (10, 6)) # Tama√±o de la figura

# 3. Se crea el gr√°fico de dispersi√≥n con Seaborn
# Se usa scatterplot para los puntos y controlamos el color con 'hue'
# Se usa palette para la escala de colores, similar a scale_color_gradient2
scatterplot = sns.scatterplot(
                              data = tabla_py,
                              x = 'prediccion',
                              y = 'residuo',
                              hue = 'residuo', # Colorear por el valor del residuo
                              palette = 'RdBu_r', # 'RdBu_r' es una paleta divergente (rojo-azul, invertida para azul-rojo)
                                                # 'coolwarm' tambi√©n es una buena opci√≥n divergente.
                              legend = False,     # No mostrar leyenda de color, similar a legend.position = "none"
                              s = 70,             # Tama√±o de los puntos
                              alpha = 0.8         # Transparencia
)

# 4.Se a√±ade la l√≠nea horizontal en y=0
plt.axhline(y = 0, color = 'black', linestyle = '-', linewidth = 1)

# 5. Se a√±aden los segmentos desde los puntos hasta y = 0
# Se puede hacer iterando o usando una funci√≥n de matplotlib si fuera posible vectorizarlo
# Para simplicidad y control, iteramos aqu√≠. Ojo: para muchos puntos, esto puede ser lento.
# Para muchos puntos, podr√≠as considerar alternativas o quitarlo si no es cr√≠tico para la interpretaci√≥n.

for i in range(len(tabla_py)):
    x_val = tabla_py['prediccion'].iloc[i]
    y_val = tabla_py['residuo'].iloc[i]
    plt.plot([x_val, x_val], [y_val, 0], color='gray', linestyle='-', linewidth = 0.5, alpha = 0.2)


# 6. Se configuran las etiquetas y t√≠tulo
plt.title("Distribuci√≥n de los residuos", fontsize = 18, loc = 'left', fontweight = 'bold')
plt.xlabel("predicci√≥n modelo", fontsize = 14)
plt.ylabel("residuo", fontsize = 14)

# Ajustes de los ticks y etiquetas de los ejes
plt.tick_params(axis = 'x', labelsize = 12)
plt.tick_params(axis  ='y', labelsize = 12)


# Ajustar los l√≠mites del eje y si es necesario para evitar que los puntos se corten
# plt.ylim(min(tabla_py['residuo']) * 1.1, max(tabla_py['residuo']) * 1.1)

# Mostrar el gr√°fico
plt.tight_layout() # Ajusta el dise√±o para que no se corten etiquetas
plt.show()
```


Los residuos se deben distribuir de forma normal con media 0. Para comprobarlo se recurre a histogramas, a los cuantiles normales o a un test de contraste de normalidad.

```{python}
#| echo: true
#| message: false
#| warning: false
#| results: as-is
#| code-fold: true

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf


# Se crea un DataFrame'tabla_py' con los residuos
# En statsmodels, los residuos se obtienen con .resid
tabla_py = pd.DataFrame({
                         'residuo': final_modelo_ols_py.resid
})

# 1. Se confifuran los estilos para el gr√°fico
sns.set_style("whitegrid") # Similar a theme_light() en R, que da un fondo blanco con rejillas

# Opcional: Se confifura  la fuente globalmente si se tiene disponible (ej. 'Montserrat')
plt.rcParams['font.family'] = 'Montserrat'
plt.rcParams['axes.labelweight'] = 'bold' # Para hacer las etiquetas de los ejes en negrita si deseas
plt.rcParams['font.size'] = 12 # Tama√±o de fuente base

# Se crea la figura y los ejes
plt.figure(figsize = (10, 6)) # Tama√±o de la figura

# 2. Se crea el histograma con Seaborn
# 'kde=False' asegura que sea solo un histograma (sin la curva de densidad suavizada)
# 'stat="density"' es el equivalente de 'aes(y = ..density..)' de ggplot2
sns.histplot(
             data = tabla_py,
             x = 'residuo',
             bins = 'auto', # 'auto' para que Seaborn determine un n√∫mero de bins apropiado
             color = '#C70039', # Color de las barras del histograma
             edgecolor = '#900C3F', # Borde de las barras
             stat = "density" # Importante: normaliza la altura de las barras para que sumen 1 (densidad)
)

# 3. Configurar etiquetas y t√≠tulo
plt.title("Histograma de los residuos", fontsize = 18, loc = 'left', fontweight = 'bold')
plt.xlabel("Residuo", fontsize = 14)
plt.ylabel("Densidad", fontsize = 14) # Cambiamos a Densidad porque usamos stat="density"

# Ajustes de los ticks y etiquetas de los ejes
plt.tick_params(axis='x', labelsize = 12)
plt.tick_params(axis='y', labelsize = 12)

# Se quita la leyenda (aunque histplot no suele generarla si solo hay una variable)
# plt.legend().remove() # Descomenta si por alguna raz√≥n aparece una leyenda

# 4. Resultado
plt.tight_layout() # Ajusta el dise√±o para que no se corten etiquetas
plt.show()
```

#### Q-Q Plot

Los gr√°ficos Q-Q normales son esenciales para verificar uno de los supuestos clave en la regresi√≥n lineal: la **normalidad de los residuos**. Si los residuos siguen una distribuci√≥n normal, los puntos en el gr√°fico Q-Q deben caer aproximadamente a lo largo de una l√≠nea recta.

```{python}
#| echo: true
#| message: false
#| warning: false
#| results: as-is
#| code-fold: true

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm # Importa statsmodels.api para qqplot

# Residuos del modelo
residuos_py = final_modelo_ols_py.resid

# 1. Se crea el Gr√°fico Q-Q Normal
# sm.qqplot autom√°ticamente calcula los cuantiles te√≥ricos y observados
# y dibuja la l√≠nea de referencia.
# 'line="45"' dibuja la l√≠nea y=x (pendiente 1, intercepto 0)
fig = sm.qqplot(residuos_py, 
                line = '45', 
                fit = True, 
                plot_type = 'qq', 
                ax = None) # 'ax=None' crea una nueva figura por defecto

# Si se necesita una personalizaci√≥n m√°s profunda o el objeto Axis, se puede hacer esto:
fig, ax = plt.subplots(figsize = (8, 6)) # Se crea una figura y ejes expl√≠citamente
sm.qqplot(residuos_py, line='45', fit = True, ax = ax)

# 2. Se configuran los estilos y se personaliza el gr√°fico
# Puedes establecer un estilo global de Seaborn para que el fondo sea similar a theme_minimal
sns.set_style("whitegrid") # O "white", "dark", "darkgrid" para diferentes estilos de fondo/rejilla

# Se configura el color de los puntos (sm.qqplot no tiene un argumento directo para el color de los puntos)
# Se necesita acceder a los objetos Line2D (los puntos) en el gr√°fico.
# sm.qqplot devuelve un objeto Figure, que contiene los Axes.
# Los puntos suelen ser el primer objeto Line2D en los Axes.
# Iteramos sobre los ejes para encontrar los puntos y la l√≠nea
for ax in fig.get_axes():
    # Los puntos son el primer elemento en ax.collections (si son scatter) o ax.lines
    # Para qqplot, los puntos son Lines2D.
    if ax.lines: # Verifica si hay l√≠neas
        # Los puntos del Q-Q plot suelen ser la primera l√≠nea/colecci√≥n
        ax.lines[0].set_color('darkblue') # Color de los puntos
        ax.lines[0].set_marker('o')      # Tipo de marcador (c√≠rculo)
        ax.lines[0].set_markersize(5)    # Tama√±o de los puntos
        ax.lines[0].set_alpha(0.7)       # Transparencia

        # La l√≠nea de referencia (si line='45' fue usado) suele ser la segunda l√≠nea
        if len(ax.lines) > 1:
            ax.lines[1].set_color('red') # Color de la l√≠nea de referencia
            ax.lines[1].set_linestyle('--') # Estilo de l√≠nea discontinua


# 3. Configurar etiquetas y t√≠tulo
plt.title("Gr√°fico Q-Q Normal de los Residuos del Modelo", fontsize=18, loc='center', fontweight='bold')
plt.xlabel("Cuantiles Te√≥ricos Normales", fontsize=14)
plt.ylabel("Residuos del Modelo", fontsize=14)

# Ajustar los ticks y etiquetas de los ejes
plt.tick_params(axis='x', labelsize=12)
plt.tick_params(axis='y', labelsize=12)

# Quitar la leyenda si aparece por defecto
# if ax.get_legend():
#     ax.get_legend().remove()

# Ajustar el dise√±o para que no se corten etiquetas
plt.tight_layout()

# Mostrar el gr√°fico
plt.show()
```

##### Interpretaci√≥n del gr√°fico Q-Q Normal:

-   **Si los puntos caen aproximadamente sobre la l√≠nea roja diagonal**, indica que los residuos siguen una distribuci√≥n normal. Esto es lo que idealmente buscas.\
-   **Si los puntos se desv√≠an de la l√≠nea**, puede indicar una violaci√≥n del supuesto de normalidad:
    -   **Forma de "S"**: Los residuos pueden tener colas m√°s pesadas o m√°s ligeras de lo esperado (ej. distribuci√≥n con curtosis).
-   **Curvatura en un extremo o ambos**: Los residuos pueden estar sesgados (skewed) hacia la izquierda o la derecha.

#### Residuos Studentizados (Studentized Residuals)

-   Tambi√©n conocidos como residuos studentizados externamente (o residuos t). Son una versi√≥n m√°s refinada de los residuos estandarizados.

-   Cada residuo se divide por una estimaci√≥n de su error est√°ndar que excluye la observaci√≥n actual, lo que los hace m√°s apropiados para la detecci√≥n de outliers, ya que el outlier no influye en la estimaci√≥n de su propia varianza.

```{python}
#| echo: true
#| eval: false
#| message: false
#| warning: false
#| results: as-is
#| code-fold: true

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm # Import statsmodels.api for qqplot

# Get the studentized residuals from the fitted model
# This is the direct equivalent of rstudent(modelo_step) in R
residuos_studentized_py = final_modelo_ols_py.get_influence().resid_studentized_external

# 1. Create the Normal Q-Q Plot
# sm.qqplot automatically calculates theoretical and observed quantiles
# and draws the reference line.
# 'line="45"' draws the y=x line (slope 1, intercept 0)
fig = sm.qqplot(residuos_studentized_py, line = '45', fit = True, plot_type = 'qq', ax = None)

# 2. Configure styles and customize the plot
fig, ax = plt.subplots(figsize = (12, 6)) # Se crea una figura y ejes expl√≠citamente
sm.qqplot(residuos_studentized_py, line='45', fit = True)
sns.set_style("whitegrid") # Sets a nice background with a grid


# Customize point and line appearance
for ax in fig.get_axes():
    if ax.lines:
        # Points
        ax.lines[0].set_color('darkblue')
        ax.lines[0].set_marker('o')
        ax.lines[0].set_markersize(5)
        ax.lines[0].set_alpha(0.7)

        # Reference line
        if len(ax.lines) > 1:
            ax.lines[1].set_color('red')
            ax.lines[1].set_linestyle('--')

# 3. Configure labels and title
plt.title("Gr√°fico Q-Q Normal de los Residuos studentized", fontsize = 18, loc = 'center', fontweight = 'bold')
plt.xlabel("Cuantiles Te√≥ricos Normales", fontsize = 14)
plt.ylabel("Residuos studentized", fontsize = 14)

# Adjust tick and label sizes
plt.tick_params(axis='x', labelsize = 12)
plt.tick_params(axis='y', labelsize = 12)

# 4. Display the plot
plt.tight_layout() # Adjust layout to prevent labels from being cut off
plt.show()
```


#### Shapiro-Wilk normality test

El **Test de Normalidad de Shapiro-Wilk** es una prueba estad√≠stica que se utiliza para determinar si una muestra de datos procede de una poblaci√≥n con distribuci√≥n normal. Es una de las pruebas de normalidad m√°s potentes y ampliamente recomendadas, especialmente para tama√±os de muestra peque√±os a moderados.

Es una prueba estad√≠stica que eval√∫a si los datos provienen de una distribuci√≥n normal.

-   **Hip√≥tesis nula (H‚ÇÄ)**: los datos siguen una distribuci√≥n normal.
-   **Hip√≥tesis alternativa (H‚ÇÅ)**: los datos **no** siguen una distribuci√≥n normal.


```{python}
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf
from scipy.stats import shapiro # Importa la funci√≥n shapiro

# Obtener los residuos del modelo entrenado
# Este es el equivalente de modelo_step$residuals en R
residuos = final_modelo_ols_py.resid

# Realizar el Test de Shapiro-Wilk para normalidad
# La funci√≥n shapiro() devuelve dos valores: el estad√≠stico W y el valor p
statistic, p_value = shapiro(residuos)

print("--- Resultado del Test de Shapiro-Wilk ---")
print(f"Estad√≠stico W: {statistic:.4f}")
print(f"Valor p: {p_value:.4f}")

# Interpretar el resultado (convencionalmente con alpha = 0.05)
alpha = 0.05
if p_value > alpha:
    print(f"Dado que el valor p ({p_value:.4f}) es mayor que {alpha}, no se puede rechazar la hip√≥tesis nula.")
    print("Por lo tanto, los residuos parecen seguir una distribuci√≥n normal.")
else:
    print(f"Dado que el valor p ({p_value:.4f}) es menor o igual que {alpha}, se rechaza la hip√≥tesis nula.")
    print("Por lo tanto, los residuos no parecen seguir una distribuci√≥n normal.")
```

-   **p = 0.3030 \> 0.05** ‚Üí **no se rechaza H‚ÇÄ**
    -   **Conclusi√≥n**: **los residuos del modelo pueden considerarse normalmente distribuidos**.


##### Evaluaci√≥n de los residuos de un modelo lineal


```{python}
#| echo: true
#| message: false
#| warning: false
#| results: as-is
#| code-fold: true

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.graphics.regressionplots import plot_leverage_resid2, plot_homoscedasticity

# Configurar el estilo de seaborn para una apariencia similar
sns.set_style("white") # Un fondo blanco, similar al default de R para estos plots

# 1. Crear una figura con dos subplots (1 fila, 2 columnas)
# Esto es el equivalente a par(mfrow = c(1,2)) en R
fig, axes = plt.subplots(1, 2, figsize = (14, 6)) # figsize ajusta el tama√±o total de la figura

# --- Gr√°fico 1: Scale-Location (o Spread-Location) ---
# Este gr√°fico eval√∫a la homoscedasticidad (varianza constante de los residuos).
# En statsmodels, puedes obtener los residuos estandarizados (studentized residuals)
# y los valores ajustados para graficarlos.
# La ra√≠z cuadrada de los residuos estandarizados absolutos vs. los valores ajustados.

# Obtener los residuos estandarizados y los valores ajustados del modelo
# Los residuos estandarizados son muy similares a los studentized residuals que usaste antes,
# pero a menudo los residuos estandarizados (con varianza 1) son los que se usan aqu√≠.
standardized_residuals = final_modelo_ols_py.get_influence().resid_std # studentized residuals from get_influence() are also often called standardized
fitted_values = final_modelo_ols_py.fittedvalues

# Calcular la ra√≠z cuadrada del valor absoluto de los residuos estandarizados
sqrt_abs_standardized_residuals = np.sqrt(np.abs(standardized_residuals))

# Graficar en el primer subplot (axes[0])
axes[0].scatter(fitted_values, sqrt_abs_standardized_residuals, edgecolors='black', facecolors='none')

# A√±adir la l√≠nea de LOESS (Locally Estimated Scatterplot Smoothing)
# Esto se hace manualmente con seaborn o statsmodels si quieres ser preciso,
# o simplemente se dibuja una l√≠nea suavizada si es solo para visualizaci√≥n.
# Aqu√≠ usaremos sns.regplot para la l√≠nea LOESS, pero lo hacemos sobre los mismos datos
# y luego eliminamos los puntos para que solo quede la l√≠nea.
sns.regplot(
    x=fitted_values,
    y=sqrt_abs_standardized_residuals,
    lowess=True, # Esto es clave para la l√≠nea suavizada (LOESS)
    scatter=False, # No dibuja los puntos (ya los dibujamos con scatter)
    color='red',
    ax=axes[0]
)

# Etiquetas para puntos influyentes (como Chrysler Imperial, Fiat 128, Datsun 710)
# Esto requiere un poco m√°s de trabajo ya que statsmodels no lo hace autom√°ticamente en todos los plots.
# Necesitas identificar los nombres de las filas de los outliers.
# Ejemplo muy b√°sico: Si conoces los √≠ndices o tienes un m√©todo para identificarlos
# (e.g., por un umbral de residuo alto)
# Aqu√≠ lo haremos con un ejemplo, si tus datos tienen nombres de √≠ndice:
if hasattr(train_data_selected_model, 'index'):
    # Identifica algunos puntos con residuos estandarizados altos para etiquetarlos
    # Esto es una simplificaci√≥n; en un an√°lisis real usar√≠as m√©tricas de influencia.
    top_indices = np.abs(standardized_residuals).nlargest(3).index
    for i, txt in enumerate(top_indices):
        axes[0].annotate(txt, (fitted_values[txt], sqrt_abs_standardized_residuals[txt]),
                         xytext=(5, 5), textcoords='offset points')


axes[0].set_title('Scale-Location')
axes[0].set_xlabel('Fitted values')
axes[0].set_ylabel(r'$\sqrt{|Standardized\ residuals|}$') # LaTeX para la ra√≠z cuadrada

# --- Gr√°fico 2: Residuals vs Leverage (con Distancia de Cook) ---
# plot_leverage_resid2 es una funci√≥n de statsmodels que hace exactamente este gr√°fico.
# fit_result.get_influence() es lo que proporciona los valores de leverage y los residuos.
sm.graphics.plot_leverage_resid2(final_modelo_ols_py, ax=axes[1], # Dibuja en el segundo subplot
                                 # Configuraci√≥n para la distancia de Cook
                                 line_kwargs={'color': 'red', 'alpha': 0.8}, # Estilo de la l√≠nea LOESS
                                 # Etiquetar puntos influyentes (lo hace sm.graphics.plot_leverage_resid2 por defecto)
                                 # El argumento 'alpha' para los contornos de Cook est√° dentro de la funci√≥n.
                                )

# Customize the title and labels for the second plot
axes[1].set_title('Residuals vs Leverage')
axes[1].set_xlabel('Leverage')
axes[1].set_ylabel('Standardized residuals') # Nota: plot_leverage_resid2 usa residuos estandarizados

# Puedes ajustar los l√≠mites si es necesario para que se parezca m√°s al gr√°fico de R
#axes[1].set_xlim(0, 0.5)
#axes[1].set_ylim(-2, 3)

# Asegurarse de que el dise√±o sea ajustado y que los subplots no se superpongan
plt.tight_layout()
plt.show()
```

