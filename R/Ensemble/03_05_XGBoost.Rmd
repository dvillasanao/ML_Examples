---
title: "CatBoost"
subtitle: "Apuntes y anotaciones personales"
author: "Diana Villasana Ocampo"
knit: (function(inputFile, encoding) {
       rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../Output/Regression")
  })
output:
   html_document:
      code_folding: hide
      highlight: tango
      theme: flatly
      toc: true
      toc_depth: 3
      toc_float:
        collapsed: yes
---

```{=html}
<style type="text/css">
body {
text-align: justify;
font-style: normal;
font-family: "Montserrat";
font-size: 12px
}
h1.title {
  font-size: 40px;
  color: #000D3B;
}
h1 {
  font-size: 35px;
  color: #B6854D;
}
h2 {
  font-size: 30px;
  color: #172984;
}
h3 {
  font-size: 25px;
  color: #172984;
}
h4 {
  font-size: 22px;
  color: #172984;
}
h5 {
  ont-size: 20px;
  color: #172984;
}
h6{
  ont-size: 18px;
  color: #1864cb;
}
</style>
```

```{=html}
<style>
.nav>li>a {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #1C3BA4
}
.nav-pills>li.active>a, .nav-pills>li.active>a:hover, .nav-pills>li>a:focus {
    color: #ffffff;
    background-color: #09C2BC
}
</style>
```

```{=html}
<style>
.tile1-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6A87;
    list-style: none;
}
.top1-tiles a:nth-of-type(1):hover, .top-tiles1 a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6A87
}
</style>
```

```{=html}
<style>
.tile2-text {
    position: relative;
    display: block;
    padding: 10px 15px;
    color: #0A6CC8;
    list-style: none;
}
.top2-tiles a:nth-of-type(1):hover, .top2-tiles a:nth-of-type(1):focus{
    color: #ffffff;
    background: #0A6CC8
}
</style>


```

```{=html}
<style>
.math {
  font-size: 15px;
  color: #1e42ab;
}

.rmdwarning {
  border: 1px solid red; /* Yellow border */
  background-color: lightgrey; /* Light yellow background */
  padding: 15px;
  margin-bottom: 15px;
  border-left: 5px solid #ffcc00; /* Stronger left border */
}

</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, 
                      cache.lazy = FALSE, class.source = "fold-show")
knitr::opts_knit$set(root.dir = here::here())
setwd(here::here())
```

```{r,echo=FALSE, eval=FALSE, }
rm(list = ls())
```

```{r, echo = FALSE, results=FALSE}
# Se descargan las fuentes de la google fonts
require(showtext)
library(extrafont)
# activar showtext
windowsFonts()
```

```{r, echo = FALSE}
# 1. Cargar librer√≠as necesarias
library(tidyverse)
library(caret)     # Para dividir datos y evaluaci√≥n
library(broom)     # Para tidy modelos
library(Metrics)   # Para m√©tricas como RMSE, MAE
require(tibble)
```

::: {.rmdwarning}
üéØ Este material es reproducible en c√≥digo R
:::


La Regresi√≥n por M√≠nimos Cuadrados Ordinarios (Ordinary Least Squares Regression, **OLSR** u **OLS**) representa una metodolog√≠a estad√≠stica esencial que permite analizar la correlaci√≥n entre una **variable dependiente** (tambi√©n conocida como variable de respuesta) y una o m√°s **variables independientes** (o predictoras). Este m√©todo constituye una herramienta fundamental en el campo del an√°lisis de regresi√≥n lineal.

<p align="center">
<img src="../../img/Regression/01_image_OLSR.png" alt="Machine Learning Steps" width="40%"/>
</p>




```{r, echo = FALSE}
# Datos de la tabla
criterios <- c(
  "üîç Tipo de modelo",
  "üéØ Variable respuesta",
  "üî¢ Variables predictoras",
  "üìà Relaci√≥n entre variables",
  "üß™ Normalidad de residuos",
  "üîÅ Independencia de errores",
  "‚öñÔ∏è Homoscedasticidad",
  "‚ùó Sensible a outliers",
  "üîó Multicolinealidad entre predictores",
  "üß† Interpretabilidad",
  "üöÄ Velocidad y eficiencia",
  "üß™ Validaci√≥n cruzada",
  "‚ùå No funciona bien si..."
)

aplica <- c(
  "Supervisado",
  "Num√©rica continua",
  "Num√©ricas y/o categ√≥ricas",
  "Lineal (supuesto clave)",
  "Deseable",
  "Necesaria",
  "Necesaria",
  "S√≠",
  "Problema com√∫n",
  "Alta",
  "Muy alta",
  "Compatible",
  "Relaciones no lineales, outliers severos, colinealidad"
)

detalles <- c(
  "Se entrena con datos X ‚Üí y",
  "Ej. mpg, precio, ingresos",
  "Categor√≠as convertidas a dummies",
  "Se asume una relaci√≥n lineal entre X e Y",
  "Importante para intervalos de confianza v√°lidos",
  "Errores deben ser independientes",
  "Varianza de errores debe ser constante",
  "Outliers pueden influir mucho en el modelo",
  "Usar VIF para detectar problemas",
  "Modelo f√°cil de explicar",
  "R√°pido incluso con datos grandes",
  "Ayuda a prevenir overfitting",
  "Evitar si no hay linealidad o hay muchos outliers"
)

# Crear y mostrar tabla
tabla_olsr <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

require(gt)

tabla_olsr %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir OLSR") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```




## Objetivo

La Regresi√≥n por M√≠nimos Cuadrados Ordinarios (`OLSR`) busca la l√≠nea que mejor se ajusta a los datos. Para lograrlo, reduce al m√≠nimo la suma de los cuadrados de las diferencias entre los valores reales y los valores que predice el modelo. Estas diferencias son los **residuos** o **errores**. Al trabajar con los cuadrados de los errores, este m√©todo evita que los errores positivos y negativos se anulen entre s√≠, y da m√°s peso a los errores grandes durante el proceso de minimizaci√≥n.

## Metodolog√≠a

La metodolog√≠a de OLSR se basa en los siguientes pasos y principios:

1.  **Modelo Lineal:** OLSR asume una relaci√≥n lineal entre las variables. Para una regresi√≥n lineal simple (una variable independiente), la ecuaci√≥n es:\
    $$Y = \beta_0 + \beta_1X + \epsilon$$

    Donde:

    -   $Y$ es la variable dependiente.

-   $X$ es la variable independiente.
-   $\beta_0$ es el intercepto (el valor de $Y$ cuando $X$ es 0).
-   $\beta_1$ es la pendiente (el cambio en $Y$ por cada unidad de cambio en $X$).
-   $\epsilon$ es el t√©rmino de error o residual, que representa la parte de $Y$ que no puede ser explicada por $X$.

Para una regresi√≥n lineal m√∫ltiple (varias variables independientes), la ecuaci√≥n se expande a:\
$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k + \epsilon$$

2.  **Minimizaci√≥n de la Suma de Cuadrados de Residuos (SSR):** El coraz√≥n de OLS es encontrar los valores de los coeficientes ($\beta_0, \beta_1$, etc.) que minimicen la siguiente funci√≥n:\
    $$\text{Minimizar } \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$\
    Donde:
    -   $y_i$ es el valor observado de la variable dependiente para la observaci√≥n $i$.

-   $\hat{y}_i$ es el valor predicho de la variable dependiente por el modelo para la observaci√≥n $i$.
-   $(y_i - \hat{y}_i)$ es el residual para la observaci√≥n $i$.

Para lograr esta minimizaci√≥n, se utilizan t√©cnicas de c√°lculo (derivadas parciales) para encontrar los valores de los coeficientes que hacen que la pendiente de la funci√≥n de suma de cuadrados sea cero.

3.  **Estimaci√≥n de Coeficientes:** Los valores estimados de los coeficientes, denotados como $\hat{\beta}_0, \hat{\beta}_1$, etc., son aquellos que resultan de la minimizaci√≥n. Estos coeficientes son los que definen la "l√≠nea de mejor ajuste".

4.  **Supuestos del OLS:** Para que los estimadores de OLS sean los "mejores estimadores lineales insesgados" (seg√∫n el Teorema de Gauss-Markov), se deben cumplir ciertas suposiciones:

    -   **Linealidad:** La relaci√≥n entre las variables es lineal.

    -   **Independencia de los errores:** Los errores de una observaci√≥n no est√°n correlacionados con los errores de otra.

    -   **Homocedasticidad:** La varianza de los errores es constante en todos los niveles de las variables independientes.

    -   **Normalidad de los errores:** Los errores se distribuyen normalmente (aunque no es estrictamente necesario para la estimaci√≥n, s√≠ lo es para la inferencia estad√≠stica).

    -   **No multicolinealidad perfecta:** Las variables independientes no est√°n perfectamente correlacionadas entre s√≠.

## **Pasos generales del Machine Learning supervisado**

1.  **Importar y explorar los datos**
2.  **Preprocesamiento**
3.  **Divisi√≥n de los datos (train/test)**
4.  **Entrenamiento del modelo**
5.  **Evaluaci√≥n del modelo**
6.  **Ajustes o validaci√≥n cruzada (si aplica)**
7.  **Predicci√≥n con nuevos datos**
8.  **Interpretaci√≥n de resultados**

<p align="center">
<img src="../../img/ML_Steps.png" alt="Machine Learning Steps" width="100%"/>
</p>

------------------------------------------------------------------------

## Base de datos

La base de datos `mtcars` es un conjunto de datos cl√°sico en R que contiene informaci√≥n sobre **32 autom√≥viles** (modelos de 1973‚Äì74), y fue extra√≠do de la revista *Motor Trend US*. Incluye **variables t√©cnicas** del desempe√±o de los autos.

Aqu√≠ est√° una descripci√≥n de cada columna:

| Variable | Significado | Tipo de dato |
|-------------------|-----------------------------------|-------------------|
| `mpg` | Miles per gallon (millas por gal√≥n) | Num√©rica |
| `cyl` | N√∫mero de cilindros | Entero |
| `disp` | Desplazamiento del motor (en pulgadas c√∫bicas) | Num√©rica |
| `hp` | Caballos de fuerza | Entero |
| `drat` | Relaci√≥n del eje trasero (rear axle ratio) | Num√©rica |
| `wt` | Peso del auto (en miles de libras) | Num√©rica |
| `qsec` | Tiempo en 1/4 de milla (segundos) | Num√©rica |
| `vs` | Tipo de motor: 0 = V-shaped, 1 = straight (en l√≠nea) | Binaria (factor) |
| `am` | Tipo de transmisi√≥n: 0 = autom√°tica, 1 = manual | Binaria (factor) |
| `gear` | N√∫mero de velocidades (marchas) adelante | Entero |
| `carb` | N√∫mero de carburadores | Entero |

```{r}
# 2. Cargar y se exploran los datos
data("mtcars")
```

```{r, echo = FALSE}
require(gt)

mtcars %>% 
 gt() %>%
  tab_header(title = "mtcars data") %>%
   tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Cuando_") ~ px(300),
                   everything() ~ px(50)) %>%
         as_raw_html() 

```

## Entrenamiento de los datos (train/test)

La divisi√≥n de datos en conjuntos de **entrenamiento (train)** y **prueba (test)** es una pr√°ctica fundamental en el aprendizaje autom√°tico y la modelizaci√≥n predictiva. Su importancia radica en la necesidad de obtener una evaluaci√≥n **realista y no sesgada** del rendimiento de un modelo, y de asegurar que el modelo sea capaz de **generalizar** a datos nuevos y no vistos.

-   Se usa la funci√≥n `createDataPartition()` del paquete `caret` para **dividir los datos**.
-   Se crea un **√≠ndice** con el 80% de las filas del `mtcars`, **estratificado** seg√∫n la variable `mpg` (la variable objetivo).
-   El argumento `p = 0.8` significa que el 80% se usar√° para **entrenamiento** y el 20% restante para **prueba**.
-   `list = FALSE` devuelve los √≠ndices como un vector, no como una lista.

```{r}
# Se quiere predecir `mpg` (millas por gal√≥n) usando otras variables
# mpg ser√° la variable dependiente (target)

# 3. Se dividen losdatos en entrenamiento y prueba
set.seed(123)  # Para reproducibilidad
train_index <- createDataPartition(mtcars$mpg, p = 0.8, list = FALSE)
train_data <- mtcars[train_index, ]
test_data <- mtcars[-train_index, ]
```

-   Particionar los datos, evita el **overfitting** (cuando el modelo memoriza los datos de entrenamiento).
-   Permite una **evaluaci√≥n honesta** del modelo al probarlo en datos que no vio durante el entrenamiento.
-   Es una pr√°ctica est√°ndar en cualquier pipeline de aprendizaje autom√°tico.

## Entrenamiento del modelo

El **entrenamiento de un modelo** es el paso m√°s importante en el aprendizaje autom√°tico. Usando un conjunto de datos de entrenamiento (`train_data`), el modelo aprende a reconocer patrones para hacer predicciones confiables con datos nuevos. Este proceso es esencial por estas razones:

-   Durante el entrenamiento, el modelo **identifica patrones espec√≠ficos** en los datos.
-   Separamos los datos en grupos de entrenamiento y prueba para asegurar que el modelo funcione bien no solo con datos conocidos, sino tambi√©n con **datos nuevos y no vistos**.
-   Despu√©s del entrenamiento con `train_data`, usamos el **conjunto de prueba (`test_data`)** para medir el rendimiento. Las m√©tricas (MAE, RMSE, $R^2$) nos muestran qu√© tan bien el modelo **maneja datos nuevos**.
-   Un rendimiento peor en `test_data` que en `train_data` indica que el modelo est√° sobreajustado.
-   Con estos resultados, podemos decidir si el modelo est√° listo para usar o necesita ajustes.

**Funci√≥n de entrenamiento**

-   la funci√≥n **`lm()`** es la funci√≥n base de R para ajustar un modelo de **regresi√≥n lineal** (OLS = *Ordinary Least Squares*).

-   **`mpg ~ .`** es una f√≥rmula que indica:

    -   `mpg` es la **variable dependiente** (lo que queremos predecir).
    -   `.` significa ‚Äútodas las dem√°s variables‚Äù del conjunto de datos se usar√°n como **variables independientes** (predictoras).
    -   **`data = train_data`** especifica que el modelo debe entrenarse usando el conjunto de **entrenamiento** (80% de los datos).

```{r}
# 4. Entrenar el modelo de regresi√≥n lineal (OLS)
modelo_ols <- lm(mpg ~ ., data = train_data)

# Revisar resumen del modelo
summary(modelo_ols)
```

Interpretemos los resultados:

**Residuales**

````         
```r
Residuals:
  Min      1Q  Median      3Q     Max 
-3.2742 -1.3609 -0.2707  1.1921  4.9877 
```
````

-   Indica la distribuci√≥n de los **errores de predicci√≥n** (diferencia entre valor real y valor predicho).
-   Lo ideal es que est√©n **centrados en 0** y sean **sim√©tricos**, lo que parece cumplirse aqu√≠.
-   El valor m√°ximo del error es aproximadamente ¬±5 millas por gal√≥n.

**Ninguna variable es estad√≠sticamente significativa individualmente** (todas tienen p \> 0.05).

| M√©trica | Valor | Significado |
|------------------|------------------|-----------------------------------|
| **R-squared** | 0.8861 | El modelo explica el **88.6%** de la variabilidad de `mpg` |
| **Adjusted R-squared** | 0.8191 | Ajusta el R¬≤ penalizando el n√∫mero de predictores |
| **F-statistic** | 13.23 | El modelo como conjunto es **significativo** |
| **p-value global** | 3.719e-06 | Muy bajo ‚Üí **el modelo es √∫til en conjunto** (aunque variables individuales no lo sean) |

### üìå **Observaciones generales**

-   **El modelo es bueno en conjunto**, pero ninguna variable individual es altamente significativa.\
-   Esto puede ser por **colinealidad** (las variables est√°n correlacionadas entre s√≠).\
-   Se podr√≠a:
    -   Usar un modelo m√°s simple (quitar predictores no √∫tiles).
    -   Aplicar **selecci√≥n de variables** (ej. stepAIC, regsubsets).
    -   Verificar colinealidad con el **VIF** (Variance Inflation Factor).
    -   Visualizar los residuos para ver si el modelo cumple los supuestos.

```{r, class.source = "fold-hide"}
require(ggplot2)
require(reshape2)

tabla <- mtcars %>% 
          melt(., id = "mpg")

p <- tabla %>% 
      ggplot(aes(y = mpg, x = value, color = variable)) + 
       geom_point() +
        geom_smooth(method = "lm", se = TRUE, color = "black") +
         theme_bw() + 
          theme(plot.title = element_text(size = 22, hjust = 0.15, family = "Montserrat", face = "bold"),
                plot.subtitle = element_text(size = 18, hjust = 0, family = "Montserrat", face = "bold"),
                plot.caption = element_text(size = 11, hjust = 0.2, vjust = 1, family = "Montserrat"), 
                axis.text = element_text(family = "Montserrat"), 
                axis.title = element_text(family = "Montserrat", size = 15), 
                legend.position = "none"
               ) + 
           scale_color_viridis_d(option = "A") +
            facet_wrap(variable~., scales = "free") + 
             labs(title = "Diagramas de dispersi√≥n",
                  x = "",
                  y = "")
p
```

## Selecci√≥n de variables

### Criterio de Informaci√≥n de Akaike

El Criterio de Informaci√≥n de Akaike (AIC, por sus siglas en ingl√©s, Akaike Information Criterion) es una medida de la bondad de ajuste de un modelo estad√≠stico que penaliza la complejidad del modelo. Su objetivo es seleccionar el modelo que mejor se ajusta a los datos con la menor cantidad de par√°metros, evitando as√≠ el sobreajuste (overfitting).

La f√≥rmula general para calcular el AIC es:

$$AIC = 2k - 2\ln(L)$$

Donde:\
\* $k$ es el n√∫mero de par√°metros del modelo. En un modelo de regresi√≥n, esto incluye el intercepto y los coeficientes de las variables predictoras, m√°s la varianza del error si se estima (en modelos de m√≠nimos cuadrados ordinarios, esto es a menudo el caso, por lo que $k$ a veces se cuenta como el n√∫mero de coeficientes + 1 para la varianza del error, o simplemente el n√∫mero de coeficientes si la varianza del error se considera impl√≠cita en la funci√≥n de verosimilitud).\
\* $\ln(L)$ es el logaritmo natural del valor m√°ximo de la funci√≥n de verosimilitud (log-likelihood) del modelo. La funci√≥n de verosimilitud mide qu√© tan bien el modelo reproduce los datos observados.

#### C√≥mo se interpreta:

-   **Valores m√°s bajos de AIC indican un mejor modelo.** El AIC busca un equilibrio entre la bondad de ajuste del modelo a los datos (representada por $\ln(L)$) y la complejidad del modelo (representada por $2k$).\
-   El t√©rmino $2k$ es una **penalizaci√≥n por la complejidad**. Cada par√°metro adicional en el modelo aumenta el valor de AIC, lo que desincentiva la inclusi√≥n de variables innecesarias que podr√≠an sobreajustar los datos.

#### Para modelos de Regresi√≥n por M√≠nimos Cuadrados Ordinarios (OLS):

Aunque la f√≥rmula general del AIC es la que se mencion√≥, para modelos de OLS con residuos normalmente distribuidos, la funci√≥n de log-verosimilitud tiene una forma espec√≠fica, lo que permite reescribir el AIC de una manera m√°s pr√°ctica.

Para un modelo de regresi√≥n lineal con $n$ observaciones y $k$ par√°metros (incluyendo el intercepto), y asumiendo errores normales con varianza constante, el AIC se puede calcular como:

$$AIC = n \cdot \ln\left(\frac{RSS}{n}\right) + 2k$$

Donde:\
\* $n$ es el n√∫mero de observaciones (tama√±o de la muestra).\
\* $RSS$ es la Suma de Cuadrados de los Residuos (Residual Sum of Squares), que es la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo.\
\* $k$ es el n√∫mero de par√°metros del modelo (coeficientes de las variables independientes + intercepto).

**Es importante recordar:**

-   El AIC no es una prueba de hip√≥tesis en el sentido tradicional; no te dice si un modelo es "bueno" o "malo" en un sentido absoluto.\
-   Es una herramienta para la **selecci√≥n de modelos entre un conjunto de modelos candidatos**. Siempre se compara el AIC de diferentes modelos ajustados a los **mismos datos**. El modelo con el AIC m√°s bajo es el preferido.\
-   Cuando la muestra es peque√±a, a veces se prefiere el **AIC corregido (AICc)**, que a√±ade una penalizaci√≥n adicional por el tama√±o de la muestra:\
    $$AICc = AIC + \frac{2k(k+1)}{n-k-1}$$

A medida que $n$ (tama√±o de la muestra) es grande, el t√©rmino de correcci√≥n se vuelve insignificante y el AICc converge al AIC.

Se realiza una selecci√≥n autom√°tica de variables para un modelo de regresi√≥n lineal, utilizando el **criterio AIC (Criterio de Informaci√≥n de Akaike**)

```{r}
require(MASS)

# Aplicar selecci√≥n autom√°tica con criterio AIC
modelo_step <- stepAIC(modelo_ols, direction = "both")
```

El procedimiento va eliminando o agregando variables al modelo original para reducir el **AIC (Criterio de Informaci√≥n de Akaike)**. El objetivo es encontrar un modelo m√°s **parsimonioso** (simple) con **buena capacidad predictiva**.

-   El proceso empieza con un modelo completo:\
    `mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb` y un AIC inicial, por ejemplo: `AIC = 57.77`.

-   Luego eval√∫a qu√© pasa si **quita** una variable (`- vs`, `- cyl`, etc.).

-   Si al eliminar una variable el AIC **baja**, se acepta ese cambio.\
    Ejemplo:\
    `- vs    1    2.1293  102.57  56.353`\
    Significa que si quitas la variable `vs`, el AIC baja de 57.77 a 56.35 ‚Üí ¬°mejor!

    -   Se acepta esa modificaci√≥n y se repite el procedimiento, ahora con el nuevo modelo.

-   Tambi√©n puede intentar **agregar** variables previamente eliminadas (`+ vs`, `+ hp`, etc.) si esto mejora el AIC.

-   Cuando **ya no puede bajar m√°s el AIC** quitando o agregando variables. El modelo final es el que **tiene el AIC m√°s bajo** alcanzado durante el proceso.

```{r}
# Ver resumen del modelo seleccionado
summary(modelo_step)
```

-   **Error est√°ndar residual**: En promedio, el error de predicci√≥n es de ¬±2.2 mpg.
-   **R¬≤ = 0.8738**: El modelo explica el **87.4% de la variabilidad** en `mpg`.
-   **R¬≤ ajustado = 0.8518**: Ajusta por el n√∫mero de predictores; a√∫n muy bueno.
-   **F-statistic = 39.81**, **p-value muy bajo (‚âà0)**: El modelo global es **altamente significativo**.

### Forward or backward stepwise

Los modelos "forward" (hacia adelante) y "backward" (hacia atr√°s) son dos enfoques comunes dentro de la **regresi√≥n stepwise (paso a paso)**, un m√©todo de selecci√≥n autom√°tica de variables para construir modelos de regresi√≥n. El objetivo de la regresi√≥n stepwise es encontrar un subconjunto √≥ptimo de variables predictoras que expliquen la mayor parte de la varianza en la variable dependiente con la menor complejidad posible, evitando el sobreajuste y mejorando la interpretabilidad del modelo.

Ambos m√©todos operan de manera iterativa, agregando o eliminando variables bas√°ndose en un criterio estad√≠stico (como el p-valor, AIC, BIC, etc.).

#### **Forward Selection** (Selecci√≥n Hacia Adelante)

La selecci√≥n hacia adelante comienza con un modelo "nulo", es decir, un modelo que no contiene ninguna variable predictora (solo el intercepto). Luego, en cada paso, eval√∫a todas las variables predictoras no incluidas en el modelo y agrega aquella que, al ser incluida, produce la mejora m√°s significativa en el ajuste del modelo. Este proceso contin√∫a hasta que ninguna de las variables restantes cumple con el criterio de entrada preestablecido (por ejemplo, su p-valor es mayor que un umbral determinado).

#### **Backward Elimination** (Eliminaci√≥n Hacia Atr√°s)

La eliminaci√≥n hacia atr√°s comienza con un modelo "completo", es decir, un modelo que incluye todas las variables predictoras candidatas. Luego, en cada paso, eval√∫a la contribuci√≥n de cada variable predictora en el modelo y elimina aquella que, al ser retirada, tiene el menor impacto negativo en el ajuste del modelo (o la que es menos significativa, por ejemplo, la que tiene el p-valor m√°s alto). Este proceso contin√∫a hasta que todas las variables restantes en el modelo cumplen con un criterio de permanencia preestablecido (por ejemplo, su p-valor es menor que un umbral determinado).

#### Consideraciones Generales sobre la Regresi√≥n Stepwise

Es importante mencionar que, aunque los m√©todos forward y backward son populares por su automatizaci√≥n, tambi√©n tienen sus **cr√≠ticas y desventajas**:

-   **Sobreajuste (Overfitting):** Los modelos resultantes pueden ajustarse muy bien a los datos de entrenamiento, pero no generalizar bien a nuevos datos. Esto se debe a que el proceso de selecci√≥n de variables se basa en los datos observados, lo que puede llevar a incluir variables que parecen importantes por puro azar en esa muestra particular.
-   **P-valores y Coeficientes Sesgados:** Los p-valores y los coeficientes de regresi√≥n obtenidos de un modelo stepwise pueden ser sesgados. Los p-valores tienden a ser m√°s peque√±os de lo que realmente son, lo que lleva a una falsa confianza en la significancia de las variables.
-   **No considera la teor√≠a:** El proceso es puramente estad√≠stico y no incorpora el conocimiento del dominio o la teor√≠a subyacente sobre las relaciones entre las variables. Un modelo estad√≠sticamente "√≥ptimo" podr√≠a carecer de sentido te√≥rico o pr√°ctico.
-   **Dependencia del orden:** La selecci√≥n de variables puede ser sensible al orden en que se a√±aden o eliminan, especialmente en la selecci√≥n hacia adelante.

```{r}
require(leaps)

#	Use exhaustive search, forward selection, backward selection or sequential replacement to search.
#method=c("exhaustive", "backward", "forward", "seqrep")  

# Evaluar todos los subconjuntos posibles
regfit <- regsubsets(mpg ~ ., data = train_data, nvmax = 10)
summary(regfit)
```

`Selection Algorithm: exhaustive` **: Esto es crucial. Significa que el algoritmo prob√≥ todas las combinaciones posibles** de variables para cada tama√±o de subconjunto hasta `nvmax = 10` y seleccion√≥ el mejor para cada tama√±o. Esto asegura que, para cada n√∫mero de variables (1, 2, ..., 10), el modelo presentado es el √≥ptimo seg√∫n el criterio interno de `regsubsets` (generalmente $R^2$ ajustado, BIC o Cp de Mallows, a menos que se especifique otro).

```{r}
# Ver los mejores modelos seg√∫n el n√∫mero de variables
plot(regfit, scale = "adjr2")  # O usar "bic" o "Cp" para otros criterios
```

```{r, class.source = "fold-hide"}

regfit <- regsubsets(mpg ~ ., data = train_data, nvmax = 10)
summary(regfit)

require(ggplot2)
# Crear un data frame con las m√©tricas para ggplot2
reg_summary <- summary(regfit)

models_data <- data.frame(
                          num_variables = 1:length(reg_summary$adjr2),
                          adjr2 = reg_summary$adjr2,
                          cp = reg_summary$cp,
                          bic = reg_summary$bic
)

ggplot(models_data, aes(x = num_variables, y = adjr2)) +
 geom_line(color = "blue") +
  geom_point(color = "blue") +
   geom_vline(xintercept = which.max(models_data$adjr2), linetype = "dashed", color = "red") +
    geom_text(aes(x = which.max(models_data$adjr2) + 0.5, y = max(adjr2) * 0.95,
                  label = paste("Max R2 Ajustado con", which.max(models_data$adjr2), "vars")),
                  color = "red", size = 3, hjust = 0) +
     theme(plot.title = element_text(size = 22, hjust = 0.15, family = "Montserrat", face = "bold"),
           plot.subtitle = element_text(size = 18, hjust = 0, family = "Montserrat", face = "bold"),
           plot.caption = element_text(size = 11, hjust = 0.2, vjust = 1, family = "Montserrat"), 
           axis.text = element_text(family = "Montserrat"), 
           axis.title = element_text(family = "Montserrat", size = 15), 
           legend.position = "none"
               ) + 
     scale_x_continuous(breaks = 1:10) + 
     labs(title = "R2 Ajustado vs. N√∫mero de Variables",
          x = "N√∫mero de Variables",
          y = "R2 Ajustado") +
      theme_minimal()
```

### Variance Inflation Factor (`VIF`)

El **Factor de Inflaci√≥n de la Varianza (VIF)** es una herramienta estad√≠stica fundamental utilizada para **detectar y cuantificar la multicolinealidad** en modelos de regresi√≥n lineal m√∫ltiple.

**Problemas que causa la multicolinealidad:**

-   **Coeficientes de regresi√≥n inestables y dif√≠ciles de interpretar:** Cuando las variables predictoras est√°n altamente correlacionadas, es dif√≠cil para el modelo determinar la contribuci√≥n √∫nica de cada variable a la variable dependiente. Peque√±os cambios en los datos pueden llevar a grandes cambios en los coeficientes estimados, haciendo que sean poco fiables.
-   **Errores est√°ndar inflados:** La multicolinealidad aumenta los errores est√°ndar de los coeficientes de regresi√≥n, lo que a su vez disminuye los valores de las estad√≠sticas t y aumenta los p-valores. Esto puede llevar a la conclusi√≥n err√≥nea de que una variable no es estad√≠sticamente significativa cuando en realidad s√≠ lo es.
-   **Poder predictivo reducido:** Aunque la multicolinealidad no necesariamente afecta la capacidad predictiva global del modelo (el $R^2$ ajustado puede seguir siendo alto), s√≠ afecta la precisi√≥n de las estimaciones de los coeficientes individuales, lo que hace dif√≠cil comprender la relaci√≥n real entre cada predictor y la variable de respuesta.

El VIF mide **cu√°nto se "infla" la varianza del coeficiente de regresi√≥n estimado de una variable predictora debido a su correlaci√≥n con otras variables predictoras** en el modelo.

**La f√≥rmula del VIF para una variable** $X_j$ es:

$$VIF_j = \frac{1}{1 - R_j^2}$$

Donde $R_j^2$ es el coeficiente de determinaci√≥n ($R^2$) de una regresi√≥n auxiliar en la que la variable $X_j$ se predice utilizando todas las dem√°s variables independientes del modelo.

#### ¬øC√≥mo se interpreta el VIF?

-   **VIF = 1:** Indica que la variable predictora no est√° correlacionada con ninguna de las otras variables predictoras en el modelo. No hay multicolinealidad.
-   **VIF \> 1:** Indica que existe alg√∫n grado de multicolinealidad. Cuanto mayor sea el valor del VIF, mayor es el grado de multicolinealidad.

**Reglas generales para interpretar los valores de VIF (son reglas de "pulgar" y pueden variar ligeramente seg√∫n el contexto y el campo de estudio):**

-   **VIF ‚â§ 5:** Generalmente se considera que no hay problemas graves de multicolinealidad.
-   **5 \< VIF ‚â§ 10:** Puede indicar un nivel moderado a alto de multicolinealidad que podr√≠a justificar una investigaci√≥n.
-   **VIF \> 10:** A menudo se considera una indicaci√≥n clara de multicolinealidad grave y problem√°tica. Es un umbral com√∫nmente aceptado para se√±alar que una variable est√° fuertemente correlacionada con otras, lo que podr√≠a afectar la estabilidad y fiabilidad del modelo.

```{r}
require(car)

# Calcular VIF para el modelo original
vif(modelo_ols)
```

**Alt√≠sima colinealidad** en:

-   `cyl`, `disp`, `wt`, `carb`

**Sospechosos comunes**:

-   `cyl`, `disp`, `hp` y `wt` est√°n muy correlacionados entre s√≠ (motores grandes tienden a pesar m√°s, tener m√°s cilindros y m√°s caballos).

```{r}
# Calcular VIF para el modelo reducido 
vif(modelo_step)
```

Todos los VIF est√°n **por debajo del umbral de 5**, lo que indica:

-   No hay **colinealidad preocupante** entre las variables.
-   El modelo es **estable** y los coeficientes son interpretables con confianza.
-   `stepAIC` hizo un buen trabajo al reducir la complejidad y mejorar la interpretabilidad del modelo.

## Evaluaci√≥n del modelo

Ahora se va a trabajar con un **modelo reducido (`modelo_step`)**, es importante **usar ese modelo** para hacer predicciones en el conjunto de prueba. Adem√°s, como solo algunas variables quedaron en el modelo (`drat`, `wt`, `gear`, `carb`), el `test_data` debe contener esas columnas.

**Verificar qu√© variables necesita el modelo reducido**

```{r}
# Ver f√≥rmulas del modelo reducido
formula(modelo_step)
```

**Nos aseguramos que las bases de (test / training) tengan esas variables**

```{r}
test_data_reducido <- test_data[, c("mpg", "drat", "wt", "gear", "carb")]
```

### Modelo predictivo

Con la funci√≥n **`predict()`** gen√©rica en R que se utiliza para obtener predicciones de varios tipos de objetos de modelos (lineales, √°rboles de decisi√≥n, series de tiempo, etc.). Su comportamiento exacto depende de la clase del objeto que se le pasa como primer argumento.

Esta operaci√≥n es un paso clave en el flujo de trabajo de modelado predictivo, ya que permite:

1.  **Evaluaci√≥n del modelo:** Una vez que se tienen las `predicciones` para el `test_data`, se puede compararlas con los valores reales (observados) de la variable dependiente en el `test_data` (si se tienen) para **evaluar qu√© tan bien se desempe√±a el modelo** en datos no vistos. Esto ayuda a estimar su rendimiento en el mundo real y a detectar problemas como el **sobreajuste (overfitting)**.

2.  **Uso pr√°ctico del modelo:** Despu√©s de validar que el modelo es bueno, se puede usarlo para predecir la variable dependiente para nuevas observaciones futuras de las que solo se conocen las variables predictoras (por ejemplo, predecir el precio de una casa bas√°ndose en sus caracter√≠sticas, si el modelo fue entrenado para eso).

```{r}
# 5. Se evalua el modelo en los datos de prueba
predicciones <- predict(modelo_step, newdata = test_data_reducido)
```

```{r}
# Comparar valores reales vs. predichos
resultados <- tibble(Real = test_data_reducido$mpg,
                     Pred = predicciones
)
```

### Evaluar el desempe√±o predictivo

#### Mean Absolute Error (`MAE`)

El **MAE (Mean Absolute Error)**, o **Error Absoluto Medio** en espa√±ol, es una de las m√©tricas m√°s utilizadas para evaluar la precisi√≥n de un modelo de regresi√≥n. Mide la **magnitud promedio de los errores** entre los valores predichos por un modelo y los valores reales observados.

##### F√≥rmula del MAE

La f√≥rmula para calcular el MAE es la siguiente:

$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

Donde:

-   $n$: Es el n√∫mero total de observaciones (o puntos de datos) en el conjunto de datos.
-   $y_i$: Es el **valor real u observado** de la variable dependiente para la observaci√≥n $i$.
-   $\hat{y}_i$: Es el **valor predicho** por el modelo para la observaci√≥n $i$.
-   $|y_i - \hat{y}_i|$: Es el **valor absoluto** de la diferencia entre el valor real y el valor predicho para la observaci√≥n $i$. Tomar el valor absoluto es crucial porque evita que los errores positivos y negativos se cancelen entre s√≠, lo que dar√≠a una falsa impresi√≥n de precisi√≥n.
-   $\sum_{i=1}^{n}$: Indica la suma de todos los errores absolutos para todas las $n$ observaciones.

```{r}
# C√°lculo del MAE (Mean Absolute Error)
MAE <- mean(abs(predicciones - test_data_reducido$mpg))
MAE
```

Esto significa que, **en promedio**, el modelo reducido predice el consumo de combustible con un error de ¬±3.68 mpg. Esto es bueno o malo. Depende del rango de la variable `mpg` en `mtcars`.

```{r}
range(mtcars$mpg)
```

El rango de `mpg` es de **10.4 a 33.9**, es decir, abarca **\~23.5 unidades**.

Por tanto:

```         
  * Un MAE de **3.68** representa alrededor de un **15% del rango total**. El modelo, en promedio, se equivoca por 3.68 millas por gal√≥n en sus predicciones.  
* No es un error enorme, pero **tampoco es excelente**.  
* Si el modelo completo (`modelo_ols`) ten√≠a un MAE menor, podr√≠a predecir mejor, aunque con m√°s colinealidad.
```

#### Root Mean Squared Error (`RMSE`)

El **RMSE (Root Mean Squared Error)**, o **Ra√≠z del Error Cuadr√°tico Medio**, es una de las m√©tricas m√°s comunes y ampliamente utilizadas para evaluar la precisi√≥n de los modelos de regresi√≥n. Mide la **magnitud promedio de los errores** entre los valores predichos por un modelo y los valores reales observados, pero dando **mayor peso a los errores m√°s grandes**.

#### F√≥rmula del RMSE

$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

Donde:

-   $n$: Es el n√∫mero total de observaciones (o puntos de datos).\
-   $y_i$: Es el **valor real u observado** de la variable dependiente para la observaci√≥n $i$.\
-   $\hat{y}_i$: Es el **valor predicho** por el modelo para la observaci√≥n $i$.\
-   $(y_i - \hat{y}_i)^2$: Es el **cuadrado de la diferencia** entre el valor real y el valor predicho para la observaci√≥n $i$.

Elevar al cuadrado las diferencias tiene dos prop√≥sitos principales:

-   Eliminar los signos negativos: Asegura que los errores positivos y negativos no se cancelen entre s√≠.\
-   Penalizar m√°s los errores grandes: Los errores m√°s grandes tienen un impacto desproporcionadamente mayor en el resultado final del RMSE que los errores peque√±os, debido a la operaci√≥n al cuadrado.\
-   $\sum_{i=1}^{n}$: Indica la suma de todos los errores al cuadrado para todas las $n$ observaciones.

##### Interpretaci√≥n del RMSE:

-   El RMSE se expresa en las **mismas unidades que la variable dependiente original**. Esto facilita su interpretaci√≥n. Por ejemplo, si est√°s prediciendo la altura en metros y el RMSE es 0.5, significa que, en promedio, las predicciones del modelo se desv√≠an aproximadamente 0.5 metros de la altura real.\
-   **Un RMSE de 0 (cero) indica un modelo perfecto**, donde todas las predicciones son exactamente iguales a los valores reales.
-   **Valores m√°s bajos de RMSE indican un mejor rendimiento del modelo.**
    -   **Sensibilidad a valores at√≠picos:** Debido al t√©rmino al cuadrado, el RMSE penaliza m√°s fuertemente los errores grandes (valores at√≠picos) que el MAE. Esto significa que si tu modelo tiene algunos errores de predicci√≥n muy grandes, el RMSE ser√° significativamente m√°s alto que el MAE. Esta caracter√≠stica puede ser una ventaja o desventaja dependiendo del contexto:\
    -   **Ventaja:** Si los errores grandes son particularmente indeseables en tu aplicaci√≥n, el RMSE es una buena m√©trica porque los destaca.\
-   **Desventaja:** Si tu conjunto de datos contiene muchos valores at√≠picos reales o errores de medici√≥n que no son representativos del rendimiento general del modelo, el RMSE podr√≠a dar una visi√≥n pesimista.

```{r}
# C√°lculo del RMSE (Root Mean Squared Error)
RMSE <- sqrt(mean((predicciones - test_data_reducido$mpg)^2))
RMSE
```

-   Un RMSE de **4.87** significa que, en promedio, las predicciones difieren de los valores reales por **¬±4.87 millas por gal√≥n**.
    -   Como **los errores grandes tienen m√°s peso** (al ser elevados al cuadrado), el RMSE ser√° siempre **igual o mayor al MAE**. Penaliza m√°s los errores grandes que el MAE.
    -   Es **aceptable para predicci√≥n en `mtcars`**, pero con espacio para mejora si se requiere mayor precisi√≥n.

**Compararlo con el MAE**

-   Si **RMSE est√° mucho m√°s alto que el MAE**, el modelo est√° cometiendo **errores grandes con frecuencia** (outliers, mala especificaci√≥n).\
-   Si **RMSE ‚âà MAE**, los errores est√°n bien distribuidos.

#### Coeficiente de determinaci√≥n $R^2$

$R^{2}$ (**coeficiente de determinaci√≥n**) mide qu√© proporci√≥n de la variabilidad de la **variable dependiente** es explicada por el modelo.

La f√≥rmula general del $R^2$ (coeficiente de determinaci√≥n) es:

$$R^2 = 1 - \frac{SSE}{SST}$$

Donde:

-   $SSE$ (Sum of Squared Errors) o $RSS$ (Residual Sum of Squares): Es la **Suma de Cuadrados de los Errores** (o Suma de Cuadrados de los Residuos). Mide la variaci√≥n no explicada por el modelo. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados ($y_i$) y los valores predichos por el modelo ($\hat{y}_i$):

$$SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

-   $SST$ (Total Sum of Squares): Es la **Suma Total de Cuadrados**. Mide la variaci√≥n total de la variable dependiente respecto a su media. Representa la variabilidad total en los datos que el modelo intenta explicar. Se calcula como la suma de los cuadrados de las diferencias entre los valores observados ($y_i$) y la media de la variable dependiente ($\bar{y}$):

$$SST = \sum_{i=1}^{n} (y_i - \bar{y})^2$$

##### Interpretaci√≥n del $R^2$:

-   El $R^2$ es una m√©trica que var√≠a entre **0 y 1** (o 0% y 100%).\
-   $R^2 = 0$: Indica que el modelo no explica ninguna de la variabilidad en la variable dependiente. Es tan bueno como simplemente usar la media de la variable dependiente para la predicci√≥n.\
-   $R^2 = 1$: Indica que el modelo explica el 100% de la variabilidad en la variable dependiente. Esto rara vez ocurre en la pr√°ctica con datos del mundo real, y a menudo sugiere sobreajuste si sucede en un conjunto de entrenamiento.\
-   **Valores m√°s altos de** $R^2$ indican un mejor ajuste del modelo a los datos observados, lo que significa que las variables predictoras del modelo explican una mayor proporci√≥n de la variabilidad en la variable dependiente.

```{r}
# R¬≤ manual (opcional)
SST <- sum((test_data_reducido$mpg - mean(test_data_reducido$mpg))^2)
SSE <- sum((test_data_reducido$mpg - predicciones)^2)
R2 <- 1 - SSE/SST
R2
```

-   Esto significa que el **60.2% de la variabilidad** de `mpg` (consumo de combustible) en los datos de prueba **es explicada por el modelo**.
    -   El **39.8% restante** es **variabilidad no explicada** (error, factores no incluidos, ruido).\
    -   El modelo predice **m√°s de la mitad de la variabilidad de `mpg`** en los datos de prueba.

#### Distribuci√≥n de los residuos

Relaci√≥n lineal entre variable dependiente e independiente:

Se calculan los residuos para cada observaci√≥n y se representan (`scatterplot`). Si las observaciones siguen la l√≠nea del modelo, los residuos se deben distribuir aleatoriamente entorno al valor 0.

```{r, class.source = "fold-hide"}
tabla <- data.frame(prediccion = modelo_step$fitted.values,
                    residuos = modelo_step$residuals)

ggplot(data = tabla, aes(x = prediccion, y = residuos)) +
 geom_point(aes(color = residuos)) +
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") +
   geom_hline(yintercept = 0) +
    geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) +
     theme_bw() +
      theme(plot.title = element_text(size = 22, hjust = 0, family = "Montserrat", face = "bold"),
            plot.subtitle = element_text(size = 18, hjust = 0, family = "Montserrat", face = "bold"),
            plot.caption = element_text(size = 11, hjust = 0.2, vjust = 1, family = "Montserrat"), 
            axis.text = element_text(family = "Montserrat"), 
            axis.title = element_text(family = "Montserrat", size = 15), 
            legend.position = "none"
                   ) + 
     labs(title = "Distribuci√≥n de los residuos", 
          x = "predicci√≥n modelo",
          y = "residuo") 
  
```

Los residuos se distribuyen de forma aleatoria entorno al `0` por lo que se acepta la linealidad.

##### Distribuci√≥n normal de los residuos

Los residuos se deben distribuir de forma normal con media 0. Para comprobarlo se recurre a histogramas, a los cuantiles normales o a un test de contraste de normalidad.

```{r, class.source = "fold-hide"}
ggplot(data = tabla, aes(x = residuos)) +
  geom_histogram(aes(y = ..density..)) +
   theme_light() +
    theme(plot.title = element_text(size = 22, hjust = 0, family = "Montserrat", face = "bold"),
          plot.subtitle = element_text(size = 18, hjust = 0, family = "Montserrat", face = "bold"),
          plot.caption = element_text(size = 11, hjust = 0.2, vjust = 1, family = "Montserrat"), 
          axis.text = element_text(family = "Montserrat"), 
          axis.title = element_text(family = "Montserrat", size = 15), 
          legend.position = "none"
                   ) + 
      labs(title = "Histograma de los residuos")
```

#### Q-Q Plot

Los gr√°ficos Q-Q normales son esenciales para verificar uno de los supuestos clave en la regresi√≥n lineal: la **normalidad de los residuos**. Si los residuos siguen una distribuci√≥n normal, los puntos en el gr√°fico Q-Q deben caer aproximadamente a lo largo de una l√≠nea recta.

```{r, class.source = "fold-hide"}
# Residuos del modelo
residuos <- residuals(modelo_step)

# Calcular los cuantiles te√≥ricos normales
# La funci√≥n 'qqnorm' internamente calcula estos valores
# Puedes replicarlo manualmente o usar la funci√≥n 'qqnorm' y luego extraer sus valores
qq_data <- data.frame(teoricos = qqnorm(residuos, plot.it = FALSE)$x,
                      observados = residuos)


ggplot(qq_data, aes(x = teoricos, y = observados)) +
 geom_point(alpha = 0.7, color = "darkblue") + # Puntos de los cuantiles
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + # L√≠nea de referencia ideal (y=x)
   theme_minimal() + 
   labs(title = "Gr√°fico Q-Q Normal de los Residuos del Modelo",
        x = "Cuantiles Te√≥ricos Normales",
        y = "Residuos del Modelo") 
```

##### Interpretaci√≥n del gr√°fico Q-Q Normal:

-   **Si los puntos caen aproximadamente sobre la l√≠nea roja diagonal**, indica que los residuos siguen una distribuci√≥n normal. Esto es lo que idealmente buscas.\
-   **Si los puntos se desv√≠an de la l√≠nea**, puede indicar una violaci√≥n del supuesto de normalidad:
    -   **Forma de "S"**: Los residuos pueden tener colas m√°s pesadas o m√°s ligeras de lo esperado (ej. distribuci√≥n con curtosis).
-   **Curvatura en un extremo o ambos**: Los residuos pueden estar sesgados (skewed) hacia la izquierda o la derecha.

#### Residuos Studentizados (Studentized Residuals)

-   Tambi√©n conocidos como residuos studentizados externamente (o residuos t). Son una versi√≥n m√°s refinada de los residuos estandarizados.

-   Cada residuo se divide por una estimaci√≥n de su error est√°ndar que excluye la observaci√≥n actual, lo que los hace m√°s apropiados para la detecci√≥n de outliers, ya que el outlier no influye en la estimaci√≥n de su propia varianza.

```{r, class.source = "fold-hide"}
# Residuos del modelo
residuos <- rstudent(modelo_step)

# Calcular los cuantiles te√≥ricos normales
# La funci√≥n 'qqnorm' internamente calcula estos valores
# Puedes replicarlo manualmente o usar la funci√≥n 'qqnorm' y luego extraer sus valores
qq_data <- data.frame(teoricos = qqnorm(residuos, plot.it = FALSE)$x,
                      observados = residuos)


ggplot(qq_data, aes(x = teoricos, y = observados)) +
 geom_point(alpha = 0.7, color = "darkblue") + # Puntos de los cuantiles
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + # L√≠nea de referencia ideal (y=x)
   theme_minimal() + 
   labs(title = "Gr√°fico Q-Q Normal de los Residuos studentized",
        x = "Cuantiles Te√≥ricos Normales",
        y = "Residuos studentized") 
```

#### Shapiro-Wilk normality test

El **Test de Normalidad de Shapiro-Wilk** es una prueba estad√≠stica que se utiliza para determinar si una muestra de datos procede de una poblaci√≥n con distribuci√≥n normal. Es una de las pruebas de normalidad m√°s potentes y ampliamente recomendadas, especialmente para tama√±os de muestra peque√±os a moderados.

Es una prueba estad√≠stica que eval√∫a si los datos provienen de una distribuci√≥n normal.

-   **Hip√≥tesis nula (H‚ÇÄ)**: los datos siguen una distribuci√≥n normal.
-   **Hip√≥tesis alternativa (H‚ÇÅ)**: los datos **no** siguen una distribuci√≥n normal.

```{r}
shapiro.test(modelo_step$residuals)
```

-   **p = 0.5222 \> 0.05** ‚Üí **no se rechaza H‚ÇÄ**
    -   **Conclusi√≥n**: **los residuos del modelo pueden considerarse normalmente distribuidos**.

##### Evaluaci√≥n de los residuos de un modelo lineal

```{r, fig.width=10}
par(mfrow = c(1,2))
plot(modelo_step)
```

### Validaci√≥n cruzada

La **validaci√≥n cruzada** es una t√©cnica estad√≠stica esencial utilizada en el aprendizaje autom√°tico y la modelizaci√≥n para **evaluar la capacidad de un modelo para generalizar a un conjunto de datos independiente**, es decir, a datos que no se han visto durante el entrenamiento. Su objetivo principal es obtener una estimaci√≥n m√°s robusta y menos sesgada del rendimiento predictivo del modelo, ayudando a evitar el **sobreajuste (overfitting)**.

Cuando se construye un modelo, y se entrena con un conjunto de datos. Se eval√∫a el rendimiento del modelo en esos mismos datos de entrenamiento, a menudo se obtendr√° una m√©trica de rendimiento inflada (por ejemplo, un $R^2$ muy alto o un MAE/RMSE muy bajo). Esto se debe a que el modelo ha "memorizado" los datos de entrenamiento, incluyendo el ruido y las particularidades de esa muestra espec√≠fica. Sin embargo, un modelo sobreajustado no funcionar√° bien con datos nuevos y reales.

#### Tipos Comunes de Validaci√≥n Cruzada:

Aunque hay varias variaciones, las m√°s comunes son:

#### Beneficios de la Validaci√≥n Cruzada:

-   **Estimaci√≥n Robusta del Rendimiento:** Proporciona una m√©trica de rendimiento m√°s fiable y menos sesgada de c√≥mo se comportar√° el modelo con datos nuevos.
-   **Detecci√≥n de Sobreajuste:** Ayuda a identificar si un modelo est√° sobreajustado, ya que un modelo sobreajustado tendr√° un rendimiento mucho peor en los folds de validaci√≥n que en los de entrenamiento.
-   **Selecci√≥n de Modelos y Ajuste de Hiperpar√°metros:** Es fundamental para comparar y seleccionar entre diferentes modelos (ej., regresi√≥n lineal vs. √°rboles de decisi√≥n) o para encontrar los mejores **hiperpar√°metros** para un modelo (ej., la profundidad m√°xima de un √°rbol de decisi√≥n). Esto se logra a menudo mediante t√©cnicas como la **b√∫squeda de rejilla (Grid Search)** o la **b√∫squeda aleatoria (Random Search)** combinadas con validaci√≥n cruzada.

##### Validaciones cruzadas recomendadas para OLSR

En modelos de **regresi√≥n lineal OLS (Ordinary Least Squares Regression)**, la **validaci√≥n cruzada (cross-validation)** es clave para estimar la capacidad de generalizaci√≥n del modelo.

###### **Validaci√≥n Cruzada K-Fold (K-Fold Cross-Validation):**

-   Es el tipo m√°s popular. El conjunto de datos se divide en $k$ folds. .
-   **Elecci√≥n de** $k$: Los valores comunes para $k$ son 5 o 10. Un $k$ m√°s alto (por ejemplo, 10) proporciona una estimaci√≥n m√°s precisa del rendimiento pero es computacionalmente m√°s costoso. Un $k$ m√°s bajo (por ejemplo, 5) es m√°s r√°pido pero la estimaci√≥n puede ser m√°s variable.

<p align="center">
<img src="../../img/K-Fold (Cross Validation).png" alt="Machine Learning Steps" width="80%"/>
</p>

````         
```r
trainControl(method = "cv", number = 10)
```
````

-   **M√°s usada** y recomendada para regresi√≥n lineal.
-   Divide los datos en *k* grupos (folds), entrena el modelo en *k-1* y valida en el restante, repitiendo *k* veces.
-   `k = 10` es un valor est√°ndar que ofrece **buen balance entre sesgo y varianza**.
-   Muy √∫til para evaluar errores como RMSE o MAE.

###### **Validaci√≥n Cruzada de Dejar Uno Fuera (Leave-One-Out Cross-Validation - LOOCV):**

-   Es un caso especial de K-Fold donde $k$ es igual al n√∫mero de observaciones ($n$) en el conjunto de datos.
-   En cada iteraci√≥n, una sola observaci√≥n se usa como conjunto de validaci√≥n, y las $n-1$ observaciones restantes se usan para entrenar el modelo.
-   **Ventaja:** Proporciona una estimaci√≥n casi insesgada del rendimiento.
-   **Desventaja:** Es computacionalmente muy costoso, especialmente para grandes conjuntos de datos, ya que se ajusta el modelo $n$ veces.

<p align="center">
<img src="../../img/LOOCV (Cross Validation).png" alt="Machine Learning Steps" width="80%"/>
</p>

````         
```r
trainControl(method = "LOOCV")
```
````

-   Cada observaci√≥n se deja fuera una vez (es como `k = n`).
-   Proporciona una evaluaci√≥n **menos sesgada**, pero puede ser **computacionalmente costosa**.
-   En modelos lineales como OLS, es factible y a veces preferido si tienes pocos datos.

###### **Validaci√≥n Cruzada de Repeated k-fold cross-validation**

La **validaci√≥n cruzada repetida k-fold** (`Repeated k-Fold Cross-Validation`) es una extensi√≥n del m√©todo k-fold cross-validation y se utiliza para obtener una **estimaci√≥n m√°s estable** y **confiable del desempe√±o de un modelo**, especialmente cuando el conjunto de datos es peque√±o o tiene mucha variabilidad.

<p align="center">
<img src="../../img/Repeated k-fold cross-validation.png" alt="Machine Learning Steps" width="50%"/>
</p>

````         
```r
trainControl(method = "repeatedcv", number = 10, repeats = 5)
```
````

-   Repite el proceso de k-fold varias veces con diferentes particiones aleatorias.
-   Ofrece una **estimaci√≥n m√°s estable** del error de generalizaci√≥n.
-   √ötil si los datos tienen mucha variabilidad o ruido.

```{r}
# 6. Validaci√≥n cruzada 
control <- trainControl(method = "cv", number = 10)

modelo_cv <- train(mpg ~ .,
                   data = mtcars,
                   method = "lm",
                   trControl = control)
print(modelo_cv)
```

```{r}
modelo_cv_reducido <- train(mpg ~ drat + wt + gear + carb,
                            data = mtcars,
                            method = "lm",
                            trControl = control
)
print(modelo_cv_reducido)
```

| M√©trica | Valor | Interpretaci√≥n |
|---------------------------------|---------------|------------------------|
| **RMSE** *(Root Mean Squared Error)* | `3.14` | El error promedio en las predicciones es de **3.14 millas por gal√≥n (mpg)**. Este valor ha **mejorado** en comparaci√≥n con el modelo completo (que ten√≠a \~3.40). |
| **R¬≤** *(R-squared)* | `0.893` | El modelo reducido explica el **89.3% de la variaci√≥n de `mpg`**, lo cual es **mejor** que el 84.5% del modelo completo. |
| **MAE** *(Mean Absolute Error)* | `2.74` | El error absoluto medio tambi√©n es **menor**, lo cual es positivo. |

#### Nuevos datos

Se **utiliza el modelo ya entrenado** para predecir el consumo de gasolina (variable `mpg`) de un **nuevo autom√≥vil simulado**, con caracter√≠sticas espec√≠ficas.

$$\hat{Y} = 12.1 + 2.20(drat) - 1.8(wt) + 2.84(gear) - 1.63(carb)$$

```{r, eval = FALSE}
# 7. Usar el modelo para predecir nuevos datos (simulaci√≥n)
nuevo_auto <- data.frame(drat = 3.5,
                         wt = 2.8,
                         gear = 4,
                         carb = 2)

predict(modelo_step, newdata = nuevo_auto)
```

Esto significa que, seg√∫n el modelo, un auto con esas caracter√≠sticas tendr√° un rendimiento de aproximadamente 22.8 mpg.

```{r}
# 8. Interpretaci√≥n del modelo (con broom)
tidy(modelo_step)
```

## üìå Notas

-   Este modelo es considerado **supervisado** porque se entrena con pares de entrada y salida.
-   Aunque la regresi√≥n lineal es simple, **sigue siendo un algoritmo de machine learning supervisado** y √∫til como l√≠nea base (baseline).
-   Puedes reemplazar `lm()` por modelos m√°s complejos como `randomForest`, `xgboost`, etc., manteniendo la misma estructura.

### Ventajas y Limitaciones

**Ventajas:**

-   **Simplicidad:** Es f√°cil de entender e implementar.

-   **Interpretabilidad:** Los coeficientes estimados tienen una interpretaci√≥n clara.

-   **Eficiencia:** Bajo ciertas condiciones, los estimadores de OLS son los m√°s eficientes.

**Limitaciones:**

-   **Sensibilidad a valores at√≠picos:** Los valores extremos pueden influir mucho en la l√≠nea de regresi√≥n.
-   **Sensibilidad a violaciones de supuestos:** Si los supuestos no se cumplen, las estimaciones pueden ser sesgadas o ineficientes, y la inferencia estad√≠stica puede ser inv√°lida.
-   **Solo relaciones lineales:** No puede capturar relaciones no lineales a menos que se transformen las variables adecuadamente.

## Referencias

James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An introduction to statistical learning: With applications in R* (2nd ed.). Springer. <https://www.statlearning.com>

Fox, J., & Weisberg, S. (2019). *An R companion to applied regression* (3rd ed.). Sage.

Montgomery, D. C., Peck, E. A., & Vining, G. G. (2012). *Introduction to linear regression analysis* (5th ed.). Wiley.

Librerias que se usaron en el documento

```{r, echo = FALSE, eval = TRUE}
sesion_info <- devtools::session_info()
require(knitr)
require(kableExtra)
kable(dplyr::select(tibble::as_tibble(sesion_info$packages %>% dplyr::filter(attached == TRUE)),
                    c(package, loadedversion, source))) %>%
 kable_styling(font_size = 10, 
               bootstrap_options = c("condensed", "responsive", "bordered")) %>%
  kable_classic(full_width = TRUE, html_font = "montserrat") %>% 
   scroll_box(width = "100%", height = "400px") %>%  
    gsub("font-size: initial !important;", "font-size: 10pt !important;", .)
```

<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png" alt="Creative Commons Licence" style="border-width:0"/></a><br />This work by [**Diana Villasana Ocampo**]{xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"} is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
